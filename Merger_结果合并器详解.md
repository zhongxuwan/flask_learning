# Merger ç»“æœåˆå¹¶å™¨è¯¦è§£

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [å¯¼å…¥è¯­å¥è¯¦è§£](#å¯¼å…¥è¯­å¥è¯¦è§£)
3. [ResultMergerç±»åˆå§‹åŒ–](#resultmergerç±»åˆå§‹åŒ–)
4. [JSONæ–‡ä»¶åˆå¹¶æ–¹æ³•](#jsonæ–‡ä»¶åˆå¹¶æ–¹æ³•)
5. [BibTeXæ–‡ä»¶åˆå¹¶æ–¹æ³•](#bibtexæ–‡ä»¶åˆå¹¶æ–¹æ³•)
6. [ç»Ÿä¸€åˆå¹¶æ–¹æ³•](#ç»Ÿä¸€åˆå¹¶æ–¹æ³•)
7. [æŠ€æœ¯æ€»ç»“](#æŠ€æœ¯æ€»ç»“)

---

## ğŸ“– é¡¹ç›®æ¦‚è¿°

`merger.py` æ˜¯ä¸€ä¸ª**æ–‡ä»¶åˆå¹¶å·¥å…·**ï¼Œç”¨äºåˆå¹¶å¤šä¸ªæœç´¢ç»“æœæ–‡ä»¶ï¼Œå»é™¤é‡å¤æ¡ç›®ï¼Œä¿ç•™æœ€å®Œæ•´çš„ä¿¡æ¯ã€‚

### ä¸»è¦åŠŸèƒ½

- ğŸ“„ **JSONåˆå¹¶**: åˆå¹¶å¤šä¸ªJSONç»“æœæ–‡ä»¶
- ğŸ“š **BibTeXåˆå¹¶**: åˆå¹¶å¤šä¸ªBibTeXå¼•ç”¨æ–‡ä»¶
- ğŸ” **å»é‡å¤„ç†**: è‡ªåŠ¨è¯†åˆ«å¹¶å»é™¤é‡å¤æ¡ç›®
- âœ¨ **æ™ºèƒ½é€‰æ‹©**: ä¿ç•™ä¿¡æ¯æœ€å®Œæ•´çš„ç‰ˆæœ¬
- ğŸ’¾ **ç»Ÿä¸€è¾“å‡º**: ç”Ÿæˆåˆå¹¶åçš„å•ä¸€æ–‡ä»¶

### æ ¸å¿ƒæµç¨‹

```
è¯»å–å¤šä¸ªæ–‡ä»¶ â†’ æå–å”¯ä¸€é”® â†’ å»é‡åˆå¹¶ â†’ ä¿ç•™æœ€ä¼˜ç‰ˆæœ¬ â†’ å†™å…¥åˆå¹¶æ–‡ä»¶
     â†“            â†“          â†“            â†“              â†“
  JSON/BIB    citation_key   å­—å…¸å­˜å‚¨    æ¯”è¾ƒæ‘˜è¦é•¿åº¦    è¾“å‡ºæ–‡ä»¶
```

### æ–‡ä»¶ç»Ÿè®¡

- **æ€»è¡Œæ•°**: 184è¡Œ
- **å¯¼å…¥æ¨¡å—**: 4ä¸ª
- **ç±»æ•°é‡**: 1ä¸ªï¼ˆResultMergerï¼‰
- **æ–¹æ³•æ•°é‡**: 4ä¸ª
- **ä»£ç ç®€æ´åº¦**: â­â­â­â­â­

---

## ğŸ“¦ å¯¼å…¥è¯­å¥è¯¦è§£

### æ ‡å‡†åº“å¯¼å…¥ï¼ˆç¬¬1-4è¡Œï¼‰

```python
import os                                  # ç¬¬1è¡Œ
import re                                  # ç¬¬2è¡Œ
import json                                # ç¬¬3è¡Œ
from typing import Dict, List              # ç¬¬4è¡Œ
```

**ç¬¬1è¡Œè¯¦è§£**ï¼š`import os`

```python
import os

# osæ¨¡å—åœ¨æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# 1. æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
os.path.exists(folder_path)

# 2. åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶
os.listdir(folder_path)

# 3. æ‹¼æ¥æ–‡ä»¶è·¯å¾„
os.path.join(folder, filename)

# os.pathå¸¸ç”¨æ–¹æ³•
# 1. exists() - æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
if os.path.exists('data.json'):
    print("æ–‡ä»¶å­˜åœ¨")

# 2. isfile() - æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶
if os.path.isfile('data.json'):
    print("æ˜¯æ–‡ä»¶")

# 3. isdir() - æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•
if os.path.isdir('results'):
    print("æ˜¯ç›®å½•")

# 4. join() - è·¨å¹³å°è·¯å¾„æ‹¼æ¥
path = os.path.join('folder', 'subfolder', 'file.txt')
# Windows: folder\subfolder\file.txt
# Linux: folder/subfolder/file.txt

# 5. dirname() - è·å–ç›®å½•å
dirname = os.path.dirname('/path/to/file.txt')
# '/path/to'

# 6. basename() - è·å–æ–‡ä»¶å
filename = os.path.basename('/path/to/file.txt')
# 'file.txt'

# os.listdir()è¯¦è§£
# åŠŸèƒ½ï¼šåˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•
files = os.listdir('results')
# ['file1.json', 'file2.json', 'subfolder']

# è¿‡æ»¤ç‰¹å®šç±»å‹çš„æ–‡ä»¶
json_files = [f for f in os.listdir('results') if f.endswith('.json')]

# éå†ç›®å½•ä¸­çš„æ–‡ä»¶
for filename in os.listdir('results'):
    if filename.endswith('.json'):
        # å¤„ç†JSONæ–‡ä»¶
        pass
```

**ç¬¬2è¡Œè¯¦è§£**ï¼š`import re`

```python
import re

# reæ¨¡å—åœ¨æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# æå–BibTeXæ¡ç›®çš„é”®åï¼ˆç¬¬91è¡Œï¼‰
entry_pattern = re.compile(r'@\w+\{([^,]+),')

# æ­£åˆ™è¡¨è¾¾å¼è¯¦è§£
# r'@\w+\{([^,]+),'
# @        - å­—é¢åŒ¹é…@ç¬¦å·
# \w+      - 1ä¸ªæˆ–å¤šä¸ªå•è¯å­—ç¬¦ï¼ˆå­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
# \{       - å­—é¢åŒ¹é…å·¦èŠ±æ‹¬å·{
# ([^,]+)  - æ•è·ç»„ï¼š1ä¸ªæˆ–å¤šä¸ªéé€—å·å­—ç¬¦
# ,        - å­—é¢åŒ¹é…é€—å·

# BibTeXæ¡ç›®æ ¼å¼ç¤ºä¾‹
"""
@article{Zhang2024DeepLearning,
  title = {Deep Learning},
  author = {Zhang, L.},
  year = {2024}
}
"""

# æå–é”®å"Zhang2024DeepLearning"
match = entry_pattern.search(entry)
if match:
    key = match.group(1)  # "Zhang2024DeepLearning"

# re.compile()è¯¦è§£
# åŠŸèƒ½ï¼šç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼Œæé«˜é‡å¤ä½¿ç”¨çš„æ•ˆç‡

# ä¸ç¼–è¯‘ï¼ˆæ¯æ¬¡éƒ½é‡æ–°è§£æï¼‰
for text in texts:
    match = re.search(r'pattern', text)

# ç¼–è¯‘åï¼ˆåªè§£æä¸€æ¬¡ï¼‰
pattern = re.compile(r'pattern')
for text in texts:
    match = pattern.search(text)  # æ›´å¿«

# reå¸¸ç”¨æ–¹æ³•
# 1. search() - æŸ¥æ‰¾ç¬¬ä¸€ä¸ªåŒ¹é…
match = re.search(r'pattern', text)
if match:
    print(match.group())

# 2. findall() - æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…
matches = re.findall(r'\d+', '123 abc 456')
# ['123', '456']

# 3. sub() - æ›¿æ¢
result = re.sub(r'\s+', ' ', '  å¤š  ä¸ª  ç©ºæ ¼  ')
# ' å¤š ä¸ª ç©ºæ ¼ '

# 4. split() - åˆ†å‰²
parts = re.split(r'\s+', 'a  b    c')
# ['a', 'b', 'c']

# æ•è·ç»„è¯¦è§£
# () - å®šä¹‰æ•è·ç»„
pattern = r'(\d{4})-(\d{2})-(\d{2})'
match = re.search(pattern, '2024-01-15')
if match:
    year = match.group(1)   # '2024'
    month = match.group(2)  # '01'
    day = match.group(3)    # '15'
    full = match.group(0)   # '2024-01-15'ï¼ˆå®Œæ•´åŒ¹é…ï¼‰
```

**ç¬¬3è¡Œè¯¦è§£**ï¼š`import json`

```python
import json

# jsonæ¨¡å—åœ¨æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# 1. è¯»å–JSONæ–‡ä»¶ï¼ˆç¬¬38è¡Œï¼‰
with open(file_path, 'r', encoding='utf-8') as f:
    data = json.load(f)

# 2. å†™å…¥JSONæ–‡ä»¶ï¼ˆç¬¬70è¡Œï¼‰
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

# json.load() vs json.loads()
# load()ï¼šä»æ–‡ä»¶è¯»å–
with open('data.json', 'r') as f:
    data = json.load(f)

# loads()ï¼šä»å­—ç¬¦ä¸²è§£æ
json_str = '{"name": "å¼ ä¸‰"}'
data = json.loads(json_str)

# json.dump() vs json.dumps()
# dump()ï¼šå†™å…¥æ–‡ä»¶
with open('data.json', 'w') as f:
    json.dump(data, f)

# dumps()ï¼šè½¬ä¸ºå­—ç¬¦ä¸²
json_str = json.dumps(data)

# dump()å‚æ•°è¯¦è§£
json.dump(
    data,                    # è¦åºåˆ—åŒ–çš„æ•°æ®
    f,                       # æ–‡ä»¶å¯¹è±¡
    ensure_ascii=False,      # ä¸è½¬ä¹‰éASCIIå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ï¼‰
    indent=2                 # ç¼©è¿›2ä¸ªç©ºæ ¼ï¼ˆç¾åŒ–è¾“å‡ºï¼‰
)

# ensure_asciiå‚æ•°
# Trueï¼ˆé»˜è®¤ï¼‰ï¼š
{"name": "\u5f20\u4e09"}  # ä¸­æ–‡è¢«è½¬ä¹‰

# Falseï¼š
{"name": "å¼ ä¸‰"}           # ä¿ç•™ä¸­æ–‡

# indentå‚æ•°
# Noneï¼ˆé»˜è®¤ï¼‰ï¼šç´§å‡‘æ ¼å¼
{"name":"å¼ ä¸‰","age":25}

# 2ï¼šç¼©è¿›2ä¸ªç©ºæ ¼
{
  "name": "å¼ ä¸‰",
  "age": 25
}

# JSONDecodeErrorå¼‚å¸¸
# å½“JSONæ ¼å¼é”™è¯¯æ—¶æŠ›å‡º
try:
    data = json.load(f)
except json.JSONDecodeError as e:
    print(f"JSONè§£æé”™è¯¯: {e}")
```

**ç¬¬4è¡Œè¯¦è§£**ï¼š`from typing import Dict, List`

```python
from typing import Dict, List

# ç±»å‹æç¤ºè¯¦è§£
# Dictï¼šå­—å…¸ç±»å‹
# Listï¼šåˆ—è¡¨ç±»å‹

# ä½¿ç”¨ç¤ºä¾‹
def merge_files(files: List[str]) -> Dict[str, int]:
    """
    å‚æ•°filesæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
    è¿”å›å€¼æ˜¯å­—å…¸ï¼šé”®æ˜¯å­—ç¬¦ä¸²ï¼Œå€¼æ˜¯æ•´æ•°
    """
    return {'count': len(files)}

# æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# List[str]ï¼šå­—ç¬¦ä¸²åˆ—è¡¨
filenames: List[str] = os.listdir(folder)

# Dict[str, dict]ï¼šå­—å…¸ï¼Œé”®æ˜¯å­—ç¬¦ä¸²ï¼Œå€¼æ˜¯å­—å…¸
unique_entries: Dict[str, dict] = {}

# ç±»å‹æç¤ºçš„å¥½å¤„
# 1. IDEè‡ªåŠ¨å®Œæˆ
# 2. ç±»å‹æ£€æŸ¥ï¼ˆmypyï¼‰
# 3. æ–‡æ¡£ä½œç”¨
# 4. æé«˜ä»£ç å¯è¯»æ€§
```

---

## ğŸ”§ ResultMergerç±»åˆå§‹åŒ–

### ç±»å®šä¹‰ï¼ˆç¬¬6-7è¡Œï¼‰

```python
class ResultMerger:                        # ç¬¬6è¡Œ
    """ç»“æœæ–‡ä»¶åˆå¹¶ç±»"""                    # ç¬¬7è¡Œ
```

**ç±»å®šä¹‰è¯¦è§£ï¼ˆç¬¬6-7è¡Œï¼‰**ï¼š

```python
class ResultMerger:
    """ç»“æœæ–‡ä»¶åˆå¹¶ç±»"""

# ç±»çš„ä½œç”¨
# 1. åˆå¹¶å¤šä¸ªJSONæ–‡ä»¶
# 2. åˆå¹¶å¤šä¸ªBibTeXæ–‡ä»¶
# 3. å»é™¤é‡å¤æ¡ç›®
# 4. ä¿ç•™æœ€å®Œæ•´çš„ä¿¡æ¯

# ä¸ºä»€ä¹ˆç”¨ç±»ï¼Ÿ
# 1. å°è£…ç›¸å…³åŠŸèƒ½
# 2. ç®¡ç†çŠ¶æ€ï¼ˆæ–‡ä»¶å¤¹è·¯å¾„ã€è¾“å‡ºæ–‡ä»¶åï¼‰
# 3. ä»£ç å¤ç”¨

# å‘½åè§„èŒƒ
# - é©¼å³°å‘½åæ³•ï¼ˆCamelCaseï¼‰
# - ResultMerger = Resultï¼ˆç»“æœï¼‰+ Mergerï¼ˆåˆå¹¶å™¨ï¼‰
```

### åˆå§‹åŒ–æ–¹æ³•ï¼ˆç¬¬8-13è¡Œï¼‰

```python
def __init__(self, json_folder: str, bib_folder: str,   # ç¬¬8è¡Œ
             combined_json: str, combined_bib: str):    # ç¬¬9è¡Œ
    self.json_folder = json_folder                      # ç¬¬10è¡Œ
    self.bib_folder = bib_folder                        # ç¬¬11è¡Œ
    self.combined_json = combined_json                  # ç¬¬12è¡Œ
    self.combined_bib = combined_bib                    # ç¬¬13è¡Œ
```

**åˆå§‹åŒ–æ–¹æ³•è¯¦è§£ï¼ˆç¬¬8-13è¡Œï¼‰**ï¼š

```python
def __init__(self, json_folder: str, bib_folder: str, 
             combined_json: str, combined_bib: str):
    self.json_folder = json_folder
    self.bib_folder = bib_folder
    self.combined_json = combined_json
    self.combined_bib = combined_bib

# __init__æ„é€ å‡½æ•°
# å‚æ•°ï¼š
# - json_folderï¼šJSONæ–‡ä»¶æ‰€åœ¨ç›®å½•
# - bib_folderï¼šBibTeXæ–‡ä»¶æ‰€åœ¨ç›®å½•
# - combined_jsonï¼šåˆå¹¶åçš„JSONæ–‡ä»¶å
# - combined_bibï¼šåˆå¹¶åçš„BibTeXæ–‡ä»¶å

# å‚æ•°ç±»å‹æç¤º
# strï¼šå­—ç¬¦ä¸²ç±»å‹
# æ‰€æœ‰å‚æ•°éƒ½æ˜¯æ–‡ä»¶è·¯å¾„

# å®ä¾‹å˜é‡
# self.json_folderï¼šä¿å­˜JSONç›®å½•è·¯å¾„
# self.bib_folderï¼šä¿å­˜BibTeXç›®å½•è·¯å¾„
# self.combined_jsonï¼šä¿å­˜è¾“å‡ºJSONæ–‡ä»¶å
# self.combined_bibï¼šä¿å­˜è¾“å‡ºBibTeXæ–‡ä»¶å

# ä½¿ç”¨ç¤ºä¾‹
merger = ResultMerger(
    json_folder='json_results',
    bib_folder='bib_results',
    combined_json='references.json',
    combined_bib='references.bib'
)

# è®¿é—®å®ä¾‹å˜é‡
print(merger.json_folder)     # 'json_results'
print(merger.combined_json)   # 'references.json'

# ä¸ºä»€ä¹ˆä¿å­˜è¿™äº›è·¯å¾„ï¼Ÿ
# 1. é¿å…é‡å¤ä¼ é€’å‚æ•°
# 2. æ–¹ä¾¿åœ¨å¤šä¸ªæ–¹æ³•ä¸­ä½¿ç”¨
# 3. æ¸…æ™°çš„çŠ¶æ€ç®¡ç†

# ä¸ä½¿ç”¨å®ä¾‹å˜é‡ï¼ˆä¸æ¨èï¼‰ï¼š
def merge_json_files(self, json_folder, combined_json):
    # æ¯æ¬¡éƒ½è¦ä¼ é€’å‚æ•°
    pass

# ä½¿ç”¨å®ä¾‹å˜é‡ï¼ˆæ¨èï¼‰ï¼š
def merge_json_files(self):
    # ç›´æ¥ä½¿ç”¨self.json_folderå’Œself.combined_json
    pass
```

---

## ğŸ“„ JSONæ–‡ä»¶åˆå¹¶æ–¹æ³•

### æ–¹æ³•å®šä¹‰å’Œç›®å½•æ£€æŸ¥ï¼ˆç¬¬15-23è¡Œï¼‰

```python
def merge_json_files(self) -> bool:        # ç¬¬15è¡Œ
    """åˆå¹¶JSONæ–‡ä»¶"""                      # ç¬¬16è¡Œ
    if not os.path.exists(self.json_folder):  # ç¬¬17è¡Œ
        print(f"é”™è¯¯ï¼š{self.json_folder} ç›®å½•ä¸å­˜åœ¨")  # ç¬¬18è¡Œ
        return False                       # ç¬¬19è¡Œ
        
    if not os.listdir(self.json_folder):   # ç¬¬21è¡Œ
        print(f"é”™è¯¯ï¼š{self.json_folder} ç›®å½•ä¸ºç©º")  # ç¬¬22è¡Œ
        return False                       # ç¬¬23è¡Œ
```

**æ–¹æ³•å®šä¹‰å’ŒéªŒè¯è¯¦è§£ï¼ˆç¬¬15-23è¡Œï¼‰**ï¼š

```python
def merge_json_files(self) -> bool:
    """åˆå¹¶JSONæ–‡ä»¶"""
    if not os.path.exists(self.json_folder):
        print(f"é”™è¯¯ï¼š{self.json_folder} ç›®å½•ä¸å­˜åœ¨")
        return False
    
    if not os.listdir(self.json_folder):
        print(f"é”™è¯¯ï¼š{self.json_folder} ç›®å½•ä¸ºç©º")
        return False

# æ–¹æ³•ç­¾åè¯¦è§£
# -> boolï¼šè¿”å›ç±»å‹æ˜¯å¸ƒå°”å€¼
# Trueï¼šæˆåŠŸ
# Falseï¼šå¤±è´¥

# è¾“å…¥éªŒè¯ï¼ˆé˜²å¾¡æ€§ç¼–ç¨‹ï¼‰
# 1. æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
if not os.path.exists(self.json_folder):
    # ç›®å½•ä¸å­˜åœ¨ï¼Œæ— æ³•ç»§ç»­
    return False

# 2. æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º
if not os.listdir(self.json_folder):
    # os.listdir()è¿”å›ç©ºåˆ—è¡¨[]
    # not [] ä¸º True
    return False

# ä¸ºä»€ä¹ˆéœ€è¦éªŒè¯ï¼Ÿ
# 1. é¿å…è¿è¡Œæ—¶é”™è¯¯
# 2. æä¾›å‹å¥½çš„é”™è¯¯æç¤º
# 3. æ—©æœŸå¤±è´¥ï¼ˆFail Fastï¼‰

# f-stringæ ¼å¼åŒ–
folder = "json_results"
print(f"é”™è¯¯ï¼š{folder} ç›®å½•ä¸å­˜åœ¨")
# è¾“å‡ºï¼šé”™è¯¯ï¼šjson_results ç›®å½•ä¸å­˜åœ¨

# ç­‰ä»·å†™æ³•
print("é”™è¯¯ï¼š" + folder + " ç›®å½•ä¸å­˜åœ¨")
print("é”™è¯¯ï¼š{} ç›®å½•ä¸å­˜åœ¨".format(folder))

# f-stringçš„ä¼˜åŠ¿ï¼š
# 1. æ›´ç®€æ´
# 2. æ›´æ˜“è¯»
# 3. æ”¯æŒè¡¨è¾¾å¼

# è¿”å›å€¼çš„ä½¿ç”¨
success = merger.merge_json_files()
if success:
    print("åˆå¹¶æˆåŠŸ")
else:
    print("åˆå¹¶å¤±è´¥")
```

### åˆå§‹åŒ–æ•°æ®ç»“æ„ï¼ˆç¬¬25-28è¡Œï¼‰

```python
# å­˜å‚¨æ‰€æœ‰å·²å¤„ç†çš„æ¡ç›®ï¼Œä½¿ç”¨citation_keyä½œä¸ºé”®  # ç¬¬25è¡Œï¼ˆæ³¨é‡Šï¼‰
unique_entries = {}                        # ç¬¬26è¡Œ

print("å¼€å§‹åˆå¹¶JSONæ–‡ä»¶...")               # ç¬¬28è¡Œ
```

**æ•°æ®ç»“æ„åˆå§‹åŒ–è¯¦è§£ï¼ˆç¬¬26è¡Œï¼‰**ï¼š

```python
unique_entries = {}

# å­—å…¸ç”¨äºå»é‡
# é”®ï¼šcitation_keyï¼ˆæ–‡çŒ®å¼•ç”¨é”®ï¼‰
# å€¼ï¼šæ–‡çŒ®æ¡ç›®ï¼ˆå­—å…¸ï¼‰

# ä¸ºä»€ä¹ˆç”¨å­—å…¸è€Œä¸æ˜¯åˆ—è¡¨ï¼Ÿ
# å­—å…¸ï¼š
unique_entries = {}
# ä¼˜åŠ¿ï¼š
# 1. å¿«é€ŸæŸ¥æ‰¾ï¼šO(1)æ—¶é—´å¤æ‚åº¦
# 2. è‡ªåŠ¨å»é‡ï¼šç›¸åŒé”®ä¼šè¦†ç›–
# 3. æ˜“äºæ›´æ–°

# åˆ—è¡¨ï¼š
unique_list = []
# é—®é¢˜ï¼š
# 1. æŸ¥æ‰¾æ…¢ï¼šO(n)æ—¶é—´å¤æ‚åº¦
# 2. éœ€è¦æ‰‹åŠ¨å»é‡
# 3. æ›´æ–°éº»çƒ¦

# ä½¿ç”¨ç¤ºä¾‹
# æ·»åŠ æ¡ç›®
unique_entries['Zhang2024'] = {
    'title': 'Deep Learning',
    'abstract': '...'
}

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨
if 'Zhang2024' in unique_entries:
    print("å·²å­˜åœ¨")

# æ›´æ–°æ¡ç›®ï¼ˆå¦‚æœæ‘˜è¦æ›´é•¿ï¼‰
if len(new_abstract) > len(unique_entries['Zhang2024']['abstract']):
    unique_entries['Zhang2024'] = new_entry
```

### éå†å’Œå¤„ç†JSONæ–‡ä»¶ï¼ˆç¬¬30-62è¡Œï¼‰

```python
# éå†ç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶                # ç¬¬30è¡Œï¼ˆæ³¨é‡Šï¼‰
for filename in os.listdir(self.json_folder):  # ç¬¬31è¡Œ
    if filename.endswith('.json'):         # ç¬¬32è¡Œ
        file_path = os.path.join(self.json_folder, filename)  # ç¬¬33è¡Œ
        
        try:                               # ç¬¬35è¡Œ
            # è¯»å–JSONæ–‡ä»¶                  # ç¬¬36è¡Œï¼ˆæ³¨é‡Šï¼‰
            with open(file_path, 'r', encoding='utf-8') as f:  # ç¬¬37è¡Œ
                data = json.load(f)        # ç¬¬38è¡Œ
```

**æ–‡ä»¶éå†è¯¦è§£ï¼ˆç¬¬31-38è¡Œï¼‰**ï¼š

```python
for filename in os.listdir(self.json_folder):
    if filename.endswith('.json'):
        file_path = os.path.join(self.json_folder, filename)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

# forå¾ªç¯éå†æ–‡ä»¶
# os.listdir()è¿”å›ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶å
for filename in os.listdir('json_results'):
    # filename: 'query1.json', 'query2.json', ...

# è¿‡æ»¤JSONæ–‡ä»¶
if filename.endswith('.json'):
    # åªå¤„ç†.jsonæ–‡ä»¶
    # å¿½ç•¥å…¶ä»–æ–‡ä»¶ï¼ˆ.txtã€.bakç­‰ï¼‰

# endswith()æ–¹æ³•
'file.json'.endswith('.json')  # True
'file.txt'.endswith('.json')   # False
'data.json.bak'.endswith('.json')  # False

# å…¶ä»–å­—ç¬¦ä¸²åˆ¤æ–­æ–¹æ³•
'file.json'.startswith('file')  # True
'test' in 'testing'  # True
'data.json'.lower()  # 'data.json'ï¼ˆè½¬å°å†™ï¼‰

# è·¯å¾„æ‹¼æ¥
file_path = os.path.join(self.json_folder, filename)
# 'json_results' + 'query1.json' â†’ 'json_results/query1.json'

# ä¸ºä»€ä¹ˆç”¨os.path.join()ï¼Ÿ
# è·¨å¹³å°å…¼å®¹
# Windows: json_results\query1.json
# Linux:   json_results/query1.json

# try-exceptå¼‚å¸¸å¤„ç†
try:
    # å¯èƒ½å‡ºé”™çš„ä»£ç 
    data = json.load(f)
except json.JSONDecodeError:
    # JSONæ ¼å¼é”™è¯¯
    print("JSONè§£æå¤±è´¥")
except Exception as e:
    # å…¶ä»–é”™è¯¯
    print(f"é”™è¯¯: {e}")

# withè¯­å¥
with open(file_path, 'r', encoding='utf-8') as f:
    data = json.load(f)
# æ–‡ä»¶è‡ªåŠ¨å…³é—­ï¼Œå³ä½¿å‡ºé”™

# ç­‰ä»·çš„try-finally
f = open(file_path, 'r', encoding='utf-8')
try:
    data = json.load(f)
finally:
    f.close()

# encoding='utf-8'
# æŒ‡å®šæ–‡ä»¶ç¼–ç ä¸ºUTF-8
# ç¡®ä¿ä¸­æ–‡ç­‰å­—ç¬¦æ­£ç¡®è¯»å–
```

### å¤„ç†JSONæ•°æ®ï¼ˆç¬¬40-56è¡Œï¼‰

```python
# ç¡®ä¿æ•°æ®æ˜¯åˆ—è¡¨æ ¼å¼                      # ç¬¬40è¡Œï¼ˆæ³¨é‡Šï¼‰
if isinstance(data, list):             # ç¬¬41è¡Œ
    total_entries = len(data)          # ç¬¬42è¡Œ
    unique_count = 0                   # ç¬¬43è¡Œ
    
    # å¤„ç†æ¯ä¸ªæ¡ç›®                       # ç¬¬45è¡Œï¼ˆæ³¨é‡Šï¼‰
    for item in data:                  # ç¬¬46è¡Œ
        # è·å–citation_key              # ç¬¬47è¡Œï¼ˆæ³¨é‡Šï¼‰
        citation_key = item.get('citation_key')  # ç¬¬48è¡Œ
        
        if citation_key:               # ç¬¬50è¡Œ
            # å¦‚æœæ˜¯æ–°çš„æ¡ç›®æˆ–è€…å½“å‰æ¡ç›®çš„æ‘˜è¦æ›´é•¿ï¼Œåˆ™æ›´æ–°  # ç¬¬51è¡Œï¼ˆæ³¨é‡Šï¼‰
            if (citation_key not in unique_entries or   # ç¬¬52è¡Œ
                len(item.get('abstract', '')) > len(unique_entries[citation_key].get('abstract', ''))):  # ç¬¬53è¡Œ
                unique_entries[citation_key] = item     # ç¬¬54è¡Œ
                if citation_key not in unique_entries:  # ç¬¬55è¡Œ
                    unique_count += 1                   # ç¬¬56è¡Œ
```

**æ•°æ®å¤„ç†è¯¦è§£ï¼ˆç¬¬41-56è¡Œï¼‰**ï¼š

```python
if isinstance(data, list):
    for item in data:
        citation_key = item.get('citation_key')
        
        if citation_key:
            if (citation_key not in unique_entries or 
                len(item.get('abstract', '')) > len(unique_entries[citation_key].get('abstract', ''))):
                unique_entries[citation_key] = item

# isinstance()ç±»å‹æ£€æŸ¥
isinstance(data, list)  # dataæ˜¯åˆ—è¡¨å—ï¼Ÿ
isinstance(data, dict)  # dataæ˜¯å­—å…¸å—ï¼Ÿ
isinstance(data, str)   # dataæ˜¯å­—ç¬¦ä¸²å—ï¼Ÿ

# ä¸ºä»€ä¹ˆæ£€æŸ¥ç±»å‹ï¼Ÿ
# JSONå¯èƒ½æ˜¯ï¼š
# 1. åˆ—è¡¨ï¼š[{...}, {...}]ï¼ˆé¢„æœŸï¼‰
# 2. å­—å…¸ï¼š{...}ï¼ˆéé¢„æœŸï¼‰
# 3. å…¶ä»–ç±»å‹ï¼ˆéé¢„æœŸï¼‰

# dict.get()æ–¹æ³•
citation_key = item.get('citation_key')
# å¦‚æœ'citation_key'å­˜åœ¨ï¼šè¿”å›å€¼
# å¦‚æœä¸å­˜åœ¨ï¼šè¿”å›None

# get() vs []
# å®‰å…¨æ–¹å¼ï¼ˆæ¨èï¼‰ï¼š
key = item.get('citation_key')  # è¿”å›Noneï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰

# ä¸å®‰å…¨æ–¹å¼ï¼š
key = item['citation_key']  # KeyErrorï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰

# get()å¸¦é»˜è®¤å€¼
abstract = item.get('abstract', '')
# å¦‚æœ'abstract'ä¸å­˜åœ¨ï¼Œè¿”å›''ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰

# å»é‡å’Œæ›´æ–°é€»è¾‘
if citation_key not in unique_entries:
    # æ–°æ¡ç›®ï¼Œç›´æ¥æ·»åŠ 
    unique_entries[citation_key] = item
else:
    # å·²å­˜åœ¨ï¼Œæ¯”è¾ƒæ‘˜è¦é•¿åº¦
    old_abstract = unique_entries[citation_key].get('abstract', '')
    new_abstract = item.get('abstract', '')
    
    if len(new_abstract) > len(old_abstract):
        # æ–°æ‘˜è¦æ›´é•¿ï¼Œæ›´æ–°
        unique_entries[citation_key] = item

# ä¸ºä»€ä¹ˆä¿ç•™æ‘˜è¦æ›´é•¿çš„ï¼Ÿ
# æ‘˜è¦æ›´é•¿é€šå¸¸æ„å‘³ç€ä¿¡æ¯æ›´å®Œæ•´

# len()å‡½æ•°
len('Hello')         # 5ï¼ˆå­—ç¬¦æ•°ï¼‰
len([1, 2, 3])       # 3ï¼ˆå…ƒç´ æ•°ï¼‰
len({'a': 1, 'b': 2})  # 2ï¼ˆé”®å€¼å¯¹æ•°ï¼‰

# æ¡ä»¶è¡¨è¾¾å¼
if (condition1 or condition2):
    # condition1æˆ–condition2ä»»ä¸€ä¸ºTrue
    pass

# æœ¬ä¾‹ä¸­ï¼š
if (citation_key not in unique_entries or 
    len(new_abstract) > len(old_abstract)):
    # 1. æ–°æ¡ç›®ï¼ˆä¸åœ¨å­—å…¸ä¸­ï¼‰
    # æˆ–
    # 2. æ‘˜è¦æ›´é•¿
    # æ»¡è¶³ä»»ä¸€æ¡ä»¶å°±æ›´æ–°
```

### å¼‚å¸¸å¤„ç†ï¼ˆç¬¬58-62è¡Œï¼‰

```python
except json.JSONDecodeError as e:         # ç¬¬58è¡Œ
    print(f"é”™è¯¯: æ— æ³•è§£æJSONæ–‡ä»¶ {filename}")  # ç¬¬59è¡Œ
    print(f"  - é”™è¯¯ä¿¡æ¯: {str(e)}")        # ç¬¬60è¡Œ
except Exception as e:                    # ç¬¬61è¡Œ
    print(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")  # ç¬¬62è¡Œ
```

**å¼‚å¸¸å¤„ç†è¯¦è§£ï¼ˆç¬¬58-62è¡Œï¼‰**ï¼š

```python
except json.JSONDecodeError as e:
    print(f"é”™è¯¯: æ— æ³•è§£æJSONæ–‡ä»¶ {filename}")
    print(f"  - é”™è¯¯ä¿¡æ¯: {str(e)}")
except Exception as e:
    print(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")

# å¤šé‡å¼‚å¸¸å¤„ç†
# 1. ç‰¹å®šå¼‚å¸¸ï¼ˆjson.JSONDecodeErrorï¼‰
except json.JSONDecodeError as e:
    # ä¸“é—¨å¤„ç†JSONè§£æé”™è¯¯
    # ä¾‹å¦‚ï¼šæ ¼å¼é”™è¯¯ã€è¯­æ³•é”™è¯¯

# 2. é€šç”¨å¼‚å¸¸ï¼ˆExceptionï¼‰
except Exception as e:
    # æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸
    # ä¾‹å¦‚ï¼šæ–‡ä»¶è¯»å–é”™è¯¯ã€æƒé™é”™è¯¯

# as e
# å°†å¼‚å¸¸å¯¹è±¡èµ‹å€¼ç»™å˜é‡e
# å¯ä»¥è®¿é—®å¼‚å¸¸çš„è¯¦ç»†ä¿¡æ¯

# str(e)
# å°†å¼‚å¸¸å¯¹è±¡è½¬ä¸ºå­—ç¬¦ä¸²
# è·å–é”™è¯¯æ¶ˆæ¯

# å¼‚å¸¸ç±»å‹å±‚æ¬¡
"""
BaseException
â””â”€â”€ Exception
    â”œâ”€â”€ json.JSONDecodeError
    â”œâ”€â”€ IOError
    â”œâ”€â”€ ValueError
    â””â”€â”€ ...å…¶ä»–å¼‚å¸¸
"""

# ä¸ºä»€ä¹ˆå…ˆæ•è·JSONDecodeErrorï¼Ÿ
# 1. æ›´å…·ä½“çš„å¼‚å¸¸å…ˆå¤„ç†
# 2. æä¾›æ›´ç²¾ç¡®çš„é”™è¯¯ä¿¡æ¯
# 3. å¦‚æœå…ˆæ•è·Exceptionï¼ŒJSONDecodeErroræ°¸è¿œä¸ä¼šè¢«å•ç‹¬å¤„ç†

# é”™è¯¯çš„é¡ºåºï¼š
try:
    json.load(f)
except Exception as e:       # å…ˆæ•è·é€šç”¨å¼‚å¸¸
    print("é€šç”¨é”™è¯¯")
except json.JSONDecodeError:  # âœ— æ°¸è¿œä¸ä¼šæ‰§è¡Œï¼ˆå·²è¢«ä¸Šé¢æ•è·ï¼‰
    print("JSONé”™è¯¯")

# æ­£ç¡®çš„é¡ºåºï¼š
try:
    json.load(f)
except json.JSONDecodeError:  # âœ“ å…ˆæ•è·ç‰¹å®šå¼‚å¸¸
    print("JSONé”™è¯¯")
except Exception as e:        # å†æ•è·é€šç”¨å¼‚å¸¸
    print("é€šç”¨é”™è¯¯")

# å®é™…ç¤ºä¾‹
# JSONæ ¼å¼é”™è¯¯ï¼š
"""
{
    "name": "test"
    "age": 25  â† ç¼ºå°‘é€—å·
}
"""
# æŠ›å‡ºJSONDecodeError

# æ–‡ä»¶ä¸å­˜åœ¨ï¼š
# æŠ›å‡ºFileNotFoundErrorï¼ˆè¢«Exceptionæ•è·ï¼‰

# æƒé™é—®é¢˜ï¼š
# æŠ›å‡ºPermissionErrorï¼ˆè¢«Exceptionæ•è·ï¼‰
```

### å†™å…¥åˆå¹¶ç»“æœï¼ˆç¬¬64-78è¡Œï¼‰

```python
# å°†å”¯ä¸€æ¡ç›®è½¬æ¢ä¸ºåˆ—è¡¨                    # ç¬¬64è¡Œï¼ˆæ³¨é‡Šï¼‰
combined_data = list(unique_entries.values())  # ç¬¬65è¡Œ

# å°†åˆå¹¶åçš„æ•°æ®å†™å…¥è¾“å‡ºæ–‡ä»¶              # ç¬¬67è¡Œï¼ˆæ³¨é‡Šï¼‰
try:                                   # ç¬¬68è¡Œ
    with open(self.combined_json, 'w', encoding='utf-8') as f:  # ç¬¬69è¡Œ
        json.dump(combined_data, f, ensure_ascii=False, indent=2)  # ç¬¬70è¡Œ
    
    print(f"\nJSONæ–‡ä»¶åˆå¹¶å®Œæˆï¼")        # ç¬¬72è¡Œ
    print(f"æ€»å…±å¤„ç†äº† {len(combined_data)} ä¸ªå”¯ä¸€çš„æ–‡çŒ®æ¡ç›®")  # ç¬¬73è¡Œ
    print(f"åˆå¹¶ç»“æœä¿å­˜è‡³: {self.combined_json}")  # ç¬¬74è¡Œ
    return True                        # ç¬¬75è¡Œ
except Exception as e:                 # ç¬¬76è¡Œ
    print(f"å†™å…¥è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")  # ç¬¬77è¡Œ
    return False                       # ç¬¬78è¡Œ
```

**è¾“å‡ºå¤„ç†è¯¦è§£ï¼ˆç¬¬65-78è¡Œï¼‰**ï¼š

```python
combined_data = list(unique_entries.values())

# dict.values()æ–¹æ³•
# è¿”å›å­—å…¸çš„æ‰€æœ‰å€¼

# ç¤ºä¾‹
entries = {
    'key1': {'title': 'Paper 1'},
    'key2': {'title': 'Paper 2'}
}
values = entries.values()
# dict_values([{'title': 'Paper 1'}, {'title': 'Paper 2'}])

# list()è½¬æ¢ä¸ºåˆ—è¡¨
combined = list(values)
# [{'title': 'Paper 1'}, {'title': 'Paper 2'}]

# ä¸ºä»€ä¹ˆè½¬æ¢ä¸ºåˆ—è¡¨ï¼Ÿ
# 1. JSONéœ€è¦åˆ—è¡¨æ ¼å¼
# 2. dict_valuesä¸èƒ½ç›´æ¥åºåˆ—åŒ–ä¸ºJSON

# dictçš„å…¶ä»–æ–¹æ³•
entries.keys()    # æ‰€æœ‰é”®
entries.values()  # æ‰€æœ‰å€¼
entries.items()   # æ‰€æœ‰é”®å€¼å¯¹

# å†™å…¥JSONæ–‡ä»¶
with open(self.combined_json, 'w', encoding='utf-8') as f:
    json.dump(combined_data, f, ensure_ascii=False, indent=2)

# 'w'æ¨¡å¼
# å†™å…¥æ¨¡å¼ï¼ˆè¦†ç›–ç°æœ‰æ–‡ä»¶ï¼‰
# å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶

# json.dump()å‚æ•°
# 1. combined_dataï¼šè¦å†™å…¥çš„æ•°æ®
# 2. fï¼šæ–‡ä»¶å¯¹è±¡
# 3. ensure_ascii=Falseï¼šä¿ç•™ä¸­æ–‡
# 4. indent=2ï¼šç¼©è¿›2ä¸ªç©ºæ ¼

# è¾“å‡ºæ ¼å¼å¯¹æ¯”
# indent=Noneï¼ˆé»˜è®¤ï¼‰ï¼š
[{"title":"è®ºæ–‡1"},{"title":"è®ºæ–‡2"}]

# indent=2ï¼š
[
  {
    "title": "è®ºæ–‡1"
  },
  {
    "title": "è®ºæ–‡2"
  }
]

# \næ¢è¡Œç¬¦
print("\nJSONæ–‡ä»¶åˆå¹¶å®Œæˆï¼")
# è¾“å‡ºå‰å…ˆæ¢è¡Œ

print("è¡Œ1")
print("\nè¡Œ2")
# è¾“å‡ºï¼š
# è¡Œ1
# (ç©ºè¡Œ)
# è¡Œ2

# æˆåŠŸåé¦ˆ
print(f"æ€»å…±å¤„ç†äº† {len(combined_data)} ä¸ªå”¯ä¸€çš„æ–‡çŒ®æ¡ç›®")
# è¾“å‡ºï¼šæ€»å…±å¤„ç†äº† 25 ä¸ªå”¯ä¸€çš„æ–‡çŒ®æ¡ç›®

# è¿”å›Trueè¡¨ç¤ºæˆåŠŸ
return True

# å†™å…¥å¤±è´¥æ—¶è¿”å›False
except Exception as e:
    print(f"å†™å…¥è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    return False
```

---

## ğŸ“š BibTeXæ–‡ä»¶åˆå¹¶æ–¹æ³•

### æ–¹æ³•å®šä¹‰å’Œåˆå§‹åŒ–ï¼ˆç¬¬80-96è¡Œï¼‰

```python
def merge_bib_files(self) -> bool:         # ç¬¬80è¡Œ
    """åˆå¹¶BIBæ–‡ä»¶"""                       # ç¬¬81è¡Œ
    if not os.path.exists(self.bib_folder):  # ç¬¬82è¡Œ
        print(f"é”™è¯¯ï¼š{self.bib_folder} ç›®å½•ä¸å­˜åœ¨")  # ç¬¬83è¡Œ
        return False                       # ç¬¬84è¡Œ
        
    if not os.listdir(self.bib_folder):    # ç¬¬86è¡Œ
        print(f"é”™è¯¯ï¼š{self.bib_folder} ç›®å½•ä¸ºç©º")  # ç¬¬87è¡Œ
        return False                       # ç¬¬88è¡Œ
        
    # æ­£åˆ™è¡¨è¾¾å¼ç”¨äºæå–BibTeXæ¡ç›®çš„é”®    # ç¬¬90è¡Œï¼ˆæ³¨é‡Šï¼‰
    entry_pattern = re.compile(r'@\w+\{([^,]+),')  # ç¬¬91è¡Œ
    
    # å­˜å‚¨æ‰€æœ‰å·²å¤„ç†çš„BibTeXæ¡ç›®          # ç¬¬93è¡Œï¼ˆæ³¨é‡Šï¼‰
    unique_entries = {}                    # ç¬¬94è¡Œ
    
    print("\nå¼€å§‹åˆå¹¶BIBæ–‡ä»¶...")          # ç¬¬96è¡Œ
```

**BibTeXåˆå¹¶åˆå§‹åŒ–è¯¦è§£ï¼ˆç¬¬91è¡Œï¼‰**ï¼š

```python
entry_pattern = re.compile(r'@\w+\{([^,]+),')

# BibTeXæ¡ç›®æ ¼å¼
"""
@article{Zhang2024DeepLearning,
  title = {Deep Learning for Computer Vision},
  author = {Zhang, L. and Wang, H.},
  year = {2024},
  journal = {IEEE TPAMI}
}
"""

# æ­£åˆ™è¡¨è¾¾å¼è¯¦è§£
# r'@\w+\{([^,]+),'

# @        - å­—é¢åŒ¹é…@ç¬¦å·
# \w+      - 1ä¸ªæˆ–å¤šä¸ªå•è¯å­—ç¬¦
#           åŒ¹é…ï¼šarticleã€inproceedingsã€bookç­‰
# \{       - å­—é¢åŒ¹é…å·¦èŠ±æ‹¬å·{
# ([^,]+)  - æ•è·ç»„ï¼šåŒ¹é…1ä¸ªæˆ–å¤šä¸ªéé€—å·å­—ç¬¦
#           è¿™æ˜¯æ¡ç›®çš„é”®å
# ,        - å­—é¢åŒ¹é…é€—å·

# åŒ¹é…ç¤ºä¾‹
text = "@article{Zhang2024DeepLearning,"
match = entry_pattern.search(text)
if match:
    print(match.group(0))  # "@article{Zhang2024DeepLearning,"ï¼ˆå®Œæ•´åŒ¹é…ï¼‰
    print(match.group(1))  # "Zhang2024DeepLearning"ï¼ˆæ•è·ç»„1ï¼‰

# [^,]+è¯¦è§£
# [^...]  - å¦å®šå­—ç¬¦ç±»ï¼ŒåŒ¹é…ä¸åœ¨æ‹¬å·å†…çš„å­—ç¬¦
# [^,]    - åŒ¹é…ä»»ä½•éé€—å·å­—ç¬¦
# [^,]+   - 1ä¸ªæˆ–å¤šä¸ªéé€—å·å­—ç¬¦

# ç¤ºä¾‹
# [^,]+åŒ¹é…ï¼šZhang2024DeepLearning
# é‡åˆ°é€—å·åœæ­¢

# re.compile()
# ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
# ä¼˜åŠ¿ï¼šå¤šæ¬¡ä½¿ç”¨æ—¶æ›´å¿«

# ä¸ç¼–è¯‘ï¼ˆæ¯æ¬¡éƒ½è§£æï¼‰ï¼š
for entry in entries:
    match = re.search(r'pattern', entry)

# ç¼–è¯‘åï¼ˆåªè§£æä¸€æ¬¡ï¼‰ï¼š
pattern = re.compile(r'pattern')
for entry in entries:
    match = pattern.search(entry)  # æ›´å¿«
```

### è¯»å–å’Œåˆ†å‰²BibTeXæ–‡ä»¶ï¼ˆç¬¬98-121è¡Œï¼‰

```python
# éå†ç›®å½•ä¸‹çš„æ‰€æœ‰BIBæ–‡ä»¶               # ç¬¬98è¡Œï¼ˆæ³¨é‡Šï¼‰
for filename in os.listdir(self.bib_folder):  # ç¬¬99è¡Œ
    if filename.endswith('.bib'):         # ç¬¬100è¡Œ
        file_path = os.path.join(self.bib_folder, filename)  # ç¬¬101è¡Œ
        
        try:                              # ç¬¬103è¡Œ
            # è¯»å–BIBæ–‡ä»¶                  # ç¬¬104è¡Œï¼ˆæ³¨é‡Šï¼‰
            with open(file_path, 'r', encoding='utf-8') as f:  # ç¬¬105è¡Œ
                content = f.read()        # ç¬¬106è¡Œ
            
            # å°†æ–‡ä»¶å†…å®¹åˆ†å‰²æˆå•ç‹¬çš„æ¡ç›®    # ç¬¬108è¡Œï¼ˆæ³¨é‡Šï¼‰
            entries = []                  # ç¬¬109è¡Œ
            current_entry = ""            # ç¬¬110è¡Œ
            lines = content.split('\n')   # ç¬¬111è¡Œ
            for line in lines:            # ç¬¬112è¡Œ
                if line.strip().startswith('@') and current_entry:  # ç¬¬113è¡Œ
                    entries.append(current_entry)  # ç¬¬114è¡Œ
                    current_entry = line  # ç¬¬115è¡Œ
                else:                     # ç¬¬116è¡Œ
                    current_entry += line + '\n'  # ç¬¬117è¡Œ
            
            # æ·»åŠ æœ€åä¸€ä¸ªæ¡ç›®              # ç¬¬119è¡Œï¼ˆæ³¨é‡Šï¼‰
            if current_entry:             # ç¬¬120è¡Œ
                entries.append(current_entry)  # ç¬¬121è¡Œ
```

**BibTeXåˆ†å‰²è¯¦è§£ï¼ˆç¬¬106-121è¡Œï¼‰**ï¼š

```python
content = f.read()

# read()æ–¹æ³•
# è¯»å–æ•´ä¸ªæ–‡ä»¶å†…å®¹ä¸ºå­—ç¬¦ä¸²

# ç¤ºä¾‹æ–‡ä»¶å†…å®¹
"""
@article{Zhang2024,
  title = {Paper 1}
}

@inproceedings{Li2024,
  title = {Paper 2}
}
"""

# åˆ†å‰²é€»è¾‘
entries = []
current_entry = ""
lines = content.split('\n')

# split('\n')
# æŒ‰æ¢è¡Œç¬¦åˆ†å‰²å­—ç¬¦ä¸²
text = "line1\nline2\nline3"
lines = text.split('\n')
# ['line1', 'line2', 'line3']

# éå†æ¯ä¸€è¡Œ
for line in lines:
    if line.strip().startswith('@') and current_entry:
        # æ–°æ¡ç›®å¼€å§‹ï¼Œä¿å­˜å½“å‰æ¡ç›®
        entries.append(current_entry)
        current_entry = line
    else:
        # ç»§ç»­ç´¯ç§¯å½“å‰æ¡ç›®
        current_entry += line + '\n'

# line.strip()
# å»é™¤è¡Œé¦–è¡Œå°¾çš„ç©ºç™½å­—ç¬¦
'  @article  '.strip()  # '@article'

# startswith()
# æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä»¥æŒ‡å®šå‰ç¼€å¼€å§‹
'@article'.startswith('@')  # True
'title'.startswith('@')     # False

# åˆ†å‰²æµç¨‹ç¤ºä¾‹
"""
åŸå§‹å†…å®¹ï¼š
@article{Zhang2024,
  title = {Paper 1}
}
@inproceedings{Li2024,
  title = {Paper 2}
}

å¤„ç†è¿‡ç¨‹ï¼š
1. è¯»å–"@article{Zhang2024,"
   current_entry = "@article{Zhang2024,\n"

2. è¯»å–"  title = {Paper 1}"
   current_entry += "  title = {Paper 1}\n"

3. è¯»å–"}"
   current_entry += "}\n"

4. è¯»å–"@inproceedings{Li2024," â† æ–°æ¡ç›®ï¼
   entries.append(current_entry)  # ä¿å­˜article
   current_entry = "@inproceedings{Li2024,\n"

5. ç»§ç»­å¤„ç†...

6. æœ€åæ·»åŠ æœ€åä¸€ä¸ªæ¡ç›®
   if current_entry:
       entries.append(current_entry)
"""

# ä¸ºä»€ä¹ˆéœ€è¦åˆ†å‰²ï¼Ÿ
# BibTeXæ–‡ä»¶åŒ…å«å¤šä¸ªæ¡ç›®
# éœ€è¦å•ç‹¬å¤„ç†æ¯ä¸ªæ¡ç›®
# ä»¥ä¾¿å»é‡å’Œåˆå¹¶

# +=è¿ç®—ç¬¦
current_entry += line + '\n'
# ç­‰ä»·äºï¼š
current_entry = current_entry + line + '\n'

# å­—ç¬¦ä¸²ç´¯åŠ 
text = "Hello"
text += " "
text += "World"
# "Hello World"
```

### å¤„ç†å’Œå»é‡BibTeXæ¡ç›®ï¼ˆç¬¬123-142è¡Œï¼‰

```python
# è®¡æ•°                                  # ç¬¬123è¡Œï¼ˆæ³¨é‡Šï¼‰
total_entries = len(entries)          # ç¬¬124è¡Œ
unique_count = 0                      # ç¬¬125è¡Œ

# å¤„ç†æ¯ä¸ªæ¡ç›®                          # ç¬¬127è¡Œï¼ˆæ³¨é‡Šï¼‰
for entry in entries:                 # ç¬¬128è¡Œ
    # è·³è¿‡ç©ºæ¡ç›®                         # ç¬¬129è¡Œï¼ˆæ³¨é‡Šï¼‰
    if not entry.strip():             # ç¬¬130è¡Œ
        continue                      # ç¬¬131è¡Œ
        
    # æå–æ¡ç›®çš„é”®                       # ç¬¬133è¡Œï¼ˆæ³¨é‡Šï¼‰
    match = entry_pattern.search(entry)  # ç¬¬134è¡Œ
    if match:                         # ç¬¬135è¡Œ
        entry_key = match.group(1).strip()  # ç¬¬136è¡Œ
        
        # å¦‚æœè¿™ä¸ªé”®è¿˜æ²¡æœ‰è¢«å¤„ç†ï¼Œæ·»åŠ åˆ°å”¯ä¸€æ¡ç›®å­—å…¸  # ç¬¬138è¡Œï¼ˆæ³¨é‡Šï¼‰
        if entry_key not in unique_entries:  # ç¬¬139è¡Œ
            unique_entries[entry_key] = entry  # ç¬¬140è¡Œ
            unique_count += 1         # ç¬¬141è¡Œ
```

**BibTeXå»é‡è¯¦è§£ï¼ˆç¬¬128-141è¡Œï¼‰**ï¼š

```python
for entry in entries:
    if not entry.strip():
        continue
    
    match = entry_pattern.search(entry)
    if match:
        entry_key = match.group(1).strip()
        
        if entry_key not in unique_entries:
            unique_entries[entry_key] = entry

# è·³è¿‡ç©ºæ¡ç›®
if not entry.strip():
    continue

# continueè¯­å¥
# è·³è¿‡æœ¬æ¬¡å¾ªç¯ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡

# ç¤ºä¾‹
for i in range(5):
    if i == 2:
        continue  # è·³è¿‡2
    print(i)
# è¾“å‡ºï¼š0, 1, 3, 4

# æå–æ¡ç›®é”®
match = entry_pattern.search(entry)
# åœ¨entryä¸­æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å¼

# entryç¤ºä¾‹ï¼š
"""
@article{Zhang2024DeepLearning,
  title = {Deep Learning},
  ...
}
"""

# åŒ¹é…ç»“æœï¼š
if match:
    entry_key = match.group(1).strip()
    # "Zhang2024DeepLearning"

# match.group(1)
# è·å–ç¬¬ä¸€ä¸ªæ•è·ç»„çš„å†…å®¹
# å³()ä¸­åŒ¹é…çš„éƒ¨åˆ†

# strip()
# å»é™¤ç©ºç™½å­—ç¬¦
'  Zhang2024  '.strip()  # 'Zhang2024'

# å»é‡é€»è¾‘
if entry_key not in unique_entries:
    # æ–°æ¡ç›®ï¼Œæ·»åŠ 
    unique_entries[entry_key] = entry
else:
    # å·²å­˜åœ¨ï¼Œè·³è¿‡ï¼ˆä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„ï¼‰

# ä¸ºä»€ä¹ˆä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„ï¼Ÿ
# BibTeXåˆå¹¶ç›¸å¯¹ç®€å•
# JSONåˆå¹¶ä¼šæ¯”è¾ƒæ‘˜è¦é•¿åº¦
# BibTeXç›´æ¥å»é‡

# unique_entrieså­—å…¸
unique_entries = {
    'Zhang2024DeepLearning': '@article{Zhang2024DeepLearning,\n...',
    'Li2024NLP': '@inproceedings{Li2024NLP,\n...',
    ...
}

# ç»Ÿè®¡
unique_count += 1
# æ¯æ·»åŠ ä¸€ä¸ªæ–°æ¡ç›®ï¼Œè®¡æ•°å™¨+1
```

### å†™å…¥åˆå¹¶çš„BibTeXæ–‡ä»¶ï¼ˆç¬¬147-162è¡Œï¼‰

```python
# å°†æ‰€æœ‰å”¯ä¸€æ¡ç›®å†™å…¥è¾“å‡ºæ–‡ä»¶            # ç¬¬147è¡Œï¼ˆæ³¨é‡Šï¼‰
try:                                  # ç¬¬148è¡Œ
    with open(self.combined_bib, 'w', encoding='utf-8') as f:  # ç¬¬149è¡Œ
        for entry in unique_entries.values():  # ç¬¬150è¡Œ
            f.write(entry)            # ç¬¬151è¡Œ
            # ç¡®ä¿æ¯ä¸ªæ¡ç›®ä¹‹é—´æœ‰è¶³å¤Ÿçš„ç©ºè¡Œ  # ç¬¬152è¡Œï¼ˆæ³¨é‡Šï¼‰
            if not entry.endswith('\n\n'):  # ç¬¬153è¡Œ
                f.write('\n\n')       # ç¬¬154è¡Œ
    
    print(f"\nBIBæ–‡ä»¶åˆå¹¶å®Œæˆï¼")       # ç¬¬156è¡Œ
    print(f"æ€»å…±å¤„ç†äº† {len(unique_entries)} ä¸ªå”¯ä¸€çš„BibTeXæ¡ç›®")  # ç¬¬157è¡Œ
    print(f"åˆå¹¶ç»“æœä¿å­˜è‡³: {self.combined_bib}")  # ç¬¬158è¡Œ
    return True                       # ç¬¬159è¡Œ
except Exception as e:                # ç¬¬160è¡Œ
    print(f"å†™å…¥è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")  # ç¬¬161è¡Œ
    return False                      # ç¬¬162è¡Œ
```

**BibTeXå†™å…¥è¯¦è§£ï¼ˆç¬¬149-154è¡Œï¼‰**ï¼š

```python
with open(self.combined_bib, 'w', encoding='utf-8') as f:
    for entry in unique_entries.values():
        f.write(entry)
        if not entry.endswith('\n\n'):
            f.write('\n\n')

# éå†æ‰€æœ‰æ¡ç›®
for entry in unique_entries.values():
    # å†™å…¥æ¡ç›®
    f.write(entry)

# f.write()
# å†™å…¥å­—ç¬¦ä¸²åˆ°æ–‡ä»¶
f.write("Hello\n")
f.write("World\n")
# æ–‡ä»¶å†…å®¹ï¼š
# Hello
# World

# ç¡®ä¿æ¡ç›®é—´æœ‰ç©ºè¡Œ
if not entry.endswith('\n\n'):
    f.write('\n\n')

# endswith()
# æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä»¥æŒ‡å®šåç¼€ç»“æŸ
'text\n\n'.endswith('\n\n')  # True
'text\n'.endswith('\n\n')    # False

# ä¸ºä»€ä¹ˆéœ€è¦ç©ºè¡Œï¼Ÿ
# BibTeXæ ¼å¼è¦æ±‚æ¡ç›®ä¹‹é—´æœ‰ç©ºè¡Œ
# æé«˜å¯è¯»æ€§

# è¾“å‡ºæ ¼å¼ç¤ºä¾‹
"""
@article{Zhang2024,
  title = {Paper 1}
}

@inproceedings{Li2024,
  title = {Paper 2}
}

@book{Wang2024,
  title = {Book 1}
}
"""

# å¦‚æœæ²¡æœ‰ç©ºè¡Œï¼š
"""
@article{Zhang2024,
  title = {Paper 1}
}
@inproceedings{Li2024,
  title = {Paper 2}
}
"""
# ä¸å¤Ÿæ¸…æ™°

# write() vs print()
# write()ï¼šå†™å…¥æ–‡ä»¶
f.write("text")

# print()ï¼šè¾“å‡ºåˆ°æ§åˆ¶å°
print("text")

# print()ä¹Ÿå¯ä»¥å†™å…¥æ–‡ä»¶
print("text", file=f)
```

---

## ğŸ”„ ç»Ÿä¸€åˆå¹¶æ–¹æ³•

### merge_all_resultsæ–¹æ³•ï¼ˆç¬¬164-184è¡Œï¼‰

```python
def merge_all_results(self) -> bool:      # ç¬¬164è¡Œ
    """åˆå¹¶æ‰€æœ‰ç»“æœæ–‡ä»¶"""                 # ç¬¬165è¡Œ
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨                    # ç¬¬166è¡Œï¼ˆæ³¨é‡Šï¼‰
    if not os.path.exists(self.json_folder) or not os.path.exists(self.bib_folder):  # ç¬¬167è¡Œ
        print("\né”™è¯¯ï¼šç»“æœç›®å½•ä¸å®Œæ•´")    # ç¬¬168è¡Œ
        print(f"JSONç›®å½• ({self.json_folder}) å­˜åœ¨: {os.path.exists(self.json_folder)}")  # ç¬¬169è¡Œ
        print(f"BIBç›®å½• ({self.bib_folder}) å­˜åœ¨: {os.path.exists(self.bib_folder)}")  # ç¬¬170è¡Œ
        return False                      # ç¬¬171è¡Œ
        
    # æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º                    # ç¬¬173è¡Œï¼ˆæ³¨é‡Šï¼‰
    if not os.listdir(self.json_folder) or not os.listdir(self.bib_folder):  # ç¬¬174è¡Œ
        print("\né”™è¯¯ï¼šç»“æœç›®å½•ä¸ºç©º")      # ç¬¬175è¡Œ
        print(f"JSONç›®å½• ({self.json_folder}) ä¸ºç©º: {not os.listdir(self.json_folder)}")  # ç¬¬176è¡Œ
        print(f"BIBç›®å½• ({self.bib_folder}) ä¸ºç©º: {not os.listdir(self.bib_folder)}")  # ç¬¬177è¡Œ
        return False                      # ç¬¬178è¡Œ
        
    # åˆå¹¶æ–‡ä»¶                           # ç¬¬180è¡Œï¼ˆæ³¨é‡Šï¼‰
    json_success = self.merge_json_files()  # ç¬¬181è¡Œ
    bib_success = self.merge_bib_files()    # ç¬¬182è¡Œ
    
    return json_success and bib_success  # ç¬¬184è¡Œ
```

**ç»Ÿä¸€åˆå¹¶æ–¹æ³•è¯¦è§£ï¼ˆç¬¬164-184è¡Œï¼‰**ï¼š

```python
def merge_all_results(self) -> bool:
    # æ£€æŸ¥ç›®å½•
    if not os.path.exists(self.json_folder) or not os.path.exists(self.bib_folder):
        print("\né”™è¯¯ï¼šç»“æœç›®å½•ä¸å®Œæ•´")
        return False
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
    if not os.listdir(self.json_folder) or not os.listdir(self.bib_folder):
        print("\né”™è¯¯ï¼šç»“æœç›®å½•ä¸ºç©º")
        return False
    
    # åˆå¹¶æ–‡ä»¶
    json_success = self.merge_json_files()
    bib_success = self.merge_bib_files()
    
    return json_success and bib_success

# é€»è¾‘æˆ–è¿ç®—ç¬¦ or
if not exists(folder1) or not exists(folder2):
    # folder1ä¸å­˜åœ¨ æˆ– folder2ä¸å­˜åœ¨
    # ä»»ä¸€æ¡ä»¶ä¸ºTrueï¼Œæ•´ä¸ªè¡¨è¾¾å¼ä¸ºTrue

# ç¤ºä¾‹
False or False  # False
False or True   # True
True or False   # True
True or True    # True

# é€»è¾‘ä¸è¿ç®—ç¬¦ and
if not empty(folder1) or not empty(folder2):
    # folder1ä¸ºç©º æˆ– folder2ä¸ºç©º
    pass

# è¿”å›å€¼ç»„åˆ
json_success = True
bib_success = True
result = json_success and bib_success  # True

json_success = True
bib_success = False
result = json_success and bib_success  # False

# andè¿ç®—ç¬¦
# ä¸¤è€…éƒ½ä¸ºTrueï¼Œç»“æœæ‰ä¸ºTrue
True and True    # True
True and False   # False
False and True   # False
False and False  # False

# ä¸ºä»€ä¹ˆç”¨andï¼Ÿ
# åªæœ‰JSONå’ŒBibTeXéƒ½æˆåŠŸåˆå¹¶
# æ•´ä¸ªæ“ä½œæ‰ç®—æˆåŠŸ

# çŸ­è·¯æ±‚å€¼
# andï¼šç¬¬ä¸€ä¸ªä¸ºFalseï¼Œä¸å†è®¡ç®—ç¬¬äºŒä¸ª
# orï¼šç¬¬ä¸€ä¸ªä¸ºTrueï¼Œä¸å†è®¡ç®—ç¬¬äºŒä¸ª

# ç¤ºä¾‹
def expensive_check():
    print("æ‰§è¡Œå¤æ‚æ£€æŸ¥")
    return True

# çŸ­è·¯ç¤ºä¾‹
result = False and expensive_check()
# expensive_check()ä¸ä¼šè¢«è°ƒç”¨
# å› ä¸ºFalse and ... å¿…å®šä¸ºFalse

result = True or expensive_check()
# expensive_check()ä¸ä¼šè¢«è°ƒç”¨
# å› ä¸ºTrue or ... å¿…å®šä¸ºTrue

# ä½¿ç”¨ç¤ºä¾‹
merger = ResultMerger(
    json_folder='json_results',
    bib_folder='bib_results',
    combined_json='references.json',
    combined_bib='references.bib'
)

# åˆå¹¶æ‰€æœ‰ç»“æœ
success = merger.merge_all_results()
if success:
    print("æ‰€æœ‰æ–‡ä»¶åˆå¹¶æˆåŠŸ")
else:
    print("åˆå¹¶å¤±è´¥")

# è¾“å‡ºç¤ºä¾‹
"""
å¼€å§‹åˆå¹¶JSONæ–‡ä»¶...

JSONæ–‡ä»¶åˆå¹¶å®Œæˆï¼
æ€»å…±å¤„ç†äº† 25 ä¸ªå”¯ä¸€çš„æ–‡çŒ®æ¡ç›®
åˆå¹¶ç»“æœä¿å­˜è‡³: references.json

å¼€å§‹åˆå¹¶BIBæ–‡ä»¶...

BIBæ–‡ä»¶åˆå¹¶å®Œæˆï¼
æ€»å…±å¤„ç†äº† 25 ä¸ªå”¯ä¸€çš„BibTeXæ¡ç›®
åˆå¹¶ç»“æœä¿å­˜è‡³: references.bib
"""
```

---

## ğŸ¯ æŠ€æœ¯æ€»ç»“

### æ ¸å¿ƒæŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç”¨é€” | å…³é”®ä»£ç  |
|------|------|---------|
| **å­—å…¸å»é‡** | è‡ªåŠ¨å»é‡ | `unique_entries[key] = value` |
| **æ­£åˆ™è¡¨è¾¾å¼** | æå–BibTeXé”® | `re.compile(r'@\w+\{([^,]+),')` |
| **æ–‡ä»¶æ“ä½œ** | è¯»å†™æ–‡ä»¶ | `os.listdir()`, `open()` |
| **JSONå¤„ç†** | åºåˆ—åŒ– | `json.load()`, `json.dump()` |
| **å¼‚å¸¸å¤„ç†** | é”™è¯¯ç®¡ç† | `try-except-finally` |

### æ ¸å¿ƒç®—æ³•

#### JSONå»é‡ç®—æ³•

```python
unique_entries = {}  # å­—å…¸å­˜å‚¨

for file in json_files:
    data = json.load(file)
    for item in data:
        key = item.get('citation_key')
        
        # å¦‚æœä¸å­˜åœ¨æˆ–æ‘˜è¦æ›´é•¿ï¼Œåˆ™æ›´æ–°
        if (key not in unique_entries or
            len(item.get('abstract', '')) > len(unique_entries[key].get('abstract', ''))):
            unique_entries[key] = item

# è½¬æ¢ä¸ºåˆ—è¡¨è¾“å‡º
result = list(unique_entries.values())
```

#### BibTeXå»é‡ç®—æ³•

```python
unique_entries = {}  # å­—å…¸å­˜å‚¨
pattern = re.compile(r'@\w+\{([^,]+),')

for file in bib_files:
    content = read_file(file)
    entries = split_entries(content)  # åˆ†å‰²æ¡ç›®
    
    for entry in entries:
        match = pattern.search(entry)
        if match:
            key = match.group(1)
            # ä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„
            if key not in unique_entries:
                unique_entries[key] = entry

# å†™å…¥æ–‡ä»¶
for entry in unique_entries.values():
    write(entry)
```

### è®¾è®¡æ¨¡å¼

1. **é˜²å¾¡æ€§ç¼–ç¨‹**: è¾“å…¥éªŒè¯
   ```python
   if not os.path.exists(folder):
       return False
   ```

2. **å­—å…¸å»é‡**: åˆ©ç”¨é”®çš„å”¯ä¸€æ€§
   ```python
   unique_entries[key] = value
   ```

3. **æ™ºèƒ½é€‰æ‹©**: ä¿ç•™æœ€ä¼˜ç‰ˆæœ¬
   ```python
   if len(new_abstract) > len(old_abstract):
       update()
   ```

4. **å¼‚å¸¸éš”ç¦»**: å•ä¸ªæ–‡ä»¶å¤±è´¥ä¸å½±å“æ•´ä½“
   ```python
   try:
       process_file()
   except Exception:
       continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
   ```

### æœ€ä½³å®è·µ

1. âœ… **ç±»å‹æç¤º**: ä½¿ç”¨`-> bool`ç­‰
2. âœ… **è¾“å…¥éªŒè¯**: æ£€æŸ¥ç›®å½•å­˜åœ¨å’Œéç©º
3. âœ… **å¼‚å¸¸å¤„ç†**: try-exceptæ•è·é”™è¯¯
4. âœ… **ç¼–ç æŒ‡å®š**: `encoding='utf-8'`
5. âœ… **å­—å…¸å»é‡**: O(1)æ—¶é—´å¤æ‚åº¦
6. âœ… **ç”¨æˆ·åé¦ˆ**: æ¸…æ™°çš„è¿›åº¦å’Œç»“æœæç¤º
7. âœ… **æ–‡ä»¶æ ¼å¼**: JSONç¾åŒ–è¾“å‡ºï¼ˆindent=2ï¼‰

### å­¦ä¹ ä»·å€¼

è¿™ä¸ªåˆå¹¶å™¨å±•ç¤ºäº†ï¼š
- ğŸ“ **æ–‡ä»¶æ‰¹å¤„ç†**: éå†ç›®å½•å’Œå¤„ç†å¤šä¸ªæ–‡ä»¶
- ğŸ” **æ­£åˆ™è¡¨è¾¾å¼**: æå–ç»“æ„åŒ–æ–‡æœ¬ä¿¡æ¯
- ğŸ“Š **æ•°æ®å»é‡**: å­—å…¸çš„é«˜æ•ˆåº”ç”¨
- ğŸ›¡ï¸ **å¥å£®æ€§**: å®Œå–„çš„é”™è¯¯å¤„ç†
- ğŸ“ **æ ¼å¼åŒ–è¾“å‡º**: JSONå’ŒBibTeXæ ¼å¼å¤„ç†

### ä½¿ç”¨åœºæ™¯

| åœºæ™¯ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| **åªåˆå¹¶JSON** | `merge_json_files()` | å•ç‹¬åˆå¹¶JSON |
| **åªåˆå¹¶BibTeX** | `merge_bib_files()` | å•ç‹¬åˆå¹¶BibTeX |
| **åˆå¹¶æ‰€æœ‰** | `merge_all_results()` | åŒæ—¶åˆå¹¶ä¸¤ç§æ ¼å¼ |

### å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºåˆå¹¶å™¨
merger = ResultMerger(
    json_folder='json_results',
    bib_folder='bib_results',
    combined_json='references.json',
    combined_bib='references.bib'
)

# æ–¹å¼1ï¼šåˆå¹¶æ‰€æœ‰ç»“æœ
success = merger.merge_all_results()

# æ–¹å¼2ï¼šå•ç‹¬åˆå¹¶
json_ok = merger.merge_json_files()
bib_ok = merger.merge_bib_files()

# æ£€æŸ¥ç»“æœ
if success:
    print("åˆå¹¶æˆåŠŸï¼")
    # è¾“å‡ºæ–‡ä»¶ï¼š
    # - references.json
    # - references.bib
```

**å®Œæ•´çš„æ–‡ä»¶åˆå¹¶è§£å†³æ–¹æ¡ˆ**ï¼ğŸš€


