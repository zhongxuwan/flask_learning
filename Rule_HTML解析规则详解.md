# Rule HTMLè§£æè§„åˆ™è¯¦è§£

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [å¯¼å…¥è¯­å¥è¯¦è§£](#å¯¼å…¥è¯­å¥è¯¦è§£)
3. [å…¨å±€å¸¸é‡å®šä¹‰](#å…¨å±€å¸¸é‡å®šä¹‰)
4. [Ruleç±»æ¶æ„](#ruleç±»æ¶æ„)
5. [å…­å¤§å‡ºç‰ˆå•†è§£æè§„åˆ™](#å…­å¤§å‡ºç‰ˆå•†è§£æè§„åˆ™)
6. [æŠ€æœ¯æ€»ç»“](#æŠ€æœ¯æ€»ç»“)

---

## ğŸ“– é¡¹ç›®æ¦‚è¿°

`Rule.py` æ˜¯**å­¦æœ¯è®ºæ–‡æ‘˜è¦æå–è§„åˆ™æ¨¡å—**ï¼Œå®šä¹‰äº†é’ˆå¯¹ä¸åŒå­¦æœ¯å‡ºç‰ˆå•†ç½‘ç«™çš„HTMLè§£æè§„åˆ™ï¼Œç”¨äºä»å„ç§å¤æ‚çš„ç½‘é¡µç»“æ„ä¸­æå–è®ºæ–‡æ‘˜è¦ã€‚

### ä¸»è¦åŠŸèƒ½

- ğŸ” **å¤šå‡ºç‰ˆå•†æ”¯æŒ**: æ”¯æŒ6ä¸ªä¸»æµå­¦æœ¯å‡ºç‰ˆå•†ï¼ˆIEEEã€ACMã€arXivã€Springerã€Elsevierã€RFC Editorï¼‰
- ğŸ›¡ï¸ **å®¹é”™æœºåˆ¶**: å¤šå±‚é€‰æ‹©å™¨å°è¯•ï¼Œæé«˜è§£ææˆåŠŸç‡
- ğŸ”„ **é‡è¯•ç­–ç•¥**: HTTPè¯·æ±‚è‡ªåŠ¨é‡è¯•æœºåˆ¶
- ğŸ§¹ **æ–‡æœ¬æ¸…ç†**: è‡ªåŠ¨æ¸…ç†æ— ç”¨å…ƒç´ å’Œæ ¼å¼åŒ–æ–‡æœ¬
- ğŸ“Š **å¤šç§æ•°æ®æº**: æ”¯æŒHTMLå…ƒç´ ã€Metaæ ‡ç­¾ã€JSON-LDæ•°æ®

### æ ¸å¿ƒè®¾è®¡æ€æƒ³

1. **ä¼˜å…ˆçº§é€‰æ‹©å™¨**ï¼šæŒ‰ä¼˜å…ˆçº§å°è¯•å¤šä¸ªCSSé€‰æ‹©å™¨
2. **å®¹é”™å¤„ç†**ï¼šæ¯ä¸ªè§„åˆ™éƒ½æœ‰å®Œæ•´çš„å¼‚å¸¸å¤„ç†
3. **æ–‡æœ¬æ¸…ç†**ï¼šè‡ªåŠ¨ç§»é™¤æ— ç”¨å…ƒç´ å’Œæ ¼å¼åŒ–
4. **æ•°æ®æ¥æºå¤šæ ·**ï¼šHTML + Meta + JSON-LD
5. **è´¨é‡éªŒè¯**ï¼šé•¿åº¦æ£€æŸ¥ç¡®ä¿æå–å†…å®¹æœ‰æ•ˆ

### æ–‡ä»¶ç»Ÿè®¡

- **æ€»è¡Œæ•°**: 404è¡Œ
- **å¯¼å…¥æ¨¡å—**: 10ä¸ª
- **ç±»æ•°é‡**: 1ä¸ªï¼ˆRuleç±»ï¼‰
- **æ–¹æ³•æ•°é‡**: 9ä¸ªï¼ˆ2ä¸ªå·¥å…·æ–¹æ³• + 1ä¸ªé€šç”¨æå– + 6ä¸ªå‡ºç‰ˆå•†è§„åˆ™ï¼‰
- **æ”¯æŒå‡ºç‰ˆå•†**: 6ä¸ª

### ç³»ç»Ÿæ¶æ„å›¾

```mermaid
graph TB
    A[HTMLæºç ] --> B{Ruleç±»}
    
    B --> C[_create_session]
    B --> D[_safe_extract]
    
    B --> E[ieee_rule]
    B --> F[acm_rule]
    B --> G[arxiv_rule]
    B --> H[springer_rule]
    B --> I[elsevier_rule]
    B --> J[rfc_editor_rule]
    
    E --> K[CSSé€‰æ‹©å™¨1]
    E --> L[CSSé€‰æ‹©å™¨2]
    E --> M[CSSé€‰æ‹©å™¨N]
    E --> N[JSON-LDæ•°æ®]
    
    K --> O{æ‰¾åˆ°å…ƒç´ ?}
    O -->|æ˜¯| P[æå–æ–‡æœ¬]
    O -->|å¦| L
    
    P --> Q{é•¿åº¦>50?}
    Q -->|æ˜¯| R[è¿”å›æ‘˜è¦]
    Q -->|å¦| L
    
    L --> S{è¿˜æœ‰é€‰æ‹©å™¨?}
    S -->|æ˜¯| M
    S -->|å¦| N
    
    N --> T{æ‰¾åˆ°æ•°æ®?}
    T -->|æ˜¯| R
    T -->|å¦| U[è¿”å›None]
```

---

## ğŸ“¦ å¯¼å…¥è¯­å¥è¯¦è§£ï¼ˆç¬¬1-10è¡Œï¼‰

```python
from typing import Optional, Callable, Dict, List, Union  # ç¬¬1è¡Œ
from dataclasses import dataclass                        # ç¬¬2è¡Œ
from bs4 import BeautifulSoup                            # ç¬¬3è¡Œ
import requests                                          # ç¬¬4è¡Œ
from requests.adapters import HTTPAdapter                # ç¬¬5è¡Œ
from urllib3.util.retry import Retry                     # ç¬¬6è¡Œ
import random                                            # ç¬¬7è¡Œ
import time                                              # ç¬¬8è¡Œ
import json                                              # ç¬¬9è¡Œ
import re                                                # ç¬¬10è¡Œ
```

### ç¬¬1è¡Œï¼štypingç±»å‹æ³¨è§£ â­â­â­â­â­

```python
from typing import Optional, Callable, Dict, List, Union

# typingæ¨¡å—è¯¦è§£
# åŠŸèƒ½ï¼šæä¾›ç±»å‹æç¤ºï¼ˆType Hintsï¼‰æ”¯æŒ

# ä¸ºä»€ä¹ˆä½¿ç”¨ç±»å‹æ³¨è§£ï¼Ÿ
# 1. ä»£ç å¯è¯»æ€§ï¼šä¸€çœ¼çœ‹å‡ºå‚æ•°å’Œè¿”å›å€¼ç±»å‹
# 2. IDEæ”¯æŒï¼šè‡ªåŠ¨è¡¥å…¨å’Œç±»å‹æ£€æŸ¥
# 3. é™æ€åˆ†æï¼šmypyç­‰å·¥å…·å¯ä»¥æ£€æŸ¥ç±»å‹é”™è¯¯
# 4. æ–‡æ¡£ä½œç”¨ï¼šç±»å‹å³æ–‡æ¡£

# Optionalè¯¦è§£ â­â­â­â­â­
# åŠŸèƒ½ï¼šè¡¨ç¤ºå€¼å¯ä»¥æ˜¯æŒ‡å®šç±»å‹æˆ–None

# å®šä¹‰ï¼š
Optional[str]  # ç­‰ä»·äº Union[str, None]

# ä½¿ç”¨ç¤ºä¾‹ï¼š
def get_abstract(html: str) -> Optional[str]:
    if html:
        return "æ‘˜è¦å†…å®¹"
    return None  # å¯ä»¥è¿”å›None

# ä¸ä½¿ç”¨Optionalï¼ˆä¸æ¨èï¼‰ï¼š
def get_abstract(html: str) -> str:
    if html:
        return "æ‘˜è¦å†…å®¹"
    return None  # ç±»å‹é”™è¯¯ï¼strä¸èƒ½æ˜¯None

# Callableè¯¦è§£ â­â­â­â­
# åŠŸèƒ½ï¼šè¡¨ç¤ºå¯è°ƒç”¨å¯¹è±¡ï¼ˆå‡½æ•°ï¼‰

# è¯­æ³•ï¼š
Callable[[å‚æ•°ç±»å‹], è¿”å›å€¼ç±»å‹]

# ç¤ºä¾‹ï¼š
def process(callback: Callable[[str], int]):
    result = callback("hello")
    return result

def my_callback(text: str) -> int:
    return len(text)

process(my_callback)  # æ­£ç¡®

# Dictè¯¦è§£ â­â­â­â­â­
# åŠŸèƒ½ï¼šè¡¨ç¤ºå­—å…¸ç±»å‹

# è¯­æ³•ï¼š
Dict[é”®ç±»å‹, å€¼ç±»å‹]

# ç¤ºä¾‹ï¼š
headers: Dict[str, str] = {
    "Accept": "text/html",
    "User-Agent": "Mozilla/5.0"
}

# å¤æ‚å­—å…¸ï¼š
config: Dict[str, Union[str, int, List[str]]] = {
    "name": "test",
    "port": 8080,
    "hosts": ["host1", "host2"]
}

# Listè¯¦è§£ â­â­â­â­â­
# åŠŸèƒ½ï¼šè¡¨ç¤ºåˆ—è¡¨ç±»å‹

# è¯­æ³•ï¼š
List[å…ƒç´ ç±»å‹]

# ç¤ºä¾‹ï¼š
names: List[str] = ["Alice", "Bob", "Charlie"]
numbers: List[int] = [1, 2, 3, 4, 5]

# åµŒå¥—åˆ—è¡¨ï¼š
matrix: List[List[int]] = [
    [1, 2, 3],
    [4, 5, 6]
]

# Unionè¯¦è§£ â­â­â­â­
# åŠŸèƒ½ï¼šè¡¨ç¤ºå¤šç§å¯èƒ½çš„ç±»å‹ä¹‹ä¸€

# è¯­æ³•ï¼š
Union[ç±»å‹1, ç±»å‹2, ...]

# ç¤ºä¾‹ï¼š
def process(value: Union[str, int]) -> str:
    if isinstance(value, str):
        return value.upper()
    else:
        return str(value)

process("hello")  # "HELLO"
process(123)      # "123"

# æœ¬é¡¹ç›®ä¸­çš„ä½¿ç”¨ï¼š
def ieee_rule(cls, html: str) -> Optional[str]:
    # å‚æ•°ï¼šhtmlæ˜¯å­—ç¬¦ä¸²
    # è¿”å›ï¼šå­—ç¬¦ä¸²æˆ–None
    pass
```

### ç¬¬2è¡Œï¼šdataclassè£…é¥°å™¨ â­â­â­â­â­

```python
from dataclasses import dataclass

# dataclassè¯¦è§£
# åŠŸèƒ½ï¼šè‡ªåŠ¨ç”Ÿæˆç±»çš„ç‰¹æ®Šæ–¹æ³•

# ä¸ä½¿ç”¨dataclassï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰ï¼š
class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age
    
    def __repr__(self):
        return f"Person(name={self.name}, age={self.age})"
    
    def __eq__(self, other):
        return self.name == other.name and self.age == other.age

# ä½¿ç”¨dataclassï¼ˆæ¨èï¼‰ï¼š
from dataclasses import dataclass

@dataclass
class Person:
    name: str
    age: int

# è‡ªåŠ¨ç”Ÿæˆï¼š
# - __init__æ–¹æ³•
# - __repr__æ–¹æ³•
# - __eq__æ–¹æ³•
# - ç­‰ç­‰

# ä½¿ç”¨ï¼š
person = Person(name="Alice", age=30)
print(person)  # Person(name='Alice', age=30)

# dataclasså‚æ•°ï¼š
@dataclass(
    frozen=True,    # ä¸å¯å˜ï¼ˆç±»ä¼¼namedtupleï¼‰
    order=True      # è‡ªåŠ¨ç”Ÿæˆæ¯”è¾ƒæ–¹æ³•
)
class Point:
    x: int
    y: int

# frozen=Trueç¤ºä¾‹ï¼š
point = Point(1, 2)
# point.x = 3  # é”™è¯¯ï¼frozenå¯¹è±¡ä¸å¯ä¿®æ”¹

# order=Trueç¤ºä¾‹ï¼š
p1 = Point(1, 2)
p2 = Point(3, 4)
print(p1 < p2)  # Trueï¼ˆè‡ªåŠ¨æ¯”è¾ƒï¼‰

# æœ¬é¡¹ç›®ä¸­çš„ä½¿ç”¨ï¼š
@dataclass
class Rule:
    # ä½¿ç”¨dataclasså®šä¹‰Ruleç±»
    # è™½ç„¶è¿™é‡Œä¸»è¦ç”¨äºç»„ç»‡é™æ€æ–¹æ³•
    pass
```

### ç¬¬3è¡Œï¼šBeautifulSoup HTMLè§£æ â­â­â­â­â­

```python
from bs4 import BeautifulSoup

# BeautifulSoupè¯¦è§£
# åŠŸèƒ½ï¼šHTML/XMLè§£æåº“ï¼Œæœ€æµè¡Œçš„ç½‘é¡µè§£æå·¥å…·

# å®‰è£…ï¼š
# pip install beautifulsoup4
# pip install lxml  # æ¨èçš„è§£æå™¨

# åŸºæœ¬ä½¿ç”¨ï¼š
from bs4 import BeautifulSoup

html = """
<html>
    <head><title>æµ‹è¯•é¡µé¢</title></head>
    <body>
        <div class="abstract">
            <p>è¿™æ˜¯æ‘˜è¦å†…å®¹</p>
        </div>
    </body>
</html>
"""

soup = BeautifulSoup(html, 'lxml')

# æŸ¥æ‰¾å…ƒç´ çš„æ–¹æ³•ï¼š

# 1. find()ï¼šæŸ¥æ‰¾ç¬¬ä¸€ä¸ªåŒ¹é…å…ƒç´ 
element = soup.find('div', class_='abstract')
# <div class="abstract">...</div>

# 2. find_all()ï¼šæŸ¥æ‰¾æ‰€æœ‰åŒ¹é…å…ƒç´ 
paragraphs = soup.find_all('p')
# [<p>è¿™æ˜¯æ‘˜è¦å†…å®¹</p>]

# 3. select_one()ï¼šCSSé€‰æ‹©å™¨ï¼ˆå•ä¸ªï¼‰â­æ¨è
element = soup.select_one('div.abstract')
# <div class="abstract">...</div>

# 4. select()ï¼šCSSé€‰æ‹©å™¨ï¼ˆå¤šä¸ªï¼‰â­æ¨è
elements = soup.select('div.abstract p')
# [<p>è¿™æ˜¯æ‘˜è¦å†…å®¹</p>]

# CSSé€‰æ‹©å™¨è¯­æ³•ï¼š

# ç±»é€‰æ‹©å™¨ï¼š
soup.select_one('.abstract')        # class="abstract"
soup.select_one('div.abstract')     # <div class="abstract">

# IDé€‰æ‹©å™¨ï¼š
soup.select_one('#main')            # id="main"
soup.select_one('div#main')         # <div id="main">

# å±æ€§é€‰æ‹©å™¨ï¼š
soup.select_one('[name="description"]')           # nameå±æ€§
soup.select_one('meta[name="description"]')       # metaæ ‡ç­¾çš„nameå±æ€§
soup.select_one('div[class*="abstract"]')         # classåŒ…å«"abstract"
soup.select_one('meta[property="og:description"]') # propertyå±æ€§

# å±‚çº§é€‰æ‹©å™¨ï¼š
soup.select_one('div > p')          # ç›´æ¥å­å…ƒç´ 
soup.select_one('div p')            # æ‰€æœ‰åä»£å…ƒç´ 
soup.select_one('div.abstract p')   # åµŒå¥—é€‰æ‹©

# æå–æ•°æ®ï¼š

# 1. è·å–æ–‡æœ¬
element = soup.select_one('div.abstract')
text = element.text          # æ‰€æœ‰æ–‡æœ¬ï¼ˆåŒ…æ‹¬å­å…ƒç´ ï¼‰
text = element.get_text()    # åŒä¸Šï¼Œå¯ä»¥æŒ‡å®šåˆ†éš”ç¬¦

# 2. è·å–å±æ€§
meta = soup.select_one('meta[name="description"]')
content = meta.get('content')        # è·å–contentå±æ€§
content = meta['content']            # åŒä¸Šï¼ˆå­—å…¸æ–¹å¼ï¼‰

# 3. æ£€æŸ¥å±æ€§å­˜åœ¨
if meta.has_attr('content'):
    content = meta['content']

# ä¿®æ”¹å’Œåˆ é™¤ï¼š

# 1. åˆ é™¤å…ƒç´ 
for script in soup.find_all('script'):
    script.decompose()  # ä»æ ‘ä¸­åˆ é™¤

# 2. æå–å…ƒç´ ï¼ˆåˆ é™¤å¹¶è¿”å›ï¼‰
element = soup.find('div').extract()

# æœ¬é¡¹ç›®ä¸­çš„å…¸å‹ä½¿ç”¨ï¼š
soup = BeautifulSoup(html, 'lxml')

# å°è¯•å¤šä¸ªé€‰æ‹©å™¨
selectors = [
    'meta[name="description"]',
    'div.abstract',
    '#abstract'
]

for selector in selectors:
    element = soup.select_one(selector)
    if element:
        if element.name == 'meta':
            abstract = element.get('content', '').strip()
        else:
            # ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ 
            for unwanted in element.find_all(['script', 'style']):
                unwanted.decompose()
            abstract = element.get_text().strip()
        
        if abstract and len(abstract) > 50:
            return abstract
```

### ç¬¬4-6è¡Œï¼šHTTPè¯·æ±‚åº“ â­â­â­â­â­

```python
import requests                                    # ç¬¬4è¡Œ
from requests.adapters import HTTPAdapter          # ç¬¬5è¡Œ
from urllib3.util.retry import Retry               # ç¬¬6è¡Œ

# requestsåº“è¯¦è§£
# åŠŸèƒ½ï¼šPythonæœ€æµè¡Œçš„HTTPå®¢æˆ·ç«¯åº“

# åŸºæœ¬ä½¿ç”¨ï¼š
import requests

# GETè¯·æ±‚
response = requests.get('https://www.example.com')
html = response.text
status_code = response.status_code

# POSTè¯·æ±‚
response = requests.post('https://api.example.com', 
    json={'key': 'value'},
    headers={'Content-Type': 'application/json'}
)

# è¯·æ±‚å¤´
headers = {
    'User-Agent': 'Mozilla/5.0',
    'Accept': 'text/html'
}
response = requests.get(url, headers=headers)

# Sessionä½¿ç”¨ï¼ˆä¿æŒè¿æ¥ï¼‰
session = requests.Session()
session.headers.update({'User-Agent': 'MyBot'})
response = session.get(url1)
response = session.get(url2)  # å¤ç”¨è¿æ¥

# HTTPAdapterè¯¦è§£ â­â­â­â­
# åŠŸèƒ½ï¼šè‡ªå®šä¹‰ä¼ è¾“é€‚é…å™¨

# ä½œç”¨ï¼š
# 1. è®¾ç½®è¿æ¥æ± å¤§å°
# 2. é…ç½®é‡è¯•ç­–ç•¥
# 3. è®¾ç½®è¶…æ—¶

# Retryè¯¦è§£ â­â­â­â­â­
# åŠŸèƒ½ï¼šè‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚

# å®Œæ•´ç¤ºä¾‹ï¼š
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import requests

# åˆ›å»ºé‡è¯•ç­–ç•¥
retry_strategy = Retry(
    total=3,                    # æ€»å…±é‡è¯•3æ¬¡
    backoff_factor=0.5,         # é‡è¯•é—´éš”ï¼š0.5s, 1s, 2s
    status_forcelist=[429, 500, 502, 503, 504],  # è¿™äº›çŠ¶æ€ç æ‰é‡è¯•
    allowed_methods=["GET"]     # åªå¯¹GETè¯·æ±‚é‡è¯•
)

# åˆ›å»ºé€‚é…å™¨
adapter = HTTPAdapter(max_retries=retry_strategy)

# åˆ›å»ºä¼šè¯å¹¶æŒ‚è½½é€‚é…å™¨
session = requests.Session()
session.mount("https://", adapter)  # å¯¹httpsè¯·æ±‚ä½¿ç”¨æ­¤é€‚é…å™¨
session.mount("http://", adapter)   # å¯¹httpè¯·æ±‚ä½¿ç”¨æ­¤é€‚é…å™¨

# ä½¿ç”¨ä¼šè¯å‘é€è¯·æ±‚
response = session.get('https://example.com')

# é‡è¯•å‚æ•°è¯¦è§£ï¼š

# totalï¼šæœ€å¤§é‡è¯•æ¬¡æ•°
# ç¤ºä¾‹ï¼štotal=3ï¼Œå¤±è´¥åæœ€å¤šå†å°è¯•3æ¬¡

# backoff_factorï¼šé‡è¯•å»¶è¿Ÿå› å­
# è®¡ç®—å…¬å¼ï¼š{backoff_factor} * (2 ** (é‡è¯•æ¬¡æ•° - 1))
# backoff_factor=0.5ï¼š
# - ç¬¬1æ¬¡é‡è¯•ï¼š0.5 * 2^0 = 0.5ç§’
# - ç¬¬2æ¬¡é‡è¯•ï¼š0.5 * 2^1 = 1ç§’
# - ç¬¬3æ¬¡é‡è¯•ï¼š0.5 * 2^2 = 2ç§’

# status_forcelistï¼šéœ€è¦é‡è¯•çš„HTTPçŠ¶æ€ç 
# 429ï¼šToo Many Requestsï¼ˆè¯·æ±‚è¿‡å¤šï¼‰
# 500ï¼šInternal Server Errorï¼ˆæœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼‰
# 502ï¼šBad Gatewayï¼ˆç½‘å…³é”™è¯¯ï¼‰
# 503ï¼šService Unavailableï¼ˆæœåŠ¡ä¸å¯ç”¨ï¼‰
# 504ï¼šGateway Timeoutï¼ˆç½‘å…³è¶…æ—¶ï¼‰

# allowed_methodsï¼šå…è®¸é‡è¯•çš„HTTPæ–¹æ³•
# ["GET"]ï¼šåªé‡è¯•GETè¯·æ±‚
# ["GET", "POST"]ï¼šGETå’ŒPOSTéƒ½é‡è¯•

# æœ¬é¡¹ç›®ä¸­çš„ä½¿ç”¨ï¼š
RETRY_STRATEGY = Retry(
    total=3,
    backoff_factor=0.5,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods=["GET"]
)

@staticmethod
def _create_session() -> requests.Session:
    session = requests.Session()
    session.mount("https://", HTTPAdapter(max_retries=Rule.RETRY_STRATEGY))
    return session

# ä½¿ç”¨ï¼š
session = Rule._create_session()
response = session.get(url)
# å¦‚æœå¤±è´¥ï¼Œè‡ªåŠ¨é‡è¯•æœ€å¤š3æ¬¡
```

### ç¬¬7-10è¡Œï¼šå…¶ä»–å·¥å…·åº“

```python
import random     # ç¬¬7è¡Œ
import time       # ç¬¬8è¡Œ
import json       # ç¬¬9è¡Œ
import re         # ç¬¬10è¡Œ

# randomæ¨¡å—
# ç”¨é€”ï¼šéšæœºæ•°ç”Ÿæˆ
# æœ¬é¡¹ç›®ä¸­å¯èƒ½ç”¨äºï¼š
# - éšæœºå»¶è¿Ÿ
# - éšæœºé€‰æ‹©User-Agent

import random
random.randint(1, 5)      # 1åˆ°5çš„éšæœºæ•´æ•°
random.choice(['a', 'b']) # éšæœºé€‰æ‹©

# timeæ¨¡å—
# ç”¨é€”ï¼šæ—¶é—´å¤„ç†
# æœ¬é¡¹ç›®ä¸­å¯èƒ½ç”¨äºï¼š
# - è¯·æ±‚å»¶è¿Ÿ
time.sleep(1)  # æš‚åœ1ç§’

# jsonæ¨¡å—
# ç”¨é€”ï¼šJSONæ•°æ®å¤„ç†
# æœ¬é¡¹ç›®ä¸­ç”¨äºï¼š
# - è§£æJSON-LDæ•°æ®
data = json.loads(script.string)

# reæ¨¡å—ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰â­â­â­â­â­
# ç”¨é€”ï¼šæ–‡æœ¬æ¨¡å¼åŒ¹é…

# åŸºæœ¬ä½¿ç”¨ï¼š
import re

# 1. re.sub()ï¼šæ›¿æ¢
text = "Abstract: This is the abstract."
text = re.sub(r'^abstract\s*:?\s*', '', text, flags=re.IGNORECASE)
# "This is the abstract."

# å‚æ•°è¯¦è§£ï¼š
# r'^abstract\s*:?\s*'ï¼šæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
# ''ï¼šæ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
# textï¼šè¦å¤„ç†çš„æ–‡æœ¬
# flags=re.IGNORECASEï¼šå¿½ç•¥å¤§å°å†™

# æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•ï¼š
# ^ï¼šå­—ç¬¦ä¸²å¼€å¤´
# abstractï¼šåŒ¹é…"abstract"
# \s*ï¼š0ä¸ªæˆ–å¤šä¸ªç©ºç™½å­—ç¬¦
# :?ï¼š0ä¸ªæˆ–1ä¸ªå†’å·
# \s*ï¼š0ä¸ªæˆ–å¤šä¸ªç©ºç™½å­—ç¬¦

# ç¤ºä¾‹ï¼š
text1 = "Abstract: content"
text2 = "abstract content"
text3 = "ABSTRACT:content"
# éƒ½ä¼šè¢«æ›¿æ¢ä¸ºï¼š"content"

# re.IGNORECASEæ ‡å¿—ï¼š
# å¿½ç•¥å¤§å°å†™åŒ¹é…
re.sub('abstract', '', 'Abstract')  # 'Abstract'ï¼ˆä¸åŒ¹é…ï¼‰
re.sub('abstract', '', 'Abstract', flags=re.IGNORECASE)  # ''ï¼ˆåŒ¹é…ï¼‰

# å…¶ä»–å¸¸ç”¨reæ–¹æ³•ï¼š
re.match(r'pattern', text)   # ä»å¼€å¤´åŒ¹é…
re.search(r'pattern', text)  # æœç´¢åŒ¹é…
re.findall(r'pattern', text) # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…
```

---

## ğŸŒ å…¨å±€å¸¸é‡å®šä¹‰ï¼ˆç¬¬12-19è¡Œï¼‰

```python
# å…¬å…±è¯·æ±‚å¤´æ¨¡æ¿                              # ç¬¬12è¡Œï¼ˆæ³¨é‡Šï¼‰
HEADER_TEMPLATE: Dict[str, str] = {         # ç¬¬13è¡Œ
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",  # ç¬¬14è¡Œ
    "Accept-Language": "en-US,en;q=0.9",    # ç¬¬15è¡Œ
    "Accept-Encoding": "gzip, deflate, br"  # ç¬¬16è¡Œ
}

CCF_RANKS = {"A", "B", "C", "E", "P"}       # ç¬¬19è¡Œ
```

**å…¨å±€å¸¸é‡è¯¦è§£**ï¼š

```python
# HEADER_TEMPLATEè¯¦è§£ â­â­â­â­â­
# ç±»å‹ï¼šDict[str, str]
# ä½œç”¨ï¼šHTTPè¯·æ±‚å¤´æ¨¡æ¿

HEADER_TEMPLATE: Dict[str, str] = {
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.9",
    "Accept-Encoding": "gzip, deflate, br"
}

# HTTPè¯·æ±‚å¤´è¯¦è§£ï¼š

# 1. Acceptå¤´
# ä½œç”¨ï¼šå‘Šè¯‰æœåŠ¡å™¨å®¢æˆ·ç«¯èƒ½æ¥å—çš„å†…å®¹ç±»å‹
"Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"

# åˆ†è§£ï¼š
# - text/htmlï¼šHTMLæ–‡æ¡£
# - application/xhtml+xmlï¼šXHTMLæ–‡æ¡£
# - application/xml;q=0.9ï¼šXMLæ–‡æ¡£ï¼ˆè´¨é‡å› å­0.9ï¼‰
# - */*;q=0.8ï¼šä»»ä½•ç±»å‹ï¼ˆè´¨é‡å› å­0.8ï¼‰

# qå€¼ï¼ˆè´¨é‡å› å­ï¼‰ï¼š
# èŒƒå›´ï¼š0.0 - 1.0
# è¡¨ç¤ºä¼˜å…ˆçº§
# q=1.0ï¼ˆé»˜è®¤ï¼‰ï¼šæœ€é«˜ä¼˜å…ˆçº§
# q=0.9ï¼šæ¬¡ä¼˜å…ˆçº§
# q=0.8ï¼šæ›´ä½ä¼˜å…ˆçº§

# æœåŠ¡å™¨ä¼šé€‰æ‹©æœ€åŒ¹é…ä¸”è´¨é‡å› å­æœ€é«˜çš„æ ¼å¼è¿”å›

# 2. Accept-Languageå¤´
# ä½œç”¨ï¼šå‘Šè¯‰æœåŠ¡å™¨å®¢æˆ·ç«¯çš„è¯­è¨€åå¥½
"Accept-Language": "en-US,en;q=0.9"

# åˆ†è§£ï¼š
# - en-USï¼šç¾å¼è‹±è¯­ï¼ˆä¼˜å…ˆï¼‰
# - en;q=0.9ï¼šè‹±è¯­ï¼ˆæ¬¡ä¼˜å…ˆï¼‰

# 3. Accept-Encodingå¤´
# ä½œç”¨ï¼šå‘Šè¯‰æœåŠ¡å™¨æ”¯æŒçš„å‹ç¼©ç®—æ³•
"Accept-Encoding": "gzip, deflate, br"

# å‹ç¼©ç®—æ³•ï¼š
# - gzipï¼šæœ€å¸¸ç”¨çš„å‹ç¼©
# - deflateï¼šå¦ä¸€ç§å‹ç¼©
# - brï¼šBrotliå‹ç¼©ï¼ˆæ›´é«˜æ•ˆï¼‰

# ä¸ºä»€ä¹ˆéœ€è¦è¯·æ±‚å¤´ï¼Ÿ
# 1. æ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸º
# 2. é¿å…è¢«æœåŠ¡å™¨æ‹’ç»
# 3. è·å¾—æ­£ç¡®æ ¼å¼çš„å“åº”
# 4. æé«˜è¯·æ±‚æˆåŠŸç‡

# ä½¿ç”¨ç¤ºä¾‹ï¼š
headers = HEADER_TEMPLATE.copy()
headers['User-Agent'] = 'Mozilla/5.0...'
response = requests.get(url, headers=headers)

# CCF_RANKSè¯¦è§£
# ç±»å‹ï¼šé›†åˆï¼ˆsetï¼‰
# ä½œç”¨ï¼šCCFä¼šè®®/æœŸåˆŠç­‰çº§

CCF_RANKS = {"A", "B", "C", "E", "P"}

# CCFåˆ†çº§ï¼š
# Aï¼šé¡¶çº§ä¼šè®®/æœŸåˆŠ
# Bï¼šä¼˜ç§€ä¼šè®®/æœŸåˆŠ
# Cï¼šæ™®é€šä¼šè®®/æœŸåˆŠ
# Eï¼šå…¶ä»–
# Pï¼šï¼ˆå¯èƒ½è¡¨ç¤ºPendingæˆ–å…¶ä»–ï¼‰

# set vs listï¼š
# setï¼š
# - æ— åº
# - ä¸å…è®¸é‡å¤
# - æˆå‘˜æ£€æŸ¥å¿«é€Ÿï¼ˆO(1)ï¼‰

# listï¼š
# - æœ‰åº
# - å…è®¸é‡å¤
# - æˆå‘˜æ£€æŸ¥æ…¢ï¼ˆO(n)ï¼‰

# æ£€æŸ¥æˆå‘˜ï¼š
if "A" in CCF_RANKS:  # éå¸¸å¿«
    print("æ˜¯CCF-Açº§")

# ä¸ºä»€ä¹ˆç”¨setï¼Ÿ
# å¿«é€Ÿæ£€æŸ¥æŸä¸ªç­‰çº§æ˜¯å¦æœ‰æ•ˆ
```

---

ç»§ç»­åˆ›å»ºRuleç±»çš„è¯¦ç»†è®²è§£éƒ¨åˆ†...

