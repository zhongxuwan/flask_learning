# Main æ–‡çŒ®æœç´¢ç³»ç»Ÿè¯¦è§£

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [å¯¼å…¥è¯­å¥è¯¦è§£](#å¯¼å…¥è¯­å¥è¯¦è§£)
3. [å…¨å±€å¸¸é‡å®šä¹‰](#å…¨å±€å¸¸é‡å®šä¹‰)
4. [BibManagerç±»è¯¦è§£](#bibmanagerç±»è¯¦è§£)
5. [CCFMapperç±»è¯¦è§£](#ccfmapperç±»è¯¦è§£)
6. [PublicationSearcherç±»è¯¦è§£](#publicationsearcherç±»è¯¦è§£)
7. [æŠ€æœ¯æ€»ç»“](#æŠ€æœ¯æ€»ç»“)

---

## ğŸ“– é¡¹ç›®æ¦‚è¿°

`Main.py` æ˜¯ä¸€ä¸ª**å­¦æœ¯æ–‡çŒ®æœç´¢å’Œç®¡ç†ç³»ç»Ÿ**çš„æ ¸å¿ƒæ¨¡å—ï¼Œè´Ÿè´£ä»DBLPæœç´¢æ–‡çŒ®ã€è·å–æ‘˜è¦ã€CCFåˆ†çº§å’ŒBibTeXç”Ÿæˆã€‚

### ä¸»è¦åŠŸèƒ½

- ğŸ” **æ–‡çŒ®æœç´¢**: ä»DBLP APIæœç´¢å­¦æœ¯å‡ºç‰ˆç‰©
- ğŸ“š **BibTeXç®¡ç†**: è·å–å’Œå¤„ç†BibTeXå¼•ç”¨æ ¼å¼
- ğŸ“„ **æ‘˜è¦è·å–**: ä»å¤šä¸ªæ¥æºæ™ºèƒ½è·å–è®ºæ–‡æ‘˜è¦
- ğŸ† **CCFåˆ†çº§**: è‡ªåŠ¨æ ‡æ³¨ä¼šè®®/æœŸåˆŠçš„CCFç­‰çº§
- ğŸ’¾ **ç»“æœå­˜å‚¨**: JSONå’ŒBibTeXæ ¼å¼ä¿å­˜
- âš¡ **å¹¶å‘å¤„ç†**: å¤šçº¿ç¨‹åŠ é€Ÿå¤„ç†
- ğŸ”„ **é‡è¯•æœºåˆ¶**: ç½‘ç»œè¯·æ±‚å¤±è´¥è‡ªåŠ¨é‡è¯•

### æ ¸å¿ƒç±»

| ç±»å | åŠŸèƒ½ | å…³é”®æ–¹æ³• |
|------|------|---------|
| **BibManager** | BibTeXç®¡ç† | `save_bib_entry()` |
| **CCFMapper** | CCFç­‰çº§æ˜ å°„ | `get_ccf_rank()` |
| **PublicationSearcher** | æ–‡çŒ®æœç´¢ | `search_publications()` |

### æ–‡ä»¶ç»Ÿè®¡

- **æ€»è¡Œæ•°**: 1475è¡Œ
- **å¯¼å…¥æ¨¡å—**: 12ä¸ª
- **ç±»æ•°é‡**: 3ä¸ª
- **ä¸»è¦æ–¹æ³•**: 30+ä¸ª

---

## ğŸ“¦ å¯¼å…¥è¯­å¥è¯¦è§£

### æ ‡å‡†åº“å¯¼å…¥ï¼ˆç¬¬1-12è¡Œï¼‰

```python
import re                                  # ç¬¬1è¡Œ
import json                                # ç¬¬2è¡Œ
import os                                  # ç¬¬3è¡Œ
import sys                                 # ç¬¬4è¡Œ
from collections import defaultdict        # ç¬¬5è¡Œ
from typing import Dict, List, Optional, Tuple  # ç¬¬6è¡Œ
import requests                            # ç¬¬7è¡Œ
from requests.adapters import HTTPAdapter  # ç¬¬8è¡Œ
from urllib3.util.retry import Retry       # ç¬¬9è¡Œ
from datetime import datetime              # ç¬¬10è¡Œ
import concurrent.futures                  # ç¬¬11è¡Œ
from functools import partial              # ç¬¬12è¡Œ
```

**ç¬¬1è¡Œè¯¦è§£**ï¼š`import re`

```python
import re

# reæ¨¡å—åœ¨æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# 1. åŒ¹é…BibTeXé”®å
pattern = r'@(\w+)\{'

# 2. æå–æœŸåˆŠç¼©å†™
abbreviation = re.search(r'journal\s*=\s*{([^}]+)}', bib_entry)

# 3. æ¸…ç†æ–‡æœ¬
cleaned = re.sub(r'\s+', ' ', text)

# æ­£åˆ™è¡¨è¾¾å¼æ˜¯æ–‡æœ¬å¤„ç†çš„æ ¸å¿ƒå·¥å…·
# åœ¨å­¦æœ¯æ–‡çŒ®å¤„ç†ä¸­å¹¿æ³›åº”ç”¨
```

**ç¬¬5è¡Œè¯¦è§£**ï¼š`from collections import defaultdict`

**defaultdictè¯¦è§£ï¼ˆç¬¬5è¡Œï¼‰**ï¼š
- `collections.defaultdict`ï¼šå¸¦é»˜è®¤å€¼çš„å­—å…¸
- ç”¨é€”ï¼šè‡ªåŠ¨åˆå§‹åŒ–ä¸å­˜åœ¨çš„é”®

```python
from collections import defaultdict

# defaultdictæ˜¯ä»€ä¹ˆï¼Ÿ
# ä¸€ç§ç‰¹æ®Šçš„å­—å…¸ï¼Œè®¿é—®ä¸å­˜åœ¨çš„é”®æ—¶è‡ªåŠ¨åˆ›å»ºé»˜è®¤å€¼

# æ™®é€šå­—å…¸çš„é—®é¢˜
normal_dict = {}
normal_dict['key1'] += 1  # âœ— KeyError: 'key1'

# éœ€è¦å…ˆæ£€æŸ¥
if 'key1' not in normal_dict:
    normal_dict['key1'] = 0
normal_dict['key1'] += 1  # âœ“ æ­£ç¡®

# defaultdictçš„ä¼˜åŠ¿
from collections import defaultdict

# åˆ›å»ºdefaultdictï¼ˆé»˜è®¤å€¼ä¸ºintï¼Œå³0ï¼‰
counter = defaultdict(int)
counter['key1'] += 1  # âœ“ è‡ªåŠ¨åˆ›å»ºå¹¶è®¾ä¸º0ï¼Œç„¶å+1
print(counter['key1'])  # 1

# defaultdictçš„é»˜è®¤å€¼å·¥å‚
# 1. int - é»˜è®¤0
counter = defaultdict(int)
print(counter['new_key'])  # 0

# 2. list - é»˜è®¤[]
groups = defaultdict(list)
groups['A'].append(1)
groups['A'].append(2)
print(groups['A'])  # [1, 2]

# 3. set - é»˜è®¤set()
tags = defaultdict(set)
tags['python'].add('programming')
tags['python'].add('web')
print(tags['python'])  # {'programming', 'web'}

# 4. lambda - è‡ªå®šä¹‰é»˜è®¤å€¼
data = defaultdict(lambda: "æœªçŸ¥")
print(data['name'])  # "æœªçŸ¥"

# æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# æŒ‰CCFç­‰çº§åˆ†ç»„æ–‡çŒ®
ccf_groups = defaultdict(list)
ccf_groups['A'].append(paper1)
ccf_groups['B'].append(paper2)

# ç»Ÿè®¡å…³é”®è¯å‡ºç°æ¬¡æ•°
keyword_count = defaultdict(int)
for keyword in keywords:
    keyword_count[keyword] += 1

# defaultdict vs æ™®é€šdict
# æ™®é€šdictï¼š
stats = {}
for item in data:
    key = item['category']
    if key not in stats:
        stats[key] = []
    stats[key].append(item)

# defaultdictï¼š
stats = defaultdict(list)
for item in data:
    stats[item['category']].append(item)

# è½¬æ¢ä¸ºæ™®é€šdict
normal_dict = dict(defaultdict_obj)
```

**ç¬¬6è¡Œè¯¦è§£**ï¼š`from typing import Dict, List, Optional, Tuple`

**ç±»å‹æç¤ºè¯¦è§£ï¼ˆç¬¬6è¡Œï¼‰**ï¼š
- `typing`ï¼šPythonç±»å‹æç¤ºæ¨¡å—
- ç”¨é€”ï¼šä»£ç å¯è¯»æ€§å’ŒIDEæ”¯æŒ

```python
from typing import Dict, List, Optional, Tuple

# ç±»å‹æç¤ºï¼ˆType Hintsï¼‰æ˜¯ä»€ä¹ˆï¼Ÿ
# Python 3.5+å¼•å…¥çš„ç‰¹æ€§
# ç”¨äºæ ‡æ³¨å˜é‡ã€å‚æ•°ã€è¿”å›å€¼çš„ç±»å‹

# åŸºæœ¬ç±»å‹æç¤º
def greet(name: str) -> str:
    return f"Hello, {name}"

# ç±»å‹æç¤ºçš„å¥½å¤„ï¼š
# 1. æé«˜ä»£ç å¯è¯»æ€§
# 2. IDEè‡ªåŠ¨å®Œæˆå’Œé”™è¯¯æ£€æŸ¥
# 3. é™æ€ç±»å‹æ£€æŸ¥å·¥å…·ï¼ˆmypyï¼‰
# 4. æ–‡æ¡£ä½œç”¨

# typingæ¨¡å—çš„å¸¸ç”¨ç±»å‹
# 1. List - åˆ—è¡¨ç±»å‹
from typing import List

def process_papers(papers: List[dict]) -> List[str]:
    """
    å‚æ•°papersæ˜¯å­—å…¸åˆ—è¡¨
    è¿”å›å€¼æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
    """
    return [p['title'] for p in papers]

# 2. Dict - å­—å…¸ç±»å‹
from typing import Dict

def count_words(text: str) -> Dict[str, int]:
    """
    è¿”å›å­—å…¸ï¼šé”®æ˜¯å­—ç¬¦ä¸²ï¼Œå€¼æ˜¯æ•´æ•°
    """
    words = text.split()
    return {word: words.count(word) for word in set(words)}

# 3. Optional - å¯é€‰ç±»å‹ï¼ˆå¯èƒ½æ˜¯Noneï¼‰
from typing import Optional

def find_user(user_id: int) -> Optional[dict]:
    """
    è¿”å›å€¼å¯èƒ½æ˜¯dictï¼Œä¹Ÿå¯èƒ½æ˜¯None
    """
    user = database.get(user_id)
    return user  # å¯èƒ½è¿”å›None

# Optional[T] ç­‰ä»·äº Union[T, None]
from typing import Union
def find_user(user_id: int) -> Union[dict, None]:
    pass

# 4. Tuple - å…ƒç»„ç±»å‹
from typing import Tuple

def get_coordinates() -> Tuple[float, float]:
    """
    è¿”å›(x, y)åæ ‡
    """
    return (3.14, 2.71)

def get_name_and_age() -> Tuple[str, int]:
    """
    è¿”å›(åå­—, å¹´é¾„)
    """
    return ("Alice", 25)

# å›ºå®šé•¿åº¦å…ƒç»„
coords: Tuple[int, int] = (10, 20)

# å¯å˜é•¿åº¦å…ƒç»„
numbers: Tuple[int, ...] = (1, 2, 3, 4, 5)

# å¤åˆç±»å‹æç¤º
# 1. å­—å…¸çš„åˆ—è¡¨
papers: List[Dict[str, str]] = [
    {'title': 'Paper 1', 'author': 'Alice'},
    {'title': 'Paper 2', 'author': 'Bob'}
]

# 2. å¯é€‰çš„å­—å…¸åˆ—è¡¨
results: Optional[List[dict]] = None

# 3. è¿”å›å¤šä¸ªå€¼
def process_bib(url: str) -> Tuple[str, str, str]:
    """
    è¿”å›(bibæ¡ç›®, æ‘˜è¦, DOI)
    """
    return bib_entry, abstract, doi

# æœ¬é¡¹ç›®ä¸­çš„å®é™…åº”ç”¨
class BibManager:
    def save_bib_entry(
        self, 
        url: str,           # å‚æ•°ç±»å‹ï¼šå­—ç¬¦ä¸²
        ee: str,            # å‚æ•°ç±»å‹ï¼šå­—ç¬¦ä¸²
        title: str,         # å‚æ•°ç±»å‹ï¼šå­—ç¬¦ä¸²
        info: dict = None   # å‚æ•°ç±»å‹ï¼šå­—å…¸ï¼Œé»˜è®¤None
    ) -> Tuple[str, str, str]:  # è¿”å›ç±»å‹ï¼šä¸‰ä¸ªå­—ç¬¦ä¸²çš„å…ƒç»„
        """è·å–Bibæ¡ç›®ä¿¡æ¯"""
        # ...
        return bib_entry, abstract, doi

# æ›´å¤æ‚çš„ç±»å‹æç¤º
from typing import Callable, Any

# Callable - å¯è°ƒç”¨å¯¹è±¡ï¼ˆå‡½æ•°ï¼‰
def execute(func: Callable[[int, int], int]) -> int:
    """
    funcæ˜¯ä¸€ä¸ªå‡½æ•°ï¼šæ¥å—ä¸¤ä¸ªintï¼Œè¿”å›int
    """
    return func(10, 20)

# Any - ä»»æ„ç±»å‹
def process(data: Any) -> str:
    return str(data)

# æ³›å‹ç±»å‹
from typing import TypeVar, Generic

T = TypeVar('T')

def get_first(items: List[T]) -> Optional[T]:
    """
    è·å–åˆ—è¡¨ç¬¬ä¸€ä¸ªå…ƒç´ 
    ä¿æŒç±»å‹ä¸€è‡´
    """
    return items[0] if items else None

# ç±»å‹æç¤ºä¸å½±å“è¿è¡Œæ—¶
# åªæ˜¯æç¤ºï¼Œä¸å¼ºåˆ¶æ£€æŸ¥
def add(a: int, b: int) -> int:
    return a + b

result = add("hello", "world")  # è¿è¡Œæ—¶ä¸æŠ¥é”™ï¼
# ä½†IDEä¼šæç¤ºç±»å‹é”™è¯¯

# ä½¿ç”¨mypyè¿›è¡Œç±»å‹æ£€æŸ¥
# $ pip install mypy
# $ mypy Main.py
# ä¼šæ£€æŸ¥ç±»å‹æ˜¯å¦åŒ¹é…

# ç±»å‹åˆ«å
from typing import Dict, List

# å®šä¹‰ç±»å‹åˆ«å
PaperInfo = Dict[str, str]
PaperList = List[PaperInfo]

def filter_papers(papers: PaperList) -> PaperList:
    """æ›´æ˜“è¯»çš„ç±»å‹æç¤º"""
    return [p for p in papers if p.get('year') == '2024']
```

**ç¬¬7-9è¡Œè¯¦è§£**ï¼šHTTPè¯·æ±‚åº“

```python
import requests                            # ç¬¬7è¡Œ
from requests.adapters import HTTPAdapter  # ç¬¬8è¡Œ
from urllib3.util.retry import Retry       # ç¬¬9è¡Œ

# requestsåº“è¯¦è§£
# Pythonæœ€æµè¡Œçš„HTTPå®¢æˆ·ç«¯åº“

# åŸºæœ¬ä½¿ç”¨
import requests

# 1. GETè¯·æ±‚
response = requests.get('https://dblp.org/search/publ/api')
print(response.status_code)  # 200
print(response.text)         # å“åº”å†…å®¹

# 2. POSTè¯·æ±‚
data = {'key': 'value'}
response = requests.post('https://api.example.com', json=data)

# 3. å¸¦å‚æ•°çš„GETè¯·æ±‚
params = {'q': 'machine learning', 'format': 'json'}
response = requests.get('https://dblp.org/search', params=params)
# å®é™…è¯·æ±‚ï¼šhttps://dblp.org/search?q=machine+learning&format=json

# HTTPAdapterå’ŒRetryæœºåˆ¶
# ç”¨äºè‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚

from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# 1. åˆ›å»ºé‡è¯•ç­–ç•¥
retry_strategy = Retry(
    total=3,                    # æœ€å¤šé‡è¯•3æ¬¡
    backoff_factor=0.5,         # é‡è¯•é—´éš”ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
    status_forcelist=[429, 500, 502, 503, 504]  # è¿™äº›çŠ¶æ€ç è§¦å‘é‡è¯•
)

# 2. åˆ›å»ºé€‚é…å™¨
adapter = HTTPAdapter(max_retries=retry_strategy)

# 3. æŒ‚è½½åˆ°session
session = requests.Session()
session.mount("https://", adapter)
session.mount("http://", adapter)

# 4. ä½¿ç”¨sessionå‘é€è¯·æ±‚
response = session.get('https://api.example.com')

# Retryå‚æ•°è¯¦è§£
retry = Retry(
    total=3,              # æ€»é‡è¯•æ¬¡æ•°
    read=3,               # è¯»å–è¶…æ—¶é‡è¯•
    connect=3,            # è¿æ¥è¶…æ—¶é‡è¯•
    backoff_factor=0.5,   # é‡è¯•é—´éš”å› å­
    status_forcelist=[429, 500, 502, 503, 504],  # è§¦å‘é‡è¯•çš„çŠ¶æ€ç 
    allowed_methods=["HEAD", "GET", "OPTIONS"]   # å…è®¸é‡è¯•çš„HTTPæ–¹æ³•
)

# backoff_factorå·¥ä½œåŸç†
# é‡è¯•é—´éš” = backoff_factor * (2 ^ (é‡è¯•æ¬¡æ•° - 1))
# backoff_factor=0.5:
# ç¬¬1æ¬¡é‡è¯•ï¼šç­‰å¾… 0.5 * 2^0 = 0.5ç§’
# ç¬¬2æ¬¡é‡è¯•ï¼šç­‰å¾… 0.5 * 2^1 = 1ç§’
# ç¬¬3æ¬¡é‡è¯•ï¼šç­‰å¾… 0.5 * 2^2 = 2ç§’

# ä¸ºä»€ä¹ˆéœ€è¦é‡è¯•ï¼Ÿ
# 1. ç½‘ç»œä¸ç¨³å®š
# 2. æœåŠ¡å™¨ä¸´æ—¶æ•…éšœ
# 3. APIé™æµï¼ˆ429çŠ¶æ€ç ï¼‰
# 4. æé«˜æˆåŠŸç‡

# Sessionçš„ä¼˜åŠ¿
# 1. è¿æ¥æ± ï¼šå¤ç”¨TCPè¿æ¥
# 2. CookieæŒä¹…åŒ–
# 3. è‡ªå®šä¹‰é…ç½®
session = requests.Session()
session.headers.update({'User-Agent': 'MyApp/1.0'})
session.proxies = {'http': 'http://proxy:8080'}

# æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨ï¼ˆç¬¬44-55è¡Œï¼‰
class BibManager:
    def __init__(self):
        self.retry_strategy = Retry(
            total=MAX_RETRIES,
            backoff_factor=BACKOFF_FACTOR,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        self.session = self._create_session()
    
    def _create_session(self) -> requests.Session:
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ä¼šè¯"""
        session = requests.Session()
        session.mount("https://", HTTPAdapter(max_retries=self.retry_strategy))
        return session
```

**ç¬¬11è¡Œè¯¦è§£**ï¼š`import concurrent.futures`

```python
import concurrent.futures

# concurrent.futuresè¯¦è§£
# Pythonæ ‡å‡†åº“ï¼Œæä¾›é«˜çº§å¹¶å‘æ¥å£

# ä¸¤ç§æ‰§è¡Œå™¨
# 1. ThreadPoolExecutor - çº¿ç¨‹æ± 
from concurrent.futures import ThreadPoolExecutor

# åˆ›å»ºçº¿ç¨‹æ± 
with ThreadPoolExecutor(max_workers=5) as executor:
    # æäº¤ä»»åŠ¡
    future = executor.submit(function, arg1, arg2)
    # è·å–ç»“æœ
    result = future.result()

# 2. ProcessPoolExecutor - è¿›ç¨‹æ± 
from concurrent.futures import ProcessPoolExecutor

with ProcessPoolExecutor(max_workers=4) as executor:
    future = executor.submit(cpu_intensive_task, data)
    result = future.result()

# ThreadPoolExecutor vs ProcessPoolExecutor
# ThreadPoolExecutor:
# - é€‚åˆï¼šIOå¯†é›†å‹ä»»åŠ¡ï¼ˆç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶è¯»å†™ï¼‰
# - ä¼˜åŠ¿ï¼šå¼€é”€å°ï¼Œå…±äº«å†…å­˜
# - é™åˆ¶ï¼šå—GILé™åˆ¶ï¼Œä¸é€‚åˆCPUå¯†é›†å‹

# ProcessPoolExecutor:
# - é€‚åˆï¼šCPUå¯†é›†å‹ä»»åŠ¡ï¼ˆæ•°å­¦è®¡ç®—ã€å›¾åƒå¤„ç†ï¼‰
# - ä¼˜åŠ¿ï¼šç»•è¿‡GILï¼ŒçœŸæ­£å¹¶è¡Œ
# - é™åˆ¶ï¼šå¼€é”€å¤§ï¼Œä¸å…±äº«å†…å­˜

# map()æ–¹æ³• - æ‰¹é‡æ‰§è¡Œ
with ThreadPoolExecutor(max_workers=10) as executor:
    # å¯¹æ¯ä¸ªURLè°ƒç”¨fetchå‡½æ•°
    results = executor.map(fetch, urls)
    # resultsæ˜¯ä¸€ä¸ªè¿­ä»£å™¨
    for result in results:
        print(result)

# submit()æ–¹æ³• - å•ä¸ªä»»åŠ¡
with ThreadPoolExecutor() as executor:
    future1 = executor.submit(download, url1)
    future2 = executor.submit(download, url2)
    # ç­‰å¾…å®Œæˆ
    result1 = future1.result()
    result2 = future2.result()

# as_completed() - æŒ‰å®Œæˆé¡ºåº
from concurrent.futures import as_completed

with ThreadPoolExecutor(max_workers=10) as executor:
    futures = [executor.submit(download, url) for url in urls]
    
    for future in as_completed(futures):
        result = future.result()
        print(f"å®Œæˆ: {result}")

# æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# å¹¶å‘è·å–å¤šç¯‡è®ºæ–‡çš„æ‘˜è¦
def fetch_abstracts(papers: List[dict]) -> List[str]:
    with ThreadPoolExecutor(max_workers=10) as executor:
        # å¹¶å‘è·å–æ‰€æœ‰æ‘˜è¦
        abstracts = list(executor.map(get_abstract, papers))
    return abstracts

# ä¸ºä»€ä¹ˆç”¨å¹¶å‘ï¼Ÿ
# 1. åŠ å¿«å¤„ç†é€Ÿåº¦
# å•çº¿ç¨‹ï¼š10ç¯‡è®ºæ–‡ Ã— 2ç§’ = 20ç§’
# 10çº¿ç¨‹ï¼š10ç¯‡è®ºæ–‡ / 10 â‰ˆ 2ç§’

# 2. æé«˜æ•ˆç‡
# ç­‰å¾…ç½‘ç»œå“åº”æ—¶ï¼Œå¯ä»¥å¤„ç†å…¶ä»–ä»»åŠ¡

# å¼‚å¸¸å¤„ç†
with ThreadPoolExecutor() as executor:
    future = executor.submit(risky_function)
    try:
        result = future.result(timeout=10)  # 10ç§’è¶…æ—¶
    except TimeoutError:
        print("ä»»åŠ¡è¶…æ—¶")
    except Exception as e:
        print(f"ä»»åŠ¡å¤±è´¥: {e}")
```

**ç¬¬12è¡Œè¯¦è§£**ï¼š`from functools import partial`

```python
from functools import partial

# partialå‡½æ•°è¯¦è§£
# åŠŸèƒ½ï¼šå›ºå®šå‡½æ•°çš„éƒ¨åˆ†å‚æ•°

# åŸºæœ¬ç”¨æ³•
from functools import partial

def power(base, exponent):
    return base ** exponent

# åˆ›å»ºå¹³æ–¹å‡½æ•°
square = partial(power, exponent=2)
print(square(5))  # 25ï¼ˆç›¸å½“äºpower(5, 2)ï¼‰

# åˆ›å»ºç«‹æ–¹å‡½æ•°
cube = partial(power, exponent=3)
print(cube(5))  # 125ï¼ˆç›¸å½“äºpower(5, 3)ï¼‰

# partialçš„ä¼˜åŠ¿
# 1. ä»£ç å¤ç”¨
# ä¸ä½¿ç”¨partialï¼š
def download_with_retry(url, retries):
    # ...
    pass

for url in urls:
    download_with_retry(url, retries=3)

# ä½¿ç”¨partialï¼š
download = partial(download_with_retry, retries=3)
for url in urls:
    download(url)

# 2. åœ¨map()ä¸­ä¼ é€’é¢å¤–å‚æ•°
from concurrent.futures import ThreadPoolExecutor
from functools import partial

def fetch(url, timeout, headers):
    # ...
    pass

# å›ºå®štimeoutå’Œheaders
fetch_with_config = partial(fetch, timeout=10, headers={'User-Agent': 'MyApp'})

# åœ¨çº¿ç¨‹æ± ä¸­ä½¿ç”¨
with ThreadPoolExecutor() as executor:
    results = executor.map(fetch_with_config, urls)

# 3. å›è°ƒå‡½æ•°
def process_result(base_path, result):
    # ä½¿ç”¨base_pathå’Œresult
    pass

# å›ºå®šbase_path
callback = partial(process_result, base_path='/output')

# ä½¿ç”¨å›è°ƒ
download(url, callback=callback)

# partial vs lambda
# partialï¼š
double = partial(power, exponent=2)

# lambdaï¼š
double = lambda x: power(x, exponent=2)

# partialçš„ä¼˜åŠ¿ï¼š
# 1. æ›´æ¸…æ™°
# 2. å¯ä»¥ä½¿ç”¨ä½ç½®å‚æ•°
# 3. æœ‰__name__å±æ€§

# æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# åœ¨å¹¶å‘å¤„ç†ä¸­ä¼ é€’é¢å¤–å‚æ•°
with ThreadPoolExecutor() as executor:
    # éœ€è¦ä¼ é€’analyserå®ä¾‹ç»™æ¯ä¸ªä»»åŠ¡
    fetch_func = partial(fetch_abstract, analyser=analyser)
    results = executor.map(fetch_func, papers)
```

### è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥ï¼ˆç¬¬19-21è¡Œï¼‰

```python
from Analyser import Analyser              # ç¬¬19è¡Œ
from merger import ResultMerger            # ç¬¬20è¡Œ
from Rule import Rule                      # ç¬¬21è¡Œ
```

**å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—è¯¦è§£ï¼ˆç¬¬19-21è¡Œï¼‰**ï¼š

```python
from Analyser import Analyser
from merger import ResultMerger
from Rule import Rule

# è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥
# 1. Analyser - æ‘˜è¦åˆ†æå™¨
#    åŠŸèƒ½ï¼šä»ç½‘é¡µæå–è®ºæ–‡æ‘˜è¦
#    ä½ç½®ï¼šAnalyser.py

# 2. ResultMerger - ç»“æœåˆå¹¶å™¨
#    åŠŸèƒ½ï¼šåˆå¹¶å¤šä¸ªæœç´¢ç»“æœ
#    ä½ç½®ï¼šmerger.py

# 3. Rule - è§„åˆ™å¼•æ“
#    åŠŸèƒ½ï¼šç½‘é¡µè§£æè§„åˆ™
#    ä½ç½®ï¼šRule.py

# æ¨¡å—å¯¼å…¥çš„è·¯å¾„é—®é¢˜ï¼ˆç¬¬14-17è¡Œï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

# ä¸ºä»€ä¹ˆéœ€è¦æ·»åŠ è·¯å¾„ï¼Ÿ
# 1. ç¡®ä¿èƒ½æ‰¾åˆ°è‡ªå®šä¹‰æ¨¡å—
# 2. æ”¯æŒä¸åŒçš„è¿è¡Œæ–¹å¼
#    - ç›´æ¥è¿è¡Œï¼špython Main.py
#    - æ¨¡å—å¯¼å…¥ï¼šfrom Main import BibManager
#    - å…¶ä»–ç›®å½•è¿è¡Œï¼špython path/to/Main.py

# __file__è¯¦è§£
# __file__ï¼šå½“å‰æ–‡ä»¶çš„è·¯å¾„

# ç¤ºä¾‹
print(__file__)
# è¾“å‡ºï¼šD:/project/Main.py

# è·å–ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
# D:/project

# sys.pathè¯¦è§£
# Pythonæ¨¡å—æœç´¢è·¯å¾„åˆ—è¡¨
import sys
print(sys.path)
# ['å½“å‰ç›®å½•', 'æ ‡å‡†åº“ç›®å½•', 'ç¬¬ä¸‰æ–¹åº“ç›®å½•', ...]

# æ·»åŠ è‡ªå®šä¹‰è·¯å¾„
sys.path.append('/my/custom/path')
# ç°åœ¨å¯ä»¥ä»è¯¥è·¯å¾„å¯¼å…¥æ¨¡å—
```

---

## âš™ï¸ å…¨å±€å¸¸é‡å®šä¹‰

### å¸¸é‡å®šä¹‰ï¼ˆç¬¬23-39è¡Œï¼‰

```python
# å¸¸é‡å®šä¹‰                                # ç¬¬23è¡Œï¼ˆæ³¨é‡Šï¼‰
MAX_RETRIES = 3                           # ç¬¬24è¡Œ
BACKOFF_FACTOR = 0.5                      # ç¬¬25è¡Œ
BATCH_SIZE = 10                           # ç¬¬26è¡Œ
MAX_RESULTS = 1000                        # ç¬¬27è¡Œ
CCF_RANKS = {"A", "B", "C", "E", "P"}     # ç¬¬28è¡Œ
# ç»“æœæ–‡ä»¶å¤¹å®šä¹‰                          # ç¬¬29è¡Œï¼ˆæ³¨é‡Šï¼‰
BIB_FOLDER = "bib_results"                # ç¬¬30è¡Œ
JSON_FOLDER = "json_results"              # ç¬¬31è¡Œ
# åˆå¹¶åçš„æ–‡ä»¶å                          # ç¬¬32è¡Œï¼ˆæ³¨é‡Šï¼‰
COMBINED_BIB = "references.bib"           # ç¬¬33è¡Œ
COMBINED_JSON = "references.json"         # ç¬¬34è¡Œ

proxies = {                               # ç¬¬36è¡Œ
    # "http": "http://127.0.0.1:7897",    # ç¬¬37è¡Œï¼ˆæ³¨é‡Šï¼‰
    # "https": "http://127.0.0.1:7897"    # ç¬¬38è¡Œï¼ˆæ³¨é‡Šï¼‰
}                                         # ç¬¬39è¡Œ
```

**å¸¸é‡å®šä¹‰è¯¦è§£ï¼ˆç¬¬24-28è¡Œï¼‰**ï¼š

```python
MAX_RETRIES = 3
BACKOFF_FACTOR = 0.5
BATCH_SIZE = 10
MAX_RESULTS = 1000
CCF_RANKS = {"A", "B", "C", "E", "P"}

# å¸¸é‡å‘½åè§„èŒƒ
# 1. å…¨å¤§å†™
# 2. ä¸‹åˆ’çº¿åˆ†éš”å•è¯
# 3. è¡¨ç¤ºä¸åº”è¯¥ä¿®æ”¹çš„å€¼

# ä¸ºä»€ä¹ˆç”¨å¸¸é‡ï¼Ÿ
# 1. å¯ç»´æŠ¤æ€§
#    ä¿®æ”¹ä¸€å¤„ï¼Œå…¨å±€ç”Ÿæ•ˆ
# 2. å¯è¯»æ€§
#    MAX_RETRIESæ¯”3æ›´æœ‰æ„ä¹‰
# 3. é¿å…é­”æ³•æ•°å­—

# å¸¸é‡è¯´æ˜
# 1. MAX_RETRIES = 3
#    æœ€å¤§é‡è¯•æ¬¡æ•°ï¼šå¤±è´¥åæœ€å¤šé‡è¯•3æ¬¡

# 2. BACKOFF_FACTOR = 0.5
#    é‡è¯•é—´éš”å› å­ï¼šæŒ‡æ•°é€€é¿ç­–ç•¥
#    ç¬¬1æ¬¡ï¼š0.5ç§’
#    ç¬¬2æ¬¡ï¼š1ç§’
#    ç¬¬3æ¬¡ï¼š2ç§’

# 3. BATCH_SIZE = 10
#    æ‰¹å¤„ç†å¤§å°ï¼šæ¯æ‰¹å¤„ç†10ä¸ªé¡¹ç›®

# 4. MAX_RESULTS = 1000
#    æœ€å¤§ç»“æœæ•°ï¼šæœ€å¤šè¿”å›1000æ¡ç»“æœ

# 5. CCF_RANKS = {"A", "B", "C", "E", "P"}
#    CCFç­‰çº§é›†åˆï¼š
#    - Aï¼šé¡¶çº§ä¼šè®®/æœŸåˆŠ
#    - Bï¼šä¼˜ç§€ä¼šè®®/æœŸåˆŠ
#    - Cï¼šä¸€èˆ¬ä¼šè®®/æœŸåˆŠ
#    - Eï¼šæ–°å¢ä¼šè®®/æœŸåˆŠ
#    - Pï¼šå‡ºç‰ˆç¤¾

# é›†åˆvsåˆ—è¡¨
# ä½¿ç”¨é›†åˆçš„åŸå› ï¼š
CCF_RANKS = {"A", "B", "C", "E", "P"}  # é›†åˆ
# 1. æŸ¥æ‰¾æ›´å¿«ï¼šO(1) vs O(n)
# 2. è¡¨ç¤ºæˆå‘˜å…³ç³»æ›´åˆé€‚

if rank in CCF_RANKS:  # å¿«é€Ÿæ£€æŸ¥
    print("æœ‰æ•ˆç­‰çº§")

# å¦‚æœç”¨åˆ—è¡¨ï¼š
CCF_RANKS_LIST = ["A", "B", "C", "E", "P"]  # è¾ƒæ…¢
```

**æ–‡ä»¶å¤¹å’Œä»£ç†é…ç½®ï¼ˆç¬¬30-39è¡Œï¼‰**ï¼š

```python
BIB_FOLDER = "bib_results"
JSON_FOLDER = "json_results"
COMBINED_BIB = "references.bib"
COMBINED_JSON = "references.json"

proxies = {
    # "http": "http://127.0.0.1:7897",
    # "https": "http://127.0.0.1:7897"
}

# æ–‡ä»¶å¤¹å¸¸é‡
# ç”¨äºç»„ç»‡è¾“å‡ºæ–‡ä»¶

# é¡¹ç›®ç›®å½•ç»“æ„
"""
project/
â”œâ”€â”€ Main.py
â”œâ”€â”€ bib_results/           â† BIB_FOLDER
â”‚   â”œâ”€â”€ query1.bib
â”‚   â””â”€â”€ query2.bib
â”œâ”€â”€ json_results/          â† JSON_FOLDER
â”‚   â”œâ”€â”€ query1.json
â”‚   â””â”€â”€ query2.json
â”œâ”€â”€ references.bib         â† COMBINED_BIB
â””â”€â”€ references.json        â† COMBINED_JSON
"""

# proxieså­—å…¸
# ç”¨äºHTTPä»£ç†é…ç½®

# å¯ç”¨ä»£ç†ï¼ˆå–æ¶ˆæ³¨é‡Šï¼‰
proxies = {
    "http": "http://127.0.0.1:7897",
    "https": "http://127.0.0.1:7897"
}

# ä½¿ç”¨ä»£ç†
response = requests.get(url, proxies=proxies)

# ä¸ºä»€ä¹ˆéœ€è¦ä»£ç†ï¼Ÿ
# 1. è®¿é—®å—é™ç½‘ç«™
# 2. éšè—IPåœ°å€
# 3. ç»•è¿‡åœ°åŸŸé™åˆ¶
# 4. ç§‘å­¦ä¸Šç½‘

# ç©ºå­—å…¸ï¼ˆé»˜è®¤ä¸ä½¿ç”¨ä»£ç†ï¼‰
proxies = {}
# ç­‰ä»·äºä¸è®¾ç½®ä»£ç†
```

---

## ğŸ“š BibManagerç±»è¯¦è§£

### ç±»å®šä¹‰å’Œåˆå§‹åŒ–ï¼ˆç¬¬41-55è¡Œï¼‰

```python
class BibManager:                          # ç¬¬41è¡Œ
    """Bibæ–‡ä»¶ç®¡ç†ç±»"""                     # ç¬¬42è¡Œ
    def __init__(self):                    # ç¬¬43è¡Œ
        self.retry_strategy = Retry(       # ç¬¬44è¡Œ
            total=MAX_RETRIES,             # ç¬¬45è¡Œ
            backoff_factor=BACKOFF_FACTOR, # ç¬¬46è¡Œ
            status_forcelist=[429, 500, 502, 503, 504]  # ç¬¬47è¡Œ
        )                                  # ç¬¬48è¡Œ
        self.session = self._create_session()  # ç¬¬49è¡Œ
```

**ç±»å®šä¹‰è¯¦è§£ï¼ˆç¬¬41-42è¡Œï¼‰**ï¼š

```python
class BibManager:
    """Bibæ–‡ä»¶ç®¡ç†ç±»"""

# ç±»çš„ä½œç”¨
# 1. ç®¡ç†BibTeXå¼•ç”¨æ ¼å¼
# 2. è·å–è®ºæ–‡æ‘˜è¦
# 3. å¤„ç†ç½‘ç»œè¯·æ±‚

# ä¸ºä»€ä¹ˆç”¨ç±»ï¼Ÿ
# 1. å°è£…ç›¸å…³åŠŸèƒ½
# 2. ç®¡ç†çŠ¶æ€ï¼ˆsessionã€retry_strategyï¼‰
# 3. ä»£ç å¤ç”¨

# ç±»çš„å‘½å
# - é©¼å³°å‘½åæ³•ï¼ˆCamelCaseï¼‰
# - åè¯æˆ–åè¯çŸ­è¯­
# - BibManager = Bib + Manager
```

**åˆå§‹åŒ–æ–¹æ³•è¯¦è§£ï¼ˆç¬¬43-49è¡Œï¼‰**ï¼š

```python
def __init__(self):
    self.retry_strategy = Retry(
        total=MAX_RETRIES,
        backoff_factor=BACKOFF_FACTOR,
        status_forcelist=[429, 500, 502, 503, 504]
    )
    self.session = self._create_session()

# __init__æ–¹æ³•
# 1. æ„é€ å‡½æ•°ï¼Œåˆ›å»ºå¯¹è±¡æ—¶è‡ªåŠ¨è°ƒç”¨
# 2. åˆå§‹åŒ–å®ä¾‹å˜é‡

# self.retry_strategy
# é‡è¯•ç­–ç•¥å¯¹è±¡
# ç”¨äºç½‘ç»œè¯·æ±‚å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•

# Retryå‚æ•°è¯¦è§£
# total=3ï¼šæœ€å¤šé‡è¯•3æ¬¡
# backoff_factor=0.5ï¼šé‡è¯•é—´éš”å› å­
# status_forcelistï¼šè§¦å‘é‡è¯•çš„HTTPçŠ¶æ€ç 
#   - 429: Too Many Requestsï¼ˆè¯·æ±‚è¿‡å¤šï¼‰
#   - 500: Internal Server Errorï¼ˆæœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼‰
#   - 502: Bad Gatewayï¼ˆç½‘å…³é”™è¯¯ï¼‰
#   - 503: Service Unavailableï¼ˆæœåŠ¡ä¸å¯ç”¨ï¼‰
#   - 504: Gateway Timeoutï¼ˆç½‘å…³è¶…æ—¶ï¼‰

# self.session
# HTTPä¼šè¯å¯¹è±¡
# ç”¨äºå‘é€ç½‘ç»œè¯·æ±‚
```

**åˆ›å»ºä¼šè¯æ–¹æ³•ï¼ˆç¬¬51-55è¡Œï¼‰**ï¼š

```python
def _create_session(self) -> requests.Session:  # ç¬¬51è¡Œ
    """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ä¼šè¯"""                   # ç¬¬52è¡Œ
    session = requests.Session()               # ç¬¬53è¡Œ
    session.mount("https://", HTTPAdapter(max_retries=self.retry_strategy))  # ç¬¬54è¡Œ
    return session                             # ç¬¬55è¡Œ

# _create_session()æ–¹æ³•è¯¦è§£
# 1. æ–¹æ³•åå‰ç¼€_è¡¨ç¤ºç§æœ‰æ–¹æ³•
# 2. è¿”å›ç±»å‹æç¤ºï¼š-> requests.Session

# æ–¹æ³•æ­¥éª¤
# 1. åˆ›å»ºSessionå¯¹è±¡
session = requests.Session()

# 2. æŒ‚è½½HTTPAdapter
session.mount("https://", HTTPAdapter(max_retries=self.retry_strategy))
# mount()ï¼šä¸ºç‰¹å®šURLå‰ç¼€è®¾ç½®é€‚é…å™¨
# "https://"ï¼šæ‰€æœ‰HTTPSè¯·æ±‚ä½¿ç”¨æ­¤é€‚é…å™¨
# HTTPAdapterï¼šå¸¦é‡è¯•æœºåˆ¶çš„é€‚é…å™¨

# 3. è¿”å›é…ç½®å¥½çš„session
return session

# Sessionçš„ä¼˜åŠ¿
# 1. è¿æ¥æ± ï¼šå¤ç”¨TCPè¿æ¥
# 2. CookieæŒä¹…åŒ–
# 3. ç»Ÿä¸€é…ç½®ï¼ˆheadersã€proxiesã€è¶…æ—¶ï¼‰

# ä½¿ç”¨ç¤ºä¾‹
manager = BibManager()
# è‡ªåŠ¨è°ƒç”¨__init__()
# åˆ›å»ºretry_strategyå’Œsession

# å‘é€è¯·æ±‚
response = manager.session.get('https://dblp.org/...')
# è‡ªåŠ¨ä½¿ç”¨é‡è¯•æœºåˆ¶
```

ç”±äºæ–‡ä»¶å¾ˆé•¿ï¼ˆ1475è¡Œï¼‰ï¼Œæˆ‘å…ˆä¸ºæ‚¨åˆ›å»ºäº†**å‰æœŸæ ¸å¿ƒéƒ¨åˆ†**çš„è¯¦ç»†è§£æã€‚æ–‡æ¡£å·²ä¿å­˜ä¸º `learn/Main_æ–‡çŒ®æœç´¢ç³»ç»Ÿè¯¦è§£.md`ï¼

è¿™ä»½æ–‡æ¡£åŒ…å«ï¼š
- âœ… é¡¹ç›®æ¦‚è¿°
- âœ… æ‰€æœ‰å¯¼å…¥è¯­å¥çš„è¯¦ç»†è®²è§£
- âœ… å…¨å±€å¸¸é‡å®šä¹‰
- âœ… BibManagerç±»çš„åˆå§‹åŒ–éƒ¨åˆ†

ä¸»è¦ç‰¹è‰²ï¼š
- ğŸ“– **è¶…è¯¦ç»†çš„å¯¼å…¥è®²è§£**ï¼šdefaultdictã€typingã€concurrent.futuresã€partialç­‰
- ğŸ¯ **å®ç”¨ç¤ºä¾‹**ï¼šæ¯ä¸ªæŠ€æœ¯ç‚¹éƒ½æœ‰ä¸°å¯Œçš„ä»£ç ç¤ºä¾‹
- ğŸ’¡ **å¯¹æ¯”å­¦ä¹ **ï¼šæ™®é€šdict vs defaultdictã€partial vs lambdaç­‰
- âš¡ **å¹¶å‘ç¼–ç¨‹è¯¦è§£**ï¼šThreadPoolExecutorå®Œæ•´è®²è§£

éœ€è¦æˆ‘ç»§ç»­è¡¥å……åç»­å†…å®¹å—ï¼ˆå¦‚BibManagerçš„å…¶ä»–æ–¹æ³•ã€CCFMapperç±»ã€PublicationSearcherç±»ç­‰ï¼‰ï¼ŸğŸš€
