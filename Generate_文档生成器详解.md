# Generate æ–‡æ¡£ç”Ÿæˆå™¨è¯¦è§£

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [å¯¼å…¥è¯­å¥è¯¦è§£](#å¯¼å…¥è¯­å¥è¯¦è§£)
3. [DocumentGeneratorç±»è¯¦è§£](#documentgeneratorç±»è¯¦è§£)
4. [åˆå§‹åŒ–æ–¹æ³•è¯¦è§£](#åˆå§‹åŒ–æ–¹æ³•è¯¦è§£)
5. [æ–‡çŒ®åŠ è½½æ–¹æ³•](#æ–‡çŒ®åŠ è½½æ–¹æ³•)
6. [æ–‡æ¡£ç”Ÿæˆä¸»æ–¹æ³•](#æ–‡æ¡£ç”Ÿæˆä¸»æ–¹æ³•)
7. [APIè°ƒç”¨æ–¹æ³•](#apiè°ƒç”¨æ–¹æ³•)
8. [å†…å®¹è§£ææ–¹æ³•](#å†…å®¹è§£ææ–¹æ³•)
9. [æ–‡æ¡£è¾“å‡ºæ–¹æ³•](#æ–‡æ¡£è¾“å‡ºæ–¹æ³•)
10. [æŠ€æœ¯æ€»ç»“](#æŠ€æœ¯æ€»ç»“)

---

## ğŸ“– é¡¹ç›®æ¦‚è¿°

`generate.py` æ˜¯ä¸€ä¸ª**AIé©±åŠ¨çš„å­¦æœ¯æ–‡æ¡£ç”Ÿæˆå™¨**ï¼Œç”¨äºè‡ªåŠ¨ç”Ÿæˆè®ºæ–‡çš„ç›¸å…³å·¥ä½œï¼ˆRelated Workï¼‰éƒ¨åˆ†ã€‚

### ä¸»è¦åŠŸèƒ½

- ğŸ¤– **AIç”Ÿæˆ**: è°ƒç”¨OpenAI/DeepSeek APIç”Ÿæˆå­¦æœ¯å†…å®¹
- ğŸ“š **æ–‡çŒ®ç®¡ç†**: è‡ªåŠ¨åŠ è½½å’Œç®¡ç†å‚è€ƒæ–‡çŒ®
- ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒä¸­æ–‡ã€è‹±æ–‡åŒè¯­ç”Ÿæˆ
- ğŸ“ **å¤šæ ¼å¼è¾“å‡º**: ç”ŸæˆWordï¼ˆ.docxï¼‰å’ŒLaTeXï¼ˆ.texï¼‰æ ¼å¼
- ğŸ”„ **è‡ªåŠ¨å¼•ç”¨**: æ™ºèƒ½ç®¡ç†æ–‡çŒ®å¼•ç”¨
- ğŸ¯ **æ¨¡æ¿é©±åŠ¨**: åŸºäºpromptæ¨¡æ¿ç”Ÿæˆç»“æ„åŒ–å†…å®¹

### æ ¸å¿ƒæµç¨‹

```
åŠ è½½æ–‡çŒ® â†’ æ„å»ºæç¤ºè¯ â†’ è°ƒç”¨AI API â†’ è§£æJSON â†’ ç”Ÿæˆæ–‡æ¡£
   â†“           â†“             â†“           â†“         â†“
2.txt      prompt.txt    OpenAI      è§£æå†…å®¹    .docx/.tex
```

### æ–‡ä»¶ç»Ÿè®¡

- **æ€»è¡Œæ•°**: 499è¡Œ
- **å¯¼å…¥æ¨¡å—**: 6ä¸ª
- **ä¸»è¦ç±»**: 1ä¸ªï¼ˆDocumentGeneratorï¼‰
- **æ–¹æ³•æ•°é‡**: 10+ä¸ª

---

## ğŸ“¦ å¯¼å…¥è¯­å¥è¯¦è§£

### å¯¼å…¥æ¨¡å—ï¼ˆç¬¬1-6è¡Œï¼‰

```python
from openai import OpenAI                # ç¬¬1è¡Œ
import os                                # ç¬¬2è¡Œ
import json                              # ç¬¬3è¡Œ
from docx import Document                # ç¬¬4è¡Œ
import re                                # ç¬¬5è¡Œ
import time                              # ç¬¬6è¡Œ
```

**ç¬¬1è¡Œè¯¦è§£**ï¼š`from openai import OpenAI`

**OpenAIå®¢æˆ·ç«¯åº“è¯¦è§£ï¼ˆç¬¬1è¡Œï¼‰**ï¼š
- `from openai import`ï¼šä»openaiåŒ…å¯¼å…¥
- `OpenAI`ï¼šOpenAIå®˜æ–¹Pythonå®¢æˆ·ç«¯ç±»
- ç”¨é€”ï¼šä¸OpenAI APIäº¤äº’ï¼Œè°ƒç”¨GPTæ¨¡å‹

```python
from openai import OpenAI

# OpenAIæ˜¯ä»€ä¹ˆï¼Ÿ
# OpenAIå®˜æ–¹æä¾›çš„Python SDK
# ç”¨äºè®¿é—®GPT-4ã€GPT-3.5ç­‰å¤§è¯­è¨€æ¨¡å‹

# å®‰è£…openaiåº“
$ pip install openai

# åŸºæœ¬ä½¿ç”¨
from openai import OpenAI

# 1. åˆ›å»ºå®¢æˆ·ç«¯
client = OpenAI(
    api_key="sk-...",                    # APIå¯†é’¥
    base_url="https://api.openai.com/v1" # APIç«¯ç‚¹
)

# 2. è°ƒç”¨èŠå¤©å®ŒæˆAPI
response = client.chat.completions.create(
    model="gpt-4",                       # æ¨¡å‹åç§°
    messages=[                           # å¯¹è¯æ¶ˆæ¯
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)

# 3. è·å–å›å¤
answer = response.choices[0].message.content
print(answer)

# OpenAI APIçš„æ¶ˆæ¯è§’è‰²
# 1. system - ç³»ç»Ÿæ¶ˆæ¯ï¼Œè®¾ç½®AIçš„è¡Œä¸º
{"role": "system", "content": "You are a helpful assistant."}

# 2. user - ç”¨æˆ·æ¶ˆæ¯ï¼Œç”¨æˆ·çš„è¾“å…¥
{"role": "user", "content": "What is Python?"}

# 3. assistant - AIçš„å›å¤
{"role": "assistant", "content": "Python is a programming language."}

# å®Œæ•´å¯¹è¯ç¤ºä¾‹
messages = [
    {"role": "system", "content": "You are a Python expert."},
    {"role": "user", "content": "What is a list?"},
    {"role": "assistant", "content": "A list is a collection..."},
    {"role": "user", "content": "How to append?"}  # ç»§ç»­å¯¹è¯
]

# OpenAIå®¢æˆ·ç«¯é…ç½®é€‰é¡¹
client = OpenAI(
    api_key="sk-...",           # å¿…éœ€ï¼šAPIå¯†é’¥
    base_url="...",             # å¯é€‰ï¼šAPIç«¯ç‚¹ï¼ˆç”¨äºä»£ç†æˆ–å…¼å®¹APIï¼‰
    timeout=60.0,               # å¯é€‰ï¼šè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    max_retries=3,              # å¯é€‰ï¼šé‡è¯•æ¬¡æ•°
    default_headers={...}       # å¯é€‰ï¼šè‡ªå®šä¹‰è¯·æ±‚å¤´
)

# æœ¬é¡¹ç›®æ”¯æŒä¸¤ç§API
# 1. OpenAIå®˜æ–¹API
client = OpenAI(
    api_key="sk-...",
    base_url="https://api.openai.com/v1",
    model="gpt-4"
)

# 2. DeepSeek APIï¼ˆå…¼å®¹OpenAIæ ¼å¼ï¼‰
client = OpenAI(
    api_key="sk-...",
    base_url="https://api.deepseek.com",
    model="deepseek-chat"
)

# ä¸ºä»€ä¹ˆå¯ä»¥ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨DeepSeekï¼Ÿ
# DeepSeek APIå…¼å®¹OpenAIçš„æ¥å£æ ¼å¼
# åªéœ€ä¿®æ”¹base_urlå’Œmodelå‚æ•°

# chat.completions.create()è¯¦è§£
response = client.chat.completions.create(
    model="gpt-4",              # æ¨¡å‹åç§°
    messages=[...],             # å¯¹è¯æ¶ˆæ¯
    temperature=0.7,            # éšæœºæ€§ï¼ˆ0-2ï¼Œè¶Šé«˜è¶Šéšæœºï¼‰
    max_tokens=1000,            # æœ€å¤§ç”Ÿæˆtokenæ•°
    top_p=1.0,                  # æ ¸é‡‡æ ·å‚æ•°
    frequency_penalty=0.0,      # é¢‘ç‡æƒ©ç½š
    presence_penalty=0.0,       # å­˜åœ¨æƒ©ç½š
    stream=False                # æ˜¯å¦æµå¼è¾“å‡º
)

# responseå¯¹è±¡ç»“æ„
response = {
    "id": "chatcmpl-...",
    "object": "chat.completion",
    "created": 1677652288,
    "model": "gpt-4",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "AIçš„å›å¤å†…å®¹"
            },
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 56,
        "completion_tokens": 31,
        "total_tokens": 87
    }
}

# è·å–å›å¤å†…å®¹
content = response.choices[0].message.content

# é”™è¯¯å¤„ç†
from openai import OpenAIError, APIError, RateLimitError

try:
    response = client.chat.completions.create(...)
except RateLimitError:
    print("APIè°ƒç”¨é¢‘ç‡è¶…é™")
except APIError as e:
    print(f"APIé”™è¯¯: {e}")
except Exception as e:
    print(f"å…¶ä»–é”™è¯¯: {e}")
```

**ç¬¬4è¡Œè¯¦è§£**ï¼š`from docx import Document`

**python-docxåº“è¯¦è§£ï¼ˆç¬¬4è¡Œï¼‰**ï¼š
- `docx`ï¼špython-docxåº“çš„åŒ…å
- `Document`ï¼šæ–‡æ¡£ç±»ï¼Œç”¨äºåˆ›å»ºå’Œä¿®æ”¹Wordæ–‡æ¡£
- ç”¨é€”ï¼šç”Ÿæˆ.docxæ ¼å¼çš„Wordæ–‡æ¡£

```python
from docx import Document

# python-docxæ˜¯ä»€ä¹ˆï¼Ÿ
# ç”¨äºåˆ›å»ºå’Œä¿®æ”¹Wordæ–‡æ¡£ï¼ˆ.docxï¼‰çš„Pythonåº“

# å®‰è£…
$ pip install python-docx

# åŸºæœ¬ä½¿ç”¨ï¼šåˆ›å»ºWordæ–‡æ¡£
from docx import Document

# 1. åˆ›å»ºæ–°æ–‡æ¡£
doc = Document()

# 2. æ·»åŠ æ ‡é¢˜
doc.add_heading('ç›¸å…³å·¥ä½œ', level=1)

# 3. æ·»åŠ æ®µè½
doc.add_paragraph('è¿™æ˜¯ç¬¬ä¸€æ®µå†…å®¹ã€‚')
doc.add_paragraph('è¿™æ˜¯ç¬¬äºŒæ®µå†…å®¹ã€‚')

# 4. æ·»åŠ å¸¦æ ·å¼çš„æ®µè½
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH

p = doc.add_paragraph('å¸¦æ ·å¼çš„æ®µè½')
# è®¾ç½®å­—ä½“å¤§å°
run = p.runs[0]
run.font.size = Pt(14)
# è®¾ç½®å¯¹é½æ–¹å¼
p.alignment = WD_ALIGN_PARAGRAPH.CENTER

# 5. æ·»åŠ åˆ—è¡¨
doc.add_paragraph('é¡¹ç›®1', style='List Bullet')
doc.add_paragraph('é¡¹ç›®2', style='List Bullet')
doc.add_paragraph('é¡¹ç›®3', style='List Bullet')

# 6. æ·»åŠ è¡¨æ ¼
table = doc.add_table(rows=3, cols=3)
table.rows[0].cells[0].text = 'å§“å'
table.rows[0].cells[1].text = 'å¹´é¾„'

# 7. ä¿å­˜æ–‡æ¡£
doc.save('output.docx')

# è¯»å–ç°æœ‰æ–‡æ¡£
doc = Document('existing.docx')

# éå†æ‰€æœ‰æ®µè½
for para in doc.paragraphs:
    print(para.text)

# æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨ï¼ˆç”ŸæˆWordæ–‡æ¡£ï¼‰
def generate_word_doc(content):
    """ç”ŸæˆWordæ–‡æ¡£"""
    doc = Document()
    
    # æ·»åŠ æ ‡é¢˜
    doc.add_heading('Related Work', level=1)
    
    # æ·»åŠ å†…å®¹ï¼ˆå¤„ç†æ¢è¡Œï¼‰
    paragraphs = content.split('\n')
    for para_text in paragraphs:
        if para_text.strip():
            doc.add_paragraph(para_text.strip())
    
    # ä¿å­˜
    doc.save('related_work.docx')
    return 'related_work.docx'

# é«˜çº§åŠŸèƒ½ï¼šè®¾ç½®é¡µé¢æ ·å¼
from docx.shared import Inches

# è®¾ç½®é¡µè¾¹è·
sections = doc.sections
for section in sections:
    section.top_margin = Inches(1)
    section.bottom_margin = Inches(1)
    section.left_margin = Inches(1.25)
    section.right_margin = Inches(1.25)

# æ·»åŠ é¡µçœ‰é¡µè„š
section = doc.sections[0]
header = section.header
header_para = header.paragraphs[0]
header_para.text = "ç›¸å…³å·¥ä½œ"

# æ·»åŠ å›¾ç‰‡
doc.add_picture('image.png', width=Inches(2))

# æ ·å¼å’Œæ ¼å¼
# 1. æ ‡é¢˜çº§åˆ«
doc.add_heading('ä¸€çº§æ ‡é¢˜', level=1)
doc.add_heading('äºŒçº§æ ‡é¢˜', level=2)
doc.add_heading('ä¸‰çº§æ ‡é¢˜', level=3)

# 2. æ®µè½æ ·å¼
doc.add_paragraph('æ™®é€šæ®µè½')
doc.add_paragraph('å¼•ç”¨æ®µè½', style='Intense Quote')
doc.add_paragraph('åˆ—è¡¨é¡¹', style='List Bullet')

# 3. å­—ä½“æ ·å¼
from docx.shared import RGBColor

p = doc.add_paragraph()
run = p.add_run('åŠ ç²—æ–‡æœ¬')
run.bold = True

run = p.add_run('æ–œä½“æ–‡æœ¬')
run.italic = True

run = p.add_run('å¸¦é¢œè‰²æ–‡æœ¬')
run.font.color.rgb = RGBColor(255, 0, 0)  # çº¢è‰²

# python-docx vs docx
# æ³¨æ„ï¼šå¯¼å…¥æ—¶ç”¨docxï¼Œä½†åŒ…åæ˜¯python-docx
# pip install python-docx
# from docx import Document  # æ­£ç¡®
# from python-docx import Document  # é”™è¯¯
```

**ç¬¬5è¡Œè¯¦è§£**ï¼š`import re`

```python
import re

# reæ­£åˆ™è¡¨è¾¾å¼åœ¨æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# 1. åˆ†å‰²æ–‡çŒ®ï¼ˆç¬¬65è¡Œï¼‰
parts = re.split(r'(?=æ–‡çŒ®\d+)', content)
# æŒ‰"æ–‡çŒ®1"ã€"æ–‡çŒ®2"ç­‰åˆ†å‰²

# 2. æå–æ–‡çŒ®ç¼–å·ï¼ˆç¬¬75è¡Œï¼‰
ref_id_match = re.match(r'æ–‡çŒ®(\d+)', ref_content)
ref_id = ref_id_match.group(1)  # æå–æ•°å­—

# 3. ç§»é™¤æ–‡çŒ®ç¼–å·å‰ç¼€ï¼ˆç¬¬79è¡Œï¼‰
match = re.match(r'æ–‡çŒ®\d+\s*', ref_content)
if match:
    ref_content = ref_content[match.end():]

# 4. æå–JSONå†…å®¹ï¼ˆç¬¬204-209è¡Œï¼‰
json_match = re.search(r'\{.*\}', content, re.DOTALL)

# 5. å¤„ç†LaTeXç‰¹æ®Šå­—ç¬¦ï¼ˆç¬¬298-307è¡Œï¼‰
text = text.replace('&', r'\&')
text = text.replace('%', r'\%')

# æ­£åˆ™è¡¨è¾¾å¼è¯¦ç»†è®²è§£
# 1. r'(?=æ–‡çŒ®\d+)'
# (?=...)  - æ­£å‘å…ˆè¡Œæ–­è¨€ï¼ˆlookaheadï¼‰
# æ–‡çŒ®     - å­—é¢åŒ¹é…"æ–‡çŒ®"
# \d+      - 1ä¸ªæˆ–å¤šä¸ªæ•°å­—
# æ•´ä½“æ„æ€ï¼šåŒ¹é…"æ–‡çŒ®"åè·Ÿæ•°å­—çš„ä½ç½®ï¼Œä½†ä¸åŒ…å«"æ–‡çŒ®"æœ¬èº«

# ç¤ºä¾‹
text = "æ–‡çŒ®1å†…å®¹...æ–‡çŒ®2å†…å®¹...æ–‡çŒ®3å†…å®¹..."
parts = re.split(r'(?=æ–‡çŒ®\d+)', text)
# ç»“æœï¼š['', 'æ–‡çŒ®1å†…å®¹...', 'æ–‡çŒ®2å†…å®¹...', 'æ–‡çŒ®3å†…å®¹...']

# 2. r'æ–‡çŒ®(\d+)'
# æ–‡çŒ®     - å­—é¢åŒ¹é…"æ–‡çŒ®"
# ()       - æ•è·ç»„
# \d+      - 1ä¸ªæˆ–å¤šä¸ªæ•°å­—
# æ•´ä½“æ„æ€ï¼šåŒ¹é…"æ–‡çŒ®"åŠ æ•°å­—ï¼Œå¹¶æ•è·æ•°å­—éƒ¨åˆ†

# ç¤ºä¾‹
text = "æ–‡çŒ®123"
match = re.match(r'æ–‡çŒ®(\d+)', text)
if match:
    print(match.group(0))  # "æ–‡çŒ®123"ï¼ˆå®Œæ•´åŒ¹é…ï¼‰
    print(match.group(1))  # "123"ï¼ˆç¬¬ä¸€ä¸ªæ•è·ç»„ï¼‰

# 3. r'\{.*\}' with re.DOTALL
# \{       - å­—é¢åŒ¹é…å·¦èŠ±æ‹¬å·
# .*       - ä»»æ„å­—ç¬¦ï¼ˆ0ä¸ªæˆ–å¤šä¸ªï¼‰
# \}       - å­—é¢åŒ¹é…å³èŠ±æ‹¬å·
# re.DOTALL - .åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„æ‰€æœ‰å­—ç¬¦

# ç¤ºä¾‹
text = """
ä¸€äº›æ–‡æœ¬
{"key": "value"}
æ›´å¤šæ–‡æœ¬
"""
match = re.search(r'\{.*\}', text, re.DOTALL)
if match:
    json_str = match.group()  # '{"key": "value"}'
```

**ç¬¬6è¡Œè¯¦è§£**ï¼š`import time`

```python
import time

# timeæ¨¡å—åœ¨æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
# 1. APIè°ƒç”¨åå»¶è¿Ÿï¼ˆç¬¬189è¡Œï¼‰
time.sleep(1)  # æš‚åœ1ç§’

# ä¸ºä»€ä¹ˆéœ€è¦å»¶è¿Ÿï¼Ÿ
# 1. é¿å…APIè°ƒç”¨é¢‘ç‡è¿‡é«˜
# 2. ç»™æœåŠ¡å™¨ç¼“å†²æ—¶é—´
# 3. é˜²æ­¢è¢«é™æµæˆ–å°ç¦

# time.sleep()è¯¦è§£
import time

# æš‚åœæŒ‡å®šç§’æ•°
time.sleep(1)      # æš‚åœ1ç§’
time.sleep(0.5)    # æš‚åœ0.5ç§’
time.sleep(2.5)    # æš‚åœ2.5ç§’

# å®é™…åº”ç”¨ï¼šAPIè°ƒç”¨é—´éš”
for i in range(10):
    call_api()      # è°ƒç”¨API
    time.sleep(1)   # ç­‰å¾…1ç§’å†è°ƒç”¨ä¸‹ä¸€æ¬¡

# è¿›åº¦æ˜¾ç¤º
import time

for i in range(5):
    print(f"å¤„ç†ç¬¬{i+1}é¡¹...")
    time.sleep(1)
    print(f"ç¬¬{i+1}é¡¹å®Œæˆ")

# timeæ¨¡å—çš„å…¶ä»–å¸¸ç”¨å‡½æ•°
import time

# 1. è·å–å½“å‰æ—¶é—´æˆ³
timestamp = time.time()
print(timestamp)  # 1699999999.123456

# 2. è·å–å½“å‰æ—¶é—´ï¼ˆç»“æ„åŒ–ï¼‰
current_time = time.localtime()
print(current_time)
# time.struct_time(tm_year=2024, tm_mon=1, tm_mday=15, ...)

# 3. æ ¼å¼åŒ–æ—¶é—´
formatted = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
print(formatted)  # "2024-01-15 14:30:25"

# 4. æ€§èƒ½è®¡æ—¶
start = time.time()
# æ‰§è¡Œä¸€äº›æ“ä½œ
time.sleep(2)
end = time.time()
duration = end - start
print(f"è€—æ—¶: {duration:.2f}ç§’")

# sleep vs delay
# time.sleep() - é˜»å¡å½“å‰çº¿ç¨‹
# ä¼˜ç‚¹ï¼šç®€å•
# ç¼ºç‚¹ï¼šé˜»å¡æ•´ä¸ªç¨‹åº

# asyncio.sleep() - å¼‚æ­¥ç­‰å¾…ï¼ˆä¸é˜»å¡ï¼‰
import asyncio

async def async_task():
    print("å¼€å§‹")
    await asyncio.sleep(1)  # ä¸é˜»å¡å…¶ä»–ä»»åŠ¡
    print("ç»“æŸ")
```

---

## ğŸ“ DocumentGeneratorç±»è¯¦è§£

### ç±»å®šä¹‰ï¼ˆç¬¬9è¡Œï¼‰

```python
class DocumentGenerator:                 # ç¬¬9è¡Œ
```

**ç¬¬9è¡Œè¯¦è§£**ï¼š`class DocumentGenerator:`

**ç±»å®šä¹‰è¯¦è§£ï¼ˆç¬¬9è¡Œï¼‰**ï¼š
- `class`ï¼šPythonå…³é”®å­—ï¼Œå®šä¹‰ç±»
- `DocumentGenerator`ï¼šç±»åï¼ˆé©¼å³°å‘½åæ³•ï¼‰
- `:`ï¼šç±»å®šä¹‰ç»“æŸç¬¦

```python
class DocumentGenerator:
    """æ–‡æ¡£ç”Ÿæˆå™¨ç±»"""

# ç±»æ˜¯ä»€ä¹ˆï¼Ÿ
# 1. é¢å‘å¯¹è±¡ç¼–ç¨‹çš„åŸºç¡€
# 2. æ•°æ®å’Œæ–¹æ³•çš„å°è£…
# 3. åˆ›å»ºå¯¹è±¡çš„æ¨¡æ¿

# ä¸ºä»€ä¹ˆç”¨ç±»ï¼Ÿ
# 1. ç»„ç»‡ç›¸å…³åŠŸèƒ½
# 2. æ•°æ®å°è£…
# 3. ä»£ç å¤ç”¨
# 4. çŠ¶æ€ç®¡ç†

# ç±» vs å‡½æ•°
# å‡½æ•°å¼å†™æ³•ï¼ˆæ— çŠ¶æ€ï¼‰
def generate_document(api_key, model, topic):
    # æ¯æ¬¡éƒ½è¦ä¼ é€’æ‰€æœ‰å‚æ•°
    pass

# é¢å‘å¯¹è±¡å†™æ³•ï¼ˆæœ‰çŠ¶æ€ï¼‰
class DocumentGenerator:
    def __init__(self, api_key, model):
        self.api_key = api_key  # çŠ¶æ€ä¿å­˜åœ¨å¯¹è±¡ä¸­
        self.model = model
    
    def generate(self, topic):
        # ä½¿ç”¨å¯¹è±¡çš„çŠ¶æ€
        pass

# ä½¿ç”¨ç±»çš„å¥½å¤„
# 1. é…ç½®åªéœ€è®¾ç½®ä¸€æ¬¡
generator = DocumentGenerator(api_key="...", model="gpt-4")
# 2. å¤šæ¬¡è°ƒç”¨ï¼ŒçŠ¶æ€ä¿æŒ
doc1 = generator.generate("Topic 1")
doc2 = generator.generate("Topic 2")

# ç±»çš„å‘½åè§„èŒƒ
# 1. é©¼å³°å‘½åæ³•ï¼ˆCamelCaseï¼‰
class DocumentGenerator:    # âœ“ æ­£ç¡®
class document_generator:   # âœ— é”™è¯¯ï¼ˆåº”è¯¥ç”¨é©¼å³°ï¼‰
class documentgenerator:    # âœ— é”™è¯¯ï¼ˆéš¾ä»¥é˜…è¯»ï¼‰

# 2. åè¯æˆ–åè¯çŸ­è¯­
class Generator:            # âœ“ å¥½
class DocumentProcessor:    # âœ“ å¥½
class GenerateDocument:     # âœ— ä¸å¥½ï¼ˆåº”è¯¥æ˜¯åè¯ï¼‰

# ç±»çš„åŸºæœ¬ç»“æ„
class DocumentGenerator:
    # ç±»å˜é‡ï¼ˆæ‰€æœ‰å®ä¾‹å…±äº«ï¼‰
    version = "1.0"
    
    # åˆå§‹åŒ–æ–¹æ³•ï¼ˆæ„é€ å‡½æ•°ï¼‰
    def __init__(self, api_key):
        # å®ä¾‹å˜é‡ï¼ˆæ¯ä¸ªå®ä¾‹ç‹¬ç«‹ï¼‰
        self.api_key = api_key
    
    # å®ä¾‹æ–¹æ³•
    def generate(self, topic):
        # ä½¿ç”¨selfè®¿é—®å®ä¾‹å˜é‡
        print(f"ä½¿ç”¨{self.api_key}ç”Ÿæˆ{topic}")
    
    # ç±»æ–¹æ³•
    @classmethod
    def from_config(cls, config):
        return cls(config['api_key'])
    
    # é™æ€æ–¹æ³•
    @staticmethod
    def validate_topic(topic):
        return len(topic) > 0

# ä½¿ç”¨ç¤ºä¾‹
# 1. åˆ›å»ºå®ä¾‹
gen = DocumentGenerator(api_key="sk-...")

# 2. è°ƒç”¨æ–¹æ³•
gen.generate("AI Research")

# 3. è®¿é—®ç±»å˜é‡
print(DocumentGenerator.version)

# 4. ä½¿ç”¨ç±»æ–¹æ³•
config = {'api_key': 'sk-...'}
gen2 = DocumentGenerator.from_config(config)

# 5. ä½¿ç”¨é™æ€æ–¹æ³•
is_valid = DocumentGenerator.validate_topic("Topic")
```

---

## âš™ï¸ åˆå§‹åŒ–æ–¹æ³•è¯¦è§£

### __init__æ–¹æ³•å®šä¹‰ï¼ˆç¬¬10-14è¡Œï¼‰

```python
def __init__(self,                       # ç¬¬10è¡Œ
             api_key=None,               # ç¬¬11è¡Œ
             model=None,                 # ç¬¬12è¡Œ
             base_url=None,              # ç¬¬13è¡Œ
             model_provider="gpt"):      # ç¬¬14è¡Œ
    """åˆå§‹åŒ–æ–‡æ¡£ç”Ÿæˆå™¨"""                # ç¬¬15è¡Œ
```

**ç¬¬10è¡Œè¯¦è§£**ï¼š`def __init__(self,`

**__init__æ„é€ å‡½æ•°è¯¦è§£ï¼ˆç¬¬10è¡Œï¼‰**ï¼š
- `def`ï¼šå®šä¹‰å‡½æ•°/æ–¹æ³•
- `__init__`ï¼šç‰¹æ®Šæ–¹æ³•åï¼Œæ„é€ å‡½æ•°
- `self`ï¼šç¬¬ä¸€ä¸ªå‚æ•°ï¼ŒæŒ‡å‘å®ä¾‹æœ¬èº«
- ç”¨é€”ï¼šåˆå§‹åŒ–å¯¹è±¡çš„å±æ€§

```python
def __init__(self, api_key=None, model=None, base_url=None, model_provider="gpt"):
    """åˆå§‹åŒ–æ–‡æ¡£ç”Ÿæˆå™¨"""

# __init__æ˜¯ä»€ä¹ˆï¼Ÿ
# 1. ç‰¹æ®Šæ–¹æ³•ï¼ˆé­”æœ¯æ–¹æ³•ï¼‰
# 2. åˆ›å»ºå¯¹è±¡æ—¶è‡ªåŠ¨è°ƒç”¨
# 3. ç”¨äºåˆå§‹åŒ–å¯¹è±¡å±æ€§

# __init__çš„å·¥ä½œæµç¨‹
class DocumentGenerator:
    def __init__(self, api_key):
        print("__init__è¢«è°ƒç”¨")
        self.api_key = api_key

# åˆ›å»ºå¯¹è±¡æ—¶
gen = DocumentGenerator("sk-...")
# è¾“å‡ºï¼š__init__è¢«è°ƒç”¨

# å®Œæ•´è¿‡ç¨‹ï¼š
# 1. Pythonåˆ›å»ºç©ºå¯¹è±¡
# 2. è‡ªåŠ¨è°ƒç”¨__init__
# 3. è®¾ç½®å¯¹è±¡å±æ€§
# 4. è¿”å›åˆå§‹åŒ–å¥½çš„å¯¹è±¡

# selfå‚æ•°è¯¦è§£
class DocumentGenerator:
    def __init__(self, api_key):
        self.api_key = api_key  # selfæŒ‡å‘å½“å‰å¯¹è±¡

# åˆ›å»ºä¸¤ä¸ªå¯¹è±¡
gen1 = DocumentGenerator("key1")
gen2 = DocumentGenerator("key2")

# æ¯ä¸ªå¯¹è±¡çš„selfä¸åŒ
# gen1çš„self.api_key = "key1"
# gen2çš„self.api_key = "key2"

# ä¸ºä»€ä¹ˆç¬¬ä¸€ä¸ªå‚æ•°å¿…é¡»æ˜¯selfï¼Ÿ
# 1. Pythonçº¦å®šï¼ˆå¯ä»¥ç”¨å…¶ä»–åå­—ï¼Œä½†ä¸æ¨èï¼‰
# 2. ç”¨äºåŒºåˆ†å®ä¾‹å˜é‡å’Œå±€éƒ¨å˜é‡

class Example:
    def __init__(self, value):
        self.value = value      # å®ä¾‹å˜é‡
        local_var = value * 2   # å±€éƒ¨å˜é‡ï¼ˆæ–¹æ³•ç»“æŸåæ¶ˆå¤±ï¼‰

# é»˜è®¤å‚æ•°è¯¦è§£
def __init__(self, api_key=None, model=None):
    # api_key=None - é»˜è®¤å‚æ•°
    # å¦‚æœä¸æä¾›ï¼Œä½¿ç”¨None

# è°ƒç”¨æ–¹å¼
# 1. æä¾›æ‰€æœ‰å‚æ•°
gen = DocumentGenerator(api_key="sk-...", model="gpt-4")

# 2. åªæä¾›éƒ¨åˆ†å‚æ•°
gen = DocumentGenerator(api_key="sk-...")
# modelä½¿ç”¨é»˜è®¤å€¼None

# 3. ä½¿ç”¨å…³é”®å­—å‚æ•°ï¼ˆæ¨èï¼‰
gen = DocumentGenerator(
    api_key="sk-...",
    model="gpt-4",
    model_provider="deepseek"
)

# 4. ä½ç½®å‚æ•°
gen = DocumentGenerator("sk-...", "gpt-4")
# ä¸æ¨èï¼šå®¹æ˜“æ··æ·†å‚æ•°é¡ºåº

# __init__ä¸­å¸¸è§çš„æ“ä½œ
class DocumentGenerator:
    def __init__(self, api_key):
        # 1. ä¿å­˜å‚æ•°åˆ°å®ä¾‹å˜é‡
        self.api_key = api_key
        
        # 2. åˆå§‹åŒ–å…¶ä»–å±æ€§
        self.reference_map = {}
        self.cited_refs = set()
        
        # 3. åˆ›å»ºå®¢æˆ·ç«¯å¯¹è±¡
        self.client = OpenAI(api_key=api_key)
        
        # 4. æ‰§è¡Œåˆå§‹åŒ–é€»è¾‘
        print("æ–‡æ¡£ç”Ÿæˆå™¨å·²åˆå§‹åŒ–")

# __init__ vs __new__
# __new__ï¼šåˆ›å»ºå¯¹è±¡ï¼ˆå¾ˆå°‘ç”¨ï¼‰
# __init__ï¼šåˆå§‹åŒ–å¯¹è±¡ï¼ˆå¸¸ç”¨ï¼‰

# __init__è¿”å›å€¼
# æ³¨æ„ï¼š__init__ä¸åº”è¯¥è¿”å›ä»»ä½•å€¼ï¼ˆé™¤äº†Noneï¼‰
def __init__(self):
    # return None  # éšå¼è¿”å›
    pass

# é”™è¯¯ç¤ºä¾‹
def __init__(self):
    return self  # âœ— é”™è¯¯ï¼ä¸åº”è¯¥è¿”å›å€¼
```

### é»˜è®¤é…ç½®å­—å…¸ï¼ˆç¬¬17-29è¡Œï¼‰

```python
# é»˜è®¤æ¨¡å‹é…ç½®                            # ç¬¬17è¡Œï¼ˆæ³¨é‡Šï¼‰
default_configs = {                      # ç¬¬18è¡Œ
    "gpt": {                             # ç¬¬19è¡Œ
        "api_key": "sk-VO4yKA1bIncBuC1TKM8jpQlROLAqcRx0CDlODqkLcffDhdRo",  # ç¬¬20è¡Œ
        "base_url": "https://chat01.ai/v1",  # ç¬¬21è¡Œ
        "model": "gpt-4.5-preview"       # ç¬¬22è¡Œ
    },                                   # ç¬¬23è¡Œ
    "deepseek": {                        # ç¬¬24è¡Œ
        "api_key": "sk-771cca9e3f9e489e9ea1f5fb9f800a2f",  # ç¬¬25è¡Œ
        "base_url": "https://api.deepseek.com",  # ç¬¬26è¡Œ
        "model": "deepseek-chat"         # ç¬¬27è¡Œ
    }                                    # ç¬¬28è¡Œ
}                                        # ç¬¬29è¡Œ
```

**é…ç½®å­—å…¸è¯¦è§£ï¼ˆç¬¬18-29è¡Œï¼‰**ï¼š

```python
default_configs = {
    "gpt": {
        "api_key": "...",
        "base_url": "https://chat01.ai/v1",
        "model": "gpt-4.5-preview"
    },
    "deepseek": {
        "api_key": "...",
        "base_url": "https://api.deepseek.com",
        "model": "deepseek-chat"
    }
}

# åµŒå¥—å­—å…¸ç»“æ„
# å¤–å±‚å­—å…¸ï¼šmodel_provider â†’ é…ç½®
# å†…å±‚å­—å…¸ï¼šé…ç½®é¡¹ â†’ å€¼

# æ•°æ®ç»“æ„å¯è§†åŒ–
default_configs = {
    "gpt": {                  â† æ¨¡å‹æä¾›å•†
        "api_key": "...",     â† APIå¯†é’¥
        "base_url": "...",    â† APIç«¯ç‚¹
        "model": "..."        â† æ¨¡å‹åç§°
    },
    "deepseek": { ... }
}

# è®¿é—®é…ç½®
# 1. è·å–æ•´ä¸ªé…ç½®
gpt_config = default_configs["gpt"]
# {'api_key': '...', 'base_url': '...', 'model': '...'}

# 2. è·å–ç‰¹å®šé…ç½®é¡¹
api_key = default_configs["gpt"]["api_key"]
# "sk-..."

# 3. ä½¿ç”¨get()æ–¹æ³•ï¼ˆæ›´å®‰å…¨ï¼‰
config = default_configs.get("gpt", {})
# å¦‚æœ"gpt"ä¸å­˜åœ¨ï¼Œè¿”å›{}è€Œä¸æ˜¯æŠ¥é”™

# ä¸ºä»€ä¹ˆç”¨å­—å…¸å­˜å‚¨é…ç½®ï¼Ÿ
# 1. ç»“æ„æ¸…æ™°
# 2. æ˜“äºæ‰©å±•ï¼ˆæ·»åŠ æ–°çš„æä¾›å•†ï¼‰
# 3. æ˜“äºè®¿é—®ï¼ˆé€šè¿‡é”®è·å–ï¼‰

# æ·»åŠ æ–°çš„æ¨¡å‹æä¾›å•†
default_configs["claude"] = {
    "api_key": "sk-...",
    "base_url": "https://api.anthropic.com",
    "model": "claude-3"
}

# é…ç½®çš„ä½¿ç”¨ï¼ˆç¬¬32-42è¡Œï¼‰
if model_provider in default_configs:
    # è·å–å¯¹åº”çš„é…ç½®
    config = default_configs[model_provider]
    # ä½¿ç”¨é…ç½®æˆ–ç”¨æˆ·æä¾›çš„å€¼
    self.api_key = api_key if api_key else config["api_key"]

# ç­‰ä»·çš„if-elseå†™æ³•
if api_key:
    self.api_key = api_key           # ç”¨æˆ·æä¾›äº†ï¼Œç”¨ç”¨æˆ·çš„
else:
    self.api_key = config["api_key"] # ç”¨æˆ·æ²¡æä¾›ï¼Œç”¨é»˜è®¤çš„

# ä¸‰å…ƒè¡¨è¾¾å¼ï¼ˆç¬¬34è¡Œï¼‰
self.api_key = api_key if api_key else config["api_key"]
# è¯­æ³•ï¼šå€¼1 if æ¡ä»¶ else å€¼2

# å®é™…ä½¿ç”¨ç¤ºä¾‹
# åœºæ™¯1ï¼šä½¿ç”¨é»˜è®¤GPTé…ç½®
gen = DocumentGenerator(model_provider="gpt")
# ä½¿ç”¨é»˜è®¤çš„api_keyã€base_urlã€model

# åœºæ™¯2ï¼šä½¿ç”¨DeepSeeké…ç½®
gen = DocumentGenerator(model_provider="deepseek")

# åœºæ™¯3ï¼šè‡ªå®šä¹‰APIå¯†é’¥
gen = DocumentGenerator(
    api_key="my-custom-key",
    model_provider="gpt"
)
# api_keyä½¿ç”¨è‡ªå®šä¹‰çš„ï¼Œbase_urlå’Œmodelä½¿ç”¨é»˜è®¤çš„

# åœºæ™¯4ï¼šå®Œå…¨è‡ªå®šä¹‰
gen = DocumentGenerator(
    api_key="my-key",
    model="gpt-4-turbo",
    base_url="https://my-proxy.com/v1",
    model_provider="gpt"
)

# âš ï¸ å®‰å…¨è­¦å‘Š
# åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼ŒAPIå¯†é’¥ä¸åº”è¯¥ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
# åº”è¯¥ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶

# æ¨èåšæ³•ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
import os

default_configs = {
    "gpt": {
        "api_key": os.getenv("OPENAI_API_KEY"),  # ä»ç¯å¢ƒå˜é‡è¯»å–
        "base_url": "https://api.openai.com/v1",
        "model": "gpt-4"
    }
}

# æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶
import json

with open('config.json', 'r') as f:
    default_configs = json.load(f)
```

### åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆç¬¬46-51è¡Œï¼‰

```python
self.client = OpenAI(                    # ç¬¬46è¡Œ
    api_key=self.api_key,                # ç¬¬47è¡Œ
    base_url=self.base_url,              # ç¬¬48è¡Œ
    timeout=60.0,  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’  # ç¬¬49è¡Œ
    max_retries=3   # è®¾ç½®é‡è¯•æ¬¡æ•°        # ç¬¬50è¡Œ
)                                        # ç¬¬51è¡Œ
```

**OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–è¯¦è§£ï¼ˆç¬¬46-51è¡Œï¼‰**ï¼š

```python
self.client = OpenAI(
    api_key=self.api_key,
    base_url=self.base_url,
    timeout=60.0,
    max_retries=3
)

# åˆ›å»ºOpenAIå®¢æˆ·ç«¯å¯¹è±¡
# self.client - å®ä¾‹å˜é‡ï¼Œä¿å­˜å®¢æˆ·ç«¯å¯¹è±¡
# åç»­å¯ä»¥ç”¨self.clientè°ƒç”¨API

# OpenAIå®¢æˆ·ç«¯å‚æ•°è¯¦è§£
# 1. api_key - APIå¯†é’¥
api_key=self.api_key
# ç”¨äºèº«ä»½éªŒè¯ï¼Œè°ƒç”¨APIæ—¶å¿…éœ€

# 2. base_url - APIç«¯ç‚¹
base_url=self.base_url
# OpenAIå®˜æ–¹ï¼šhttps://api.openai.com/v1
# ä»£ç†æˆ–å…¼å®¹APIï¼šå…¶ä»–URL

# 3. timeout - è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
timeout=60.0
# å¦‚æœ60ç§’å†…æ²¡æœ‰å“åº”ï¼ŒæŠ›å‡ºè¶…æ—¶å¼‚å¸¸
# ä¸ºä»€ä¹ˆè®¾ç½®60ç§’ï¼Ÿç”Ÿæˆé•¿æ–‡æœ¬å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´

# 4. max_retries - æœ€å¤§é‡è¯•æ¬¡æ•°
max_retries=3
# APIè°ƒç”¨å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨é‡è¯•3æ¬¡
# é€‚ç”¨äºç½‘ç»œä¸ç¨³å®šçš„æƒ…å†µ

# è¶…æ—¶è®¾ç½®çš„é‡è¦æ€§
# ä¸è®¾ç½®è¶…æ—¶çš„é—®é¢˜ï¼š
client = OpenAI(api_key="...")
# å¦‚æœæœåŠ¡å™¨æ— å“åº”ï¼Œç¨‹åºä¼šä¸€ç›´ç­‰å¾…ï¼ˆæŒ‚èµ·ï¼‰

# è®¾ç½®è¶…æ—¶åï¼š
client = OpenAI(api_key="...", timeout=60.0)
# 60ç§’åæŠ›å‡ºTimeoutErrorï¼Œç¨‹åºå¯ä»¥ç»§ç»­

# è¶…æ—¶æ—¶é—´çš„é€‰æ‹©
# çŸ­ä»»åŠ¡ï¼ˆç®€å•é—®ç­”ï¼‰ï¼š10-30ç§’
client = OpenAI(timeout=30.0)

# é•¿ä»»åŠ¡ï¼ˆç”Ÿæˆé•¿æ–‡æœ¬ï¼‰ï¼š60-120ç§’
client = OpenAI(timeout=60.0)  # æœ¬é¡¹ç›®

# éå¸¸é•¿çš„ä»»åŠ¡ï¼šå¯ä»¥æ›´é•¿
client = OpenAI(timeout=300.0)  # 5åˆ†é’Ÿ

# é‡è¯•æœºåˆ¶è¯¦è§£
max_retries=3

# å·¥ä½œåŸç†ï¼š
# ç¬¬1æ¬¡è°ƒç”¨å¤±è´¥ â†’ é‡è¯•
# ç¬¬2æ¬¡è°ƒç”¨å¤±è´¥ â†’ é‡è¯•
# ç¬¬3æ¬¡è°ƒç”¨å¤±è´¥ â†’ é‡è¯•
# ç¬¬4æ¬¡è¿˜å¤±è´¥ â†’ æŠ›å‡ºå¼‚å¸¸

# é€‚ç”¨åœºæ™¯ï¼š
# 1. ä¸´æ—¶ç½‘ç»œé—®é¢˜
# 2. æœåŠ¡å™¨çŸ­æš‚æ•…éšœ
# 3. APIé™æµï¼ˆçŸ­æš‚å»¶è¿Ÿåå¯èƒ½æˆåŠŸï¼‰

# é‡è¯•ç­–ç•¥
from openai import OpenAI
import time

# OpenAIå®¢æˆ·ç«¯å†…ç½®é‡è¯•ï¼ˆæ¨èï¼‰
client = OpenAI(max_retries=3)

# æ‰‹åŠ¨é‡è¯•ï¼ˆä¸æ¨èï¼Œä½†æ›´çµæ´»ï¼‰
for attempt in range(3):
    try:
        response = client.chat.completions.create(...)
        break  # æˆåŠŸï¼Œè·³å‡ºå¾ªç¯
    except Exception as e:
        if attempt < 2:  # ä¸æ˜¯æœ€åä¸€æ¬¡
            print(f"é‡è¯• {attempt + 1}/3...")
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        else:
            raise  # æœ€åä¸€æ¬¡å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸

# ä½¿ç”¨å®¢æˆ·ç«¯è°ƒç”¨APIï¼ˆç¬¬178-186è¡Œï¼‰
response = self.client.chat.completions.create(
    model=self.model,
    messages=[
        {"role": "system", "content": "..."},
        {"role": "user", "content": "..."}
    ]
)

# å®Œæ•´çš„å®¢æˆ·ç«¯é…ç½®ç¤ºä¾‹
from openai import OpenAI

# æœ€å°é…ç½®
client = OpenAI(api_key="sk-...")

# æ¨èé…ç½®
client = OpenAI(
    api_key="sk-...",
    base_url="https://api.openai.com/v1",
    timeout=60.0,
    max_retries=3
)

# é«˜çº§é…ç½®
client = OpenAI(
    api_key="sk-...",
    base_url="https://api.openai.com/v1",
    timeout=60.0,
    max_retries=3,
    default_headers={
        "User-Agent": "MyApp/1.0"
    },
    default_query={
        "custom_param": "value"
    }
)

# é”™è¯¯å¤„ç†
try:
    response = client.chat.completions.create(...)
except openai.APITimeoutError:
    print("APIè¶…æ—¶")
except openai.APIConnectionError:
    print("è¿æ¥å¤±è´¥")
except openai.RateLimitError:
    print("APIè°ƒç”¨é¢‘ç‡è¶…é™")
except Exception as e:
    print(f"å…¶ä»–é”™è¯¯: {e}")
```

### åˆå§‹åŒ–å®ä¾‹å˜é‡ï¼ˆç¬¬52-55è¡Œï¼‰

```python
# æ·»åŠ å­˜å‚¨æ–‡çŒ®åŸå§‹å†…å®¹çš„å­—å…¸            # ç¬¬52è¡Œï¼ˆæ³¨é‡Šï¼‰
self.reference_map = {}                  # ç¬¬53è¡Œ
# å·²å¼•ç”¨çš„æ–‡çŒ®é›†åˆ                      # ç¬¬54è¡Œï¼ˆæ³¨é‡Šï¼‰
self.cited_refs = set()                  # ç¬¬55è¡Œ
```

**å®ä¾‹å˜é‡åˆå§‹åŒ–è¯¦è§£ï¼ˆç¬¬53ã€55è¡Œï¼‰**ï¼š

```python
self.reference_map = {}    # æ–‡çŒ®æ˜ å°„å­—å…¸
self.cited_refs = set()    # å·²å¼•ç”¨æ–‡çŒ®é›†åˆ

# å®ä¾‹å˜é‡ vs å±€éƒ¨å˜é‡
class DocumentGenerator:
    def __init__(self):
        self.reference_map = {}  # å®ä¾‹å˜é‡ï¼ˆå¯¹è±¡å±æ€§ï¼‰
        local_var = "test"       # å±€éƒ¨å˜é‡ï¼ˆæ–¹æ³•ç»“æŸåæ¶ˆå¤±ï¼‰

# å®ä¾‹å˜é‡çš„ä½œç”¨åŸŸ
gen = DocumentGenerator()
print(gen.reference_map)  # âœ“ å¯ä»¥è®¿é—®
print(gen.local_var)      # âœ— é”™è¯¯ï¼å±€éƒ¨å˜é‡å·²æ¶ˆå¤±

# å®ä¾‹å˜é‡åœ¨ä¸åŒæ–¹æ³•é—´å…±äº«
class DocumentGenerator:
    def __init__(self):
        self.reference_map = {}
    
    def load_references(self):
        # å¯ä»¥è®¿é—®å’Œä¿®æ”¹self.reference_map
        self.reference_map["1"] = "Reference 1"
    
    def get_reference(self, ref_id):
        # å…¶ä»–æ–¹æ³•ä¹Ÿå¯ä»¥è®¿é—®
        return self.reference_map.get(ref_id)

# ä½¿ç”¨ç¤ºä¾‹
gen = DocumentGenerator()
gen.load_references()
ref = gen.get_reference("1")
print(ref)  # "Reference 1"

# reference_mapå­—å…¸è¯¦è§£
self.reference_map = {}
# ç”¨é€”ï¼šå­˜å‚¨æ–‡çŒ®ç¼–å· â†’ æ–‡çŒ®å†…å®¹çš„æ˜ å°„

# æ•°æ®ç»“æ„
self.reference_map = {
    "1": "Zhang et al. (2024). Deep Learning...",
    "2": "Li et al. (2023). Machine Learning...",
    "3": "Wang et al. (2024). Neural Networks..."
}

# ä½¿ç”¨æ–¹å¼
# 1. æ·»åŠ æ–‡çŒ®
self.reference_map["1"] = "æ–‡çŒ®å†…å®¹..."

# 2. è·å–æ–‡çŒ®
content = self.reference_map["1"]

# 3. æ£€æŸ¥æ–‡çŒ®æ˜¯å¦å­˜åœ¨
if "1" in self.reference_map:
    print("æ–‡çŒ®1å­˜åœ¨")

# 4. éå†æ‰€æœ‰æ–‡çŒ®
for ref_id, content in self.reference_map.items():
    print(f"æ–‡çŒ®{ref_id}: {content[:50]}...")

# cited_refsé›†åˆè¯¦è§£
self.cited_refs = set()
# ç”¨é€”ï¼šè®°å½•å“ªäº›æ–‡çŒ®å·²ç»è¢«å¼•ç”¨

# é›†åˆçš„ç‰¹ç‚¹
# 1. æ— åº
# 2. ä¸é‡å¤
# 3. å¿«é€ŸæŸ¥æ‰¾ï¼ˆO(1)æ—¶é—´å¤æ‚åº¦ï¼‰

# æ•°æ®ç»“æ„
self.cited_refs = {"1", "3", "5"}
# è¡¨ç¤ºæ–‡çŒ®1ã€3ã€5å·²è¢«å¼•ç”¨

# ä½¿ç”¨æ–¹å¼
# 1. æ·»åŠ å¼•ç”¨
self.cited_refs.add("1")
self.cited_refs.add("1")  # é‡å¤æ·»åŠ æ— æ•ˆï¼ˆè‡ªåŠ¨å»é‡ï¼‰

# 2. æ£€æŸ¥æ˜¯å¦å·²å¼•ç”¨
if "1" in self.cited_refs:
    print("æ–‡çŒ®1å·²è¢«å¼•ç”¨")

# 3. ç§»é™¤å¼•ç”¨
self.cited_refs.discard("1")

# 4. æ¸…ç©ºæ‰€æœ‰å¼•ç”¨
self.cited_refs.clear()

# ä¸ºä»€ä¹ˆç”¨setè€Œä¸æ˜¯listï¼Ÿ
# listç‰ˆæœ¬ï¼ˆä¸æ¨èï¼‰ï¼š
self.cited_refs = []
if "1" not in self.cited_refs:  # O(n)æ—¶é—´å¤æ‚åº¦
    self.cited_refs.append("1")

# setç‰ˆæœ¬ï¼ˆæ¨èï¼‰ï¼š
self.cited_refs = set()
self.cited_refs.add("1")  # O(1)æ—¶é—´å¤æ‚åº¦ï¼Œè‡ªåŠ¨å»é‡

# å®Œæ•´çš„ä½¿ç”¨åœºæ™¯
class DocumentGenerator:
    def __init__(self):
        self.reference_map = {}   # æ–‡çŒ®åº“
        self.cited_refs = set()   # å¼•ç”¨è®°å½•
    
    def load_reference(self, ref_id, content):
        """åŠ è½½æ–‡çŒ®"""
        self.reference_map[ref_id] = content
    
    def cite_reference(self, ref_id):
        """å¼•ç”¨æ–‡çŒ®"""
        if ref_id in self.reference_map:
            self.cited_refs.add(ref_id)
            return self.reference_map[ref_id]
        return None
    
    def get_uncited_references(self):
        """è·å–æœªå¼•ç”¨çš„æ–‡çŒ®"""
        all_refs = set(self.reference_map.keys())
        return all_refs - self.cited_refs

# ä½¿ç”¨ç¤ºä¾‹
gen = DocumentGenerator()
gen.load_reference("1", "æ–‡çŒ®1å†…å®¹...")
gen.load_reference("2", "æ–‡çŒ®2å†…å®¹...")
gen.cite_reference("1")
uncited = gen.get_uncited_references()
print(f"æœªå¼•ç”¨çš„æ–‡çŒ®: {uncited}")  # {'2'}
```

---

## ğŸ“š æ–‡çŒ®åŠ è½½æ–¹æ³•

### load_all_referencesæ–¹æ³•ï¼ˆç¬¬57-92è¡Œï¼‰

```python
def load_all_references(self, file_path="2.txt"):  # ç¬¬57è¡Œ
    """ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡çŒ®å¼•ç”¨"""                 # ç¬¬58è¡Œ
    references = []                              # ç¬¬59è¡Œ
    try:                                         # ç¬¬60è¡Œ
        with open(file_path, 'r', encoding='utf-8') as f:  # ç¬¬61è¡Œ
            content = f.read()                   # ç¬¬62è¡Œ
```

**ç¬¬57è¡Œè¯¦è§£**ï¼š`def load_all_references(self, file_path="2.txt"):`

**æ–¹æ³•å®šä¹‰å’Œé»˜è®¤å‚æ•°è¯¦è§£ï¼ˆç¬¬57è¡Œï¼‰**ï¼š
- `self`ï¼šç¬¬ä¸€ä¸ªå‚æ•°ï¼ŒæŒ‡å‘å®ä¾‹
- `file_path="2.txt"`ï¼šé»˜è®¤å‚æ•°ï¼Œé»˜è®¤æ–‡ä»¶å

```python
def load_all_references(self, file_path="2.txt"):
    """ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡çŒ®å¼•ç”¨"""

# æ–¹æ³• vs å‡½æ•°
# æ–¹æ³•ï¼ˆMethodï¼‰ï¼š
# - å®šä¹‰åœ¨ç±»ä¸­
# - ç¬¬ä¸€ä¸ªå‚æ•°å¿…é¡»æ˜¯self
# - é€šè¿‡å¯¹è±¡è°ƒç”¨

class DocumentGenerator:
    def load_all_references(self, file_path="2.txt"):
        # è¿™æ˜¯ä¸€ä¸ªæ–¹æ³•
        pass

# å‡½æ•°ï¼ˆFunctionï¼‰ï¼š
# - å®šä¹‰åœ¨ç±»å¤–
# - æ²¡æœ‰selfå‚æ•°
# - ç›´æ¥è°ƒç”¨

def load_references(file_path):
    # è¿™æ˜¯ä¸€ä¸ªå‡½æ•°
    pass

# è°ƒç”¨æ–¹å¼å¯¹æ¯”
# è°ƒç”¨æ–¹æ³•
gen = DocumentGenerator()
gen.load_all_references("data.txt")

# è°ƒç”¨å‡½æ•°
load_references("data.txt")

# é»˜è®¤å‚æ•°çš„ä½¿ç”¨
# 1. ä½¿ç”¨é»˜è®¤å€¼
gen.load_all_references()
# ç­‰ä»·äº
gen.load_all_references("2.txt")

# 2. æŒ‡å®šå‚æ•°
gen.load_all_references("custom.txt")

# 3. ä½¿ç”¨å…³é”®å­—å‚æ•°
gen.load_all_references(file_path="my_file.txt")

# é»˜è®¤å‚æ•°çš„ä½ç½®
# é»˜è®¤å‚æ•°å¿…é¡»åœ¨ä½ç½®å‚æ•°ä¹‹å

# âœ“ æ­£ç¡®
def method(self, required_param, optional_param="default"):
    pass

# âœ— é”™è¯¯
def method(self, optional_param="default", required_param):
    pass

# ä¸ºä»€ä¹ˆç”¨"2.txt"ä½œä¸ºé»˜è®¤å€¼ï¼Ÿ
# è¿™æ˜¯é¡¹ç›®ä¸­å­˜å‚¨æ–‡çŒ®çš„é»˜è®¤æ–‡ä»¶
# ç”¨æˆ·å¯ä»¥ï¼š
# 1. ä¸æŒ‡å®šæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤çš„2.txt
# 2. æŒ‡å®šå…¶ä»–æ–‡ä»¶å
```

**ç¬¬59-62è¡Œè¯¦è§£**ï¼šæ–‡ä»¶è¯»å–

```python
references = []                              # ç¬¬59è¡Œ
try:                                         # ç¬¬60è¡Œ
    with open(file_path, 'r', encoding='utf-8') as f:  # ç¬¬61è¡Œ
        content = f.read()                   # ç¬¬62è¡Œ

# ç¬¬59è¡Œï¼šåˆå§‹åŒ–åˆ—è¡¨
references = []
# åˆ›å»ºç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ‰€æœ‰æ–‡çŒ®

# ç¬¬60è¡Œï¼šå¼‚å¸¸å¤„ç†
try:
    # å¯èƒ½å‡ºé”™çš„ä»£ç 
except FileNotFoundError:
    # æ–‡ä»¶ä¸å­˜åœ¨æ—¶çš„å¤„ç†

# ä¸ºä»€ä¹ˆç”¨try-exceptï¼Ÿ
# 1. æ–‡ä»¶å¯èƒ½ä¸å­˜åœ¨
# 2. æ–‡ä»¶å¯èƒ½æ— æ³•è¯»å–ï¼ˆæƒé™é—®é¢˜ï¼‰
# 3. æ–‡ä»¶ç¼–ç å¯èƒ½ä¸å¯¹

# ç¬¬61è¡Œï¼šwithè¯­å¥æ‰“å¼€æ–‡ä»¶
with open(file_path, 'r', encoding='utf-8') as f:
    content = f.read()

# withè¯­å¥è¯¦è§£
# 1. ä½œç”¨ï¼šè‡ªåŠ¨ç®¡ç†èµ„æº
# 2. ä¼˜åŠ¿ï¼šè‡ªåŠ¨å…³é—­æ–‡ä»¶ï¼Œå³ä½¿å‡ºé”™ä¹Ÿä¼šå…³é—­

# ä¸ä½¿ç”¨withï¼ˆä¸æ¨èï¼‰
f = open(file_path, 'r', encoding='utf-8')
content = f.read()
f.close()  # å®¹æ˜“å¿˜è®°ï¼Œæˆ–è€…å‡ºé”™æ—¶ä¸æ‰§è¡Œ

# ä½¿ç”¨withï¼ˆæ¨èï¼‰
with open(file_path, 'r', encoding='utf-8') as f:
    content = f.read()
# æ–‡ä»¶è‡ªåŠ¨å…³é—­ï¼Œå³ä½¿è¯»å–å‡ºé”™

# open()å‚æ•°è¯¦è§£
open(
    file_path,         # æ–‡ä»¶è·¯å¾„
    'r',               # æ¨¡å¼ï¼ˆr=è¯»å–ï¼‰
    encoding='utf-8'   # ç¼–ç 
)

# æ–‡ä»¶æ‰“å¼€æ¨¡å¼
'r'   # åªè¯»æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
'w'   # å†™å…¥æ¨¡å¼ï¼ˆè¦†ç›–ï¼‰
'a'   # è¿½åŠ æ¨¡å¼
'r+'  # è¯»å†™æ¨¡å¼
'rb'  # äºŒè¿›åˆ¶åªè¯»
'wb'  # äºŒè¿›åˆ¶å†™å…¥

# encodingå‚æ•°çš„é‡è¦æ€§
# ä¸æŒ‡å®šç¼–ç ï¼ˆå¯èƒ½å‡ºé”™ï¼‰
with open('file.txt', 'r') as f:  # ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ç¼–ç 
    content = f.read()  # ä¸­æ–‡å¯èƒ½ä¹±ç 

# æŒ‡å®šUTF-8ç¼–ç ï¼ˆæ¨èï¼‰
with open('file.txt', 'r', encoding='utf-8') as f:
    content = f.read()  # ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º

# read()æ–¹æ³•
content = f.read()
# ä¸€æ¬¡æ€§è¯»å–æ•´ä¸ªæ–‡ä»¶å†…å®¹ä¸ºå­—ç¬¦ä¸²

# å…¶ä»–è¯»å–æ–¹æ³•
f.read()         # è¯»å–æ•´ä¸ªæ–‡ä»¶
f.read(100)      # è¯»å–100ä¸ªå­—ç¬¦
f.readline()     # è¯»å–ä¸€è¡Œ
f.readlines()    # è¯»å–æ‰€æœ‰è¡Œï¼Œè¿”å›åˆ—è¡¨

# æ–‡ä»¶å†…å®¹ç¤ºä¾‹ï¼ˆ2.txtï¼‰
"""
æ–‡çŒ®1
Zhang, L., et al. (2024). Deep Learning for Computer Vision...

æ–‡çŒ®2
Li, M., et al. (2023). Machine Learning Applications...

æ–‡çŒ®3
Wang, H., et al. (2024). Neural Networks in NLP...
"""

# è¯»å–åçš„content
content = """æ–‡çŒ®1
Zhang, L., et al. (2024)...
æ–‡çŒ®2
Li, M., et al. (2023)..."""
```

### æ–‡çŒ®åˆ†å‰²å’Œå¤„ç†ï¼ˆç¬¬64-86è¡Œï¼‰

```python
# æŒ‰æ–‡çŒ®åˆ†å‰²                                 # ç¬¬64è¡Œï¼ˆæ³¨é‡Šï¼‰
parts = re.split(r'(?=æ–‡çŒ®\d+)', content)   # ç¬¬65è¡Œ
parts = [part.strip() for part in parts if part.strip()]  # ç¬¬66è¡Œ

if not parts:                                 # ç¬¬68è¡Œ
    print("è­¦å‘Šï¼šæœªæ‰¾åˆ°ä»»ä½•æ–‡çŒ®")              # ç¬¬69è¡Œ
    return []                                 # ç¬¬70è¡Œ

for i, part in enumerate(parts):              # ç¬¬72è¡Œ
    ref_content = part                        # ç¬¬73è¡Œ
    # æå–æ–‡çŒ®ç¼–å·                            # ç¬¬74è¡Œï¼ˆæ³¨é‡Šï¼‰
    ref_id_match = re.match(r'æ–‡çŒ®(\d+)', ref_content)  # ç¬¬75è¡Œ
    ref_id = ref_id_match.group(1) if ref_id_match else str(i + 1)  # ç¬¬76è¡Œ
```

**ç¬¬65è¡Œè¯¦è§£**ï¼šæ­£åˆ™åˆ†å‰²

```python
parts = re.split(r'(?=æ–‡çŒ®\d+)', content)

# re.split()è¯¦è§£
# åŠŸèƒ½ï¼šæŒ‰æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²å­—ç¬¦ä¸²
# è¿”å›ï¼šåˆ†å‰²åçš„åˆ—è¡¨

# ç¤ºä¾‹
import re
text = "æ–‡çŒ®1å†…å®¹...æ–‡çŒ®2å†…å®¹...æ–‡çŒ®3å†…å®¹..."
parts = re.split(r'(?=æ–‡çŒ®\d+)', text)
# ç»“æœï¼š['', 'æ–‡çŒ®1å†…å®¹...', 'æ–‡çŒ®2å†…å®¹...', 'æ–‡çŒ®3å†…å®¹...']

# æ­£åˆ™è¡¨è¾¾å¼ r'(?=æ–‡çŒ®\d+)' è¯¦è§£
# (?=...)  - æ­£å‘å…ˆè¡Œæ–­è¨€ï¼ˆlookaheadï¼‰
# æ–‡çŒ®     - å­—é¢åŒ¹é…"æ–‡çŒ®"
# \d+      - ä¸€ä¸ªæˆ–å¤šä¸ªæ•°å­—

# ä»€ä¹ˆæ˜¯å…ˆè¡Œæ–­è¨€ï¼Ÿ
# åŒ¹é…ä½ç½®ï¼Œä½†ä¸æ¶ˆè€—å­—ç¬¦

# æ™®é€šåˆ†å‰²ï¼ˆæ¶ˆè€—åˆ†éš”ç¬¦ï¼‰
parts = re.split(r'æ–‡çŒ®\d+', text)
# ç»“æœï¼š['', 'å†…å®¹...', 'å†…å®¹...']
# é—®é¢˜ï¼šä¸¢å¤±äº†"æ–‡çŒ®1"ã€"æ–‡çŒ®2"ç­‰æ ‡è®°

# å…ˆè¡Œæ–­è¨€ï¼ˆä¿ç•™åˆ†éš”ç¬¦ï¼‰
parts = re.split(r'(?=æ–‡çŒ®\d+)', text)
# ç»“æœï¼š['', 'æ–‡çŒ®1å†…å®¹...', 'æ–‡çŒ®2å†…å®¹...']
# ä¼˜åŠ¿ï¼šä¿ç•™äº†"æ–‡çŒ®1"ã€"æ–‡çŒ®2"ç­‰æ ‡è®°

# å¯è§†åŒ–è¿‡ç¨‹
åŸå§‹æ–‡æœ¬ï¼š
"æ–‡çŒ®1å†…å®¹...æ–‡çŒ®2å†…å®¹...æ–‡çŒ®3å†…å®¹..."

åˆ†å‰²ä½ç½®ï¼ˆçº¢çº¿è¡¨ç¤ºï¼‰ï¼š
| æ–‡çŒ®1å†…å®¹...| æ–‡çŒ®2å†…å®¹...| æ–‡çŒ®3å†…å®¹...
â†‘           â†‘           â†‘
åœ¨è¿™äº›ä½ç½®åˆ†å‰²

åˆ†å‰²ç»“æœï¼š
['', 'æ–‡çŒ®1å†…å®¹...', 'æ–‡çŒ®2å†…å®¹...', 'æ–‡çŒ®3å†…å®¹...']
```

**ç¬¬66è¡Œè¯¦è§£**ï¼šåˆ—è¡¨æ¨å¯¼å¼

```python
parts = [part.strip() for part in parts if part.strip()]

# åˆ—è¡¨æ¨å¯¼å¼è¯¦è§£
# è¯­æ³•ï¼š[è¡¨è¾¾å¼ for é¡¹ in åºåˆ— if æ¡ä»¶]

# æ‹†è§£æˆæ™®é€šå¾ªç¯
parts_filtered = []
for part in parts:
    if part.strip():  # å¦‚æœå»ç©ºæ ¼åä¸ä¸ºç©º
        parts_filtered.append(part.strip())
parts = parts_filtered

# åˆ—è¡¨æ¨å¯¼å¼ï¼ˆç®€æ´ï¼‰
parts = [part.strip() for part in parts if part.strip()]

# strip()æ–¹æ³•è¯¦è§£
# åŠŸèƒ½ï¼šå»é™¤å­—ç¬¦ä¸²ä¸¤ç«¯çš„ç©ºç™½å­—ç¬¦

text = "  Hello  "
result = text.strip()
# ç»“æœï¼š"Hello"

# ç©ºç™½å­—ç¬¦åŒ…æ‹¬ï¼š
# - ç©ºæ ¼ ' '
# - åˆ¶è¡¨ç¬¦ '\t'
# - æ¢è¡Œç¬¦ '\n'
# - å›è½¦ç¬¦ '\r'

# ç¤ºä¾‹
"  æ–‡çŒ®1  ".strip()    # "æ–‡çŒ®1"
"\næ–‡çŒ®2\n".strip()   # "æ–‡çŒ®2"
"\t æ–‡çŒ®3 \t".strip() # "æ–‡çŒ®3"

# ä¸ºä»€ä¹ˆè¦è¿‡æ»¤ï¼Ÿ
åŸå§‹åˆ†å‰²ç»“æœï¼š
['', '  æ–‡çŒ®1...  ', '\næ–‡çŒ®2...\n', 'æ–‡çŒ®3...']

è¿‡æ»¤å’Œå»ç©ºæ ¼åï¼š
['æ–‡çŒ®1...', 'æ–‡çŒ®2...', 'æ–‡çŒ®3...']

# åˆ—è¡¨æ¨å¯¼å¼çš„ä¼˜åŠ¿
# 1. ä»£ç ç®€æ´
# 2. æ‰§è¡Œæ•ˆç‡é«˜
# 3. æ˜“äºé˜…è¯»

# æ›´å¤šåˆ—è¡¨æ¨å¯¼å¼ç¤ºä¾‹
# 1. åŸºæœ¬ç”¨æ³•
numbers = [1, 2, 3, 4, 5]
squares = [x**2 for x in numbers]
# [1, 4, 9, 16, 25]

# 2. å¸¦æ¡ä»¶
even_squares = [x**2 for x in numbers if x % 2 == 0]
# [4, 16]

# 3. å¤„ç†å­—ç¬¦ä¸²
words = ['  hello  ', '  world  ', '']
cleaned = [w.strip() for w in words if w.strip()]
# ['hello', 'world']

# 4. åµŒå¥—åˆ—è¡¨æ¨å¯¼å¼
matrix = [[1, 2], [3, 4], [5, 6]]
flat = [num for row in matrix for num in row]
# [1, 2, 3, 4, 5, 6]
```

**ç¬¬72è¡Œè¯¦è§£**ï¼šenumerate()å‡½æ•°

```python
for i, part in enumerate(parts):

# enumerate()è¯¦è§£
# åŠŸèƒ½ï¼šåœ¨å¾ªç¯æ—¶åŒæ—¶è·å–ç´¢å¼•å’Œå€¼
# è¿”å›ï¼š(ç´¢å¼•, å€¼) çš„å…ƒç»„

# ä¸ä½¿ç”¨enumerate
parts = ['æ–‡çŒ®1...', 'æ–‡çŒ®2...', 'æ–‡çŒ®3...']
for i in range(len(parts)):
    part = parts[i]
    print(f"{i}: {part}")

# ä½¿ç”¨enumerateï¼ˆæ¨èï¼‰
for i, part in enumerate(parts):
    print(f"{i}: {part}")

# è¾“å‡ºï¼š
# 0: æ–‡çŒ®1...
# 1: æ–‡çŒ®2...
# 2: æ–‡çŒ®3...

# enumerate()çš„å‚æ•°
# é»˜è®¤ä»0å¼€å§‹
for i, part in enumerate(parts):
    # i = 0, 1, 2, ...

# æŒ‡å®šèµ·å§‹å€¼
for i, part in enumerate(parts, start=1):
    # i = 1, 2, 3, ...

# enumerate()çš„å·¥ä½œåŸç†
parts = ['A', 'B', 'C']
enumerated = enumerate(parts)
# ç­‰ä»·äºï¼š
# [(0, 'A'), (1, 'B'), (2, 'C')]

# è§£åŒ…å…ƒç»„
for i, part in enumerate(parts):
    # i, part = (0, 'A')
    # i, part = (1, 'B')
    # i, part = (2, 'C')

# ä¸ºä»€ä¹ˆéœ€è¦ç´¢å¼•ï¼Ÿ
# æœ¬é¡¹ç›®ä¸­ç”¨äºç”Ÿæˆé»˜è®¤æ–‡çŒ®ç¼–å·
ref_id = str(i + 1)  # 0â†’"1", 1â†’"2", 2â†’"3"
```

**ç¬¬75-76è¡Œè¯¦è§£**ï¼šæå–æ–‡çŒ®ç¼–å·

```python
ref_id_match = re.match(r'æ–‡çŒ®(\d+)', ref_content)
ref_id = ref_id_match.group(1) if ref_id_match else str(i + 1)

# re.match()è¯¦è§£
# åŠŸèƒ½ï¼šä»å­—ç¬¦ä¸²å¼€å¤´åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼
# è¿”å›ï¼šMatchå¯¹è±¡ï¼ˆåŒ¹é…æˆåŠŸï¼‰æˆ–Noneï¼ˆå¤±è´¥ï¼‰

# ç¤ºä¾‹
import re
text = "æ–‡çŒ®123å†…å®¹..."
match = re.match(r'æ–‡çŒ®(\d+)', text)

# Matchå¯¹è±¡çš„æ–¹æ³•
if match:
    match.group(0)  # "æ–‡çŒ®123"ï¼ˆå®Œæ•´åŒ¹é…ï¼‰
    match.group(1)  # "123"ï¼ˆç¬¬ä¸€ä¸ªæ•è·ç»„ï¼‰
    match.start()   # 0ï¼ˆåŒ¹é…å¼€å§‹ä½ç½®ï¼‰
    match.end()     # 5ï¼ˆåŒ¹é…ç»“æŸä½ç½®ï¼‰

# match() vs search()
# match()ï¼šåªåŒ¹é…å­—ç¬¦ä¸²å¼€å¤´
text = "å†…å®¹æ–‡çŒ®123"
match = re.match(r'æ–‡çŒ®\d+', text)  # Noneï¼ˆå¼€å¤´ä¸æ˜¯"æ–‡çŒ®"ï¼‰

# search()ï¼šåœ¨æ•´ä¸ªå­—ç¬¦ä¸²ä¸­æŸ¥æ‰¾
match = re.search(r'æ–‡çŒ®\d+', text)  # æ‰¾åˆ°

# æ•è·ç»„è¯¦è§£
# r'æ–‡çŒ®(\d+)'
#    ^^^^^ - æ•è·ç»„ï¼Œç”¨()åŒ…å›´

match = re.match(r'æ–‡çŒ®(\d+)', 'æ–‡çŒ®123')
match.group(0)  # 'æ–‡çŒ®123'ï¼ˆå®Œæ•´åŒ¹é…ï¼‰
match.group(1)  # '123'ï¼ˆæ•è·ç»„1ï¼‰

# å¤šä¸ªæ•è·ç»„
match = re.match(r'æ–‡çŒ®(\d+)-(\w+)', 'æ–‡çŒ®123-ABC')
match.group(1)  # '123'
match.group(2)  # 'ABC'

# ç¬¬76è¡Œï¼šä¸‰å…ƒè¡¨è¾¾å¼ + group()
ref_id = ref_id_match.group(1) if ref_id_match else str(i + 1)

# æ‹†è§£
if ref_id_match:
    ref_id = ref_id_match.group(1)  # ä½¿ç”¨æ­£åˆ™æå–çš„ç¼–å·
else:
    ref_id = str(i + 1)             # ä½¿ç”¨ç´¢å¼•ç”Ÿæˆç¼–å·

# åº”ç”¨åœºæ™¯
# æƒ…å†µ1ï¼šæ–‡çŒ®æœ‰æ˜ç¡®ç¼–å·
"æ–‡çŒ®123å†…å®¹..."
# ref_id = "123"

# æƒ…å†µ2ï¼šæ–‡çŒ®æ²¡æœ‰ç¼–å·
"Some reference content..."
# ref_id = "1"ï¼ˆä½¿ç”¨ç´¢å¼• i=0, i+1=1ï¼‰

# str()è½¬æ¢
i = 0
ref_id = str(i + 1)  # "1"ï¼ˆå­—ç¬¦ä¸²ï¼‰

# ä¸ºä»€ä¹ˆè½¬ä¸ºå­—ç¬¦ä¸²ï¼Ÿ
# å› ä¸ºreference_mapçš„é”®æ˜¯å­—ç¬¦ä¸²
self.reference_map["1"] = content  # é”®æ˜¯å­—ç¬¦ä¸²
```

### å­˜å‚¨æ–‡çŒ®ï¼ˆç¬¬83-88è¡Œï¼‰

```python
# å­˜å‚¨æ–‡çŒ®å†…å®¹                              # ç¬¬83è¡Œï¼ˆæ³¨é‡Šï¼‰
self.reference_map[ref_id] = ref_content   # ç¬¬84è¡Œ
references.append(ref_content)             # ç¬¬85è¡Œ

print(f"æˆåŠŸåŠ è½½äº† {len(references)} ç¯‡æ–‡çŒ®")  # ç¬¬87è¡Œ
return references                          # ç¬¬88è¡Œ
```

**å­˜å‚¨å’Œè¿”å›è¯¦è§£ï¼ˆç¬¬84-88è¡Œï¼‰**ï¼š

```python
# ç¬¬84è¡Œï¼šå­˜å‚¨åˆ°å­—å…¸
self.reference_map[ref_id] = ref_content

# å­—å…¸èµ‹å€¼
# é”®ï¼šæ–‡çŒ®ç¼–å·ï¼ˆå­—ç¬¦ä¸²ï¼‰
# å€¼ï¼šæ–‡çŒ®å†…å®¹ï¼ˆå­—ç¬¦ä¸²ï¼‰

# ç¤ºä¾‹
self.reference_map = {
    "1": "Zhang et al. (2024). Deep Learning...",
    "2": "Li et al. (2023). Machine Learning...",
    "3": "Wang et al. (2024). Neural Networks..."
}

# ç¬¬85è¡Œï¼šæ·»åŠ åˆ°åˆ—è¡¨
references.append(ref_content)

# append()æ–¹æ³•
# åŠŸèƒ½ï¼šåœ¨åˆ—è¡¨æœ«å°¾æ·»åŠ å…ƒç´ 

references = []
references.append("æ–‡çŒ®1...")  # ['æ–‡çŒ®1...']
references.append("æ–‡çŒ®2...")  # ['æ–‡çŒ®1...', 'æ–‡çŒ®2...']

# ä¸ºä»€ä¹ˆåŒæ—¶å­˜å‚¨åˆ°å­—å…¸å’Œåˆ—è¡¨ï¼Ÿ
# 1. reference_mapï¼ˆå­—å…¸ï¼‰ï¼š
#    - ç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼ˆO(1)ï¼‰
#    - é€šè¿‡ç¼–å·è·å–å†…å®¹
#    ä¾‹ï¼šself.reference_map["1"]

# 2. referencesï¼ˆåˆ—è¡¨ï¼‰ï¼š
#    - ä¿æŒé¡ºåº
#    - ç”¨äºç”Ÿæˆæç¤ºè¯æ—¶çš„å¼•ç”¨åˆ—è¡¨
#    ä¾‹ï¼š[ref for ref in references]

# ç¬¬87è¡Œï¼šæ‰“å°æˆåŠŸä¿¡æ¯
print(f"æˆåŠŸåŠ è½½äº† {len(references)} ç¯‡æ–‡çŒ®")

# len()å‡½æ•°
# åŠŸèƒ½ï¼šè·å–åºåˆ—çš„é•¿åº¦

len([1, 2, 3])      # 3
len("Hello")        # 5
len({"a": 1, "b": 2})  # 2

# f-stringæ ¼å¼åŒ–
references = ["æ–‡çŒ®1", "æ–‡çŒ®2", "æ–‡çŒ®3"]
print(f"æˆåŠŸåŠ è½½äº† {len(references)} ç¯‡æ–‡çŒ®")
# è¾“å‡ºï¼šæˆåŠŸåŠ è½½äº† 3 ç¯‡æ–‡çŒ®

# ç¬¬88è¡Œï¼šè¿”å›æ–‡çŒ®åˆ—è¡¨
return references

# ä¸ºä»€ä¹ˆè¿”å›åˆ—è¡¨è€Œä¸æ˜¯å­—å…¸ï¼Ÿ
# 1. åˆ—è¡¨ä¿æŒæ–‡çŒ®çš„é¡ºåº
# 2. è°ƒç”¨è€…å¯èƒ½éœ€è¦éå†æ‰€æœ‰æ–‡çŒ®
# 3. å­—å…¸å·²ç»å­˜å‚¨åœ¨self.reference_mapä¸­

# å®Œæ•´çš„åŠ è½½æµç¨‹
# 1. è¯»å–æ–‡ä»¶ â†’ content
# 2. åˆ†å‰²æ–‡çŒ® â†’ parts
# 3. éå†å¤„ç† â†’ forå¾ªç¯
# 4. æå–ç¼–å· â†’ ref_id
# 5. å­˜å‚¨å­—å…¸ â†’ self.reference_map[ref_id]
# 6. æ·»åŠ åˆ—è¡¨ â†’ references.append()
# 7. è¿”å›åˆ—è¡¨ â†’ return references
```

---

## ğŸ¨ æ–‡æ¡£ç”Ÿæˆä¸»æ–¹æ³•

### generate_documentæ–¹æ³•æ¦‚è§ˆï¼ˆç¬¬94-169è¡Œï¼‰

```python
def generate_document(self, research_topic, word_count, output_length="long", language="zh"):
    """ç”Ÿæˆæ–‡æ¡£"""
    # ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡çŒ®
    references = self.load_all_references()
    
    # è¯»å–promptæ¨¡æ¿
    with open("prompt.txt", "r", encoding="utf-8") as f:
        prompt_template = f.read()
    
    # æ„å»ºå®Œæ•´æç¤ºè¯
    full_prompt = f"""
åŸºäºä»¥ä¸‹JSONæ ¼å¼çš„è¦æ±‚ç”Ÿæˆç›¸å…³å·¥ä½œéƒ¨åˆ†ï¼š

{prompt_template}

å…·ä½“å‚æ•°ï¼š
- Research Topic: {research_topic}
- Target Word Count: {word_count}
- Preferred Language: {language}
"""
    
    # è°ƒç”¨APIç”Ÿæˆå†…å®¹
    content = self._call_api(full_prompt)
    parsed_content = self._parse_content(content)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
    if language == "zh":
        word_path = self._generate_word_doc(chinese_text)
    if language == "en":
        latex_path = self._generate_latex_doc(english_text)
    
    return result
```

**æ–¹æ³•å‚æ•°è¯¦è§£**ï¼š

```python
def generate_document(
    self,
    research_topic,      # ç ”ç©¶ä¸»é¢˜
    word_count,          # ç›®æ ‡å­—æ•°
    output_length="long", # è¾“å‡ºé•¿åº¦
    language="zh"        # è¯­è¨€
):

# å‚æ•°è¯´æ˜
# 1. research_topic - ç ”ç©¶ä¸»é¢˜ï¼ˆå­—ç¬¦ä¸²ï¼‰
research_topic = "Deep Learning in Computer Vision"

# 2. word_count - ç›®æ ‡å­—æ•°ï¼ˆæ•´æ•°ï¼‰
word_count = 3000

# 3. output_length - è¾“å‡ºé•¿åº¦ï¼ˆå­—ç¬¦ä¸²ï¼Œé»˜è®¤"long"ï¼‰
output_length = "long"   # é•¿æ–‡æœ¬
output_length = "medium" # ä¸­ç­‰é•¿åº¦
output_length = "short"  # çŸ­æ–‡æœ¬

# 4. language - è¯­è¨€ï¼ˆå­—ç¬¦ä¸²ï¼Œé»˜è®¤"zh"ï¼‰
language = "zh"    # ä¸­æ–‡
language = "en"    # è‹±æ–‡
language = "both"  # åŒè¯­

# ä½¿ç”¨ç¤ºä¾‹
gen = DocumentGenerator(model_provider="gpt")

# ç”Ÿæˆä¸­æ–‡æ–‡æ¡£
result = gen.generate_document(
    research_topic="æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨",
    word_count=3000,
    language="zh"
)

# ç”Ÿæˆè‹±æ–‡æ–‡æ¡£
result = gen.generate_document(
    research_topic="Deep Learning in CV",
    word_count=3000,
    language="en"
)

# ç”ŸæˆåŒè¯­æ–‡æ¡£
result = gen.generate_document(
    research_topic="æ·±åº¦å­¦ä¹  / Deep Learning",
    word_count=3000,
    language="both"
)

# è¿”å›å€¼ç»“æ„
result = {
    "word_cn_path": "output_chinese.docx",     # ä¸­æ–‡Wordæ–‡æ¡£
    "latex_en_path": "output_english.tex",     # è‹±æ–‡LaTeXæ–‡æ¡£
    "content": "AIè¿”å›çš„åŸå§‹å†…å®¹",
    "parsed_content": {...}                    # è§£æåçš„JSON
}
```

---

## ğŸ”Œ APIè°ƒç”¨æ–¹æ³•

### _call_apiæ–¹æ³•ï¼ˆç¬¬171-193è¡Œï¼‰

```python
def _call_api(self, prompt):                 # ç¬¬171è¡Œ
    """è°ƒç”¨API"""                             # ç¬¬172è¡Œ
    try:                                     # ç¬¬173è¡Œ
        print("æ­£åœ¨è°ƒç”¨API...")               # ç¬¬174è¡Œ
        response = self.client.chat.completions.create(  # ç¬¬178è¡Œ
            model=self.model,                # ç¬¬179è¡Œ
            messages=[                       # ç¬¬180è¡Œ
                {"role": "system", "content": "You are a helpful assistant..."},  # ç¬¬181-182è¡Œ
                {"role": "user", "content": prompt},  # ç¬¬183è¡Œ
            ],
            stream=False                     # ç¬¬185è¡Œ
        )
        
        time.sleep(1)                        # ç¬¬189è¡Œ
        return response.choices[0].message.content  # ç¬¬190è¡Œ
    except Exception as e:                   # ç¬¬191è¡Œ
        return f"APIè°ƒç”¨å¤±è´¥: {str(e)}"       # ç¬¬193è¡Œ
```

**APIè°ƒç”¨è¯¦è§£**ï¼š

```python
# æ–¹æ³•åå‰ç¼€ï¼š_call_api
# ä¸‹åˆ’çº¿å¼€å¤´è¡¨ç¤º"ç§æœ‰æ–¹æ³•"ï¼ˆçº¦å®šï¼‰
# ä¸åº”è¯¥è¢«å¤–éƒ¨ç›´æ¥è°ƒç”¨

# å…¬æœ‰æ–¹æ³•ï¼ˆå¤–éƒ¨å¯è°ƒç”¨ï¼‰
def generate_document(self):
    pass

# ç§æœ‰æ–¹æ³•ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
def _call_api(self):
    pass

# chat.completions.create()è¯¦è§£
response = self.client.chat.completions.create(
    model=self.model,              # æ¨¡å‹åç§°
    messages=[...],                # å¯¹è¯æ¶ˆæ¯
    stream=False                   # éæµå¼è¾“å‡º
)

# messageså‚æ•°è¯¦è§£
messages = [
    {
        "role": "system",
        "content": "You are a helpful assistant that generates academic content in JSON format."
    },
    {
        "role": "user",
        "content": prompt
    }
]

# systemæ¶ˆæ¯ï¼šè®¾ç½®AIçš„è¡Œä¸º
# - å®šä¹‰AIçš„è§’è‰²
# - æŒ‡å®šè¾“å‡ºæ ¼å¼
# - è®¾ç½®å†™ä½œé£æ ¼

# useræ¶ˆæ¯ï¼šç”¨æˆ·çš„å®é™…è¯·æ±‚
# - åŒ…å«å®Œæ•´çš„æç¤ºè¯
# - åŒ…å«æ–‡çŒ®å¼•ç”¨
# - åŒ…å«æ ¼å¼è¦æ±‚

# streamå‚æ•°è¯¦è§£
stream=False  # éæµå¼è¾“å‡ºï¼ˆä¸€æ¬¡æ€§è¿”å›å®Œæ•´ç»“æœï¼‰

# éæµå¼ï¼ˆstream=Falseï¼‰
response = client.chat.completions.create(
    model="gpt-4",
    messages=[...],
    stream=False
)
content = response.choices[0].message.content
print(content)  # ä¸€æ¬¡æ€§è¾“å‡ºå®Œæ•´å†…å®¹

# æµå¼ï¼ˆstream=Trueï¼‰
response = client.chat.completions.create(
    model="gpt-4",
    messages=[...],
    stream=True
)
for chunk in response:
    print(chunk.choices[0].delta.content, end='')
    # é€å­—è¾“å‡ºï¼Œç±»ä¼¼æ‰“å­—æœºæ•ˆæœ

# é€‰æ‹©éæµå¼çš„åŸå› ï¼š
# 1. éœ€è¦å®Œæ•´å†…å®¹æ‰èƒ½è§£æJSON
# 2. ä¸éœ€è¦å®æ—¶æ˜¾ç¤º
# 3. ä»£ç æ›´ç®€å•

# responseå¯¹è±¡ç»“æ„
response = {
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "AIç”Ÿæˆçš„å†…å®¹"
            }
        }
    ]
}

# æå–å†…å®¹
content = response.choices[0].message.content

# å»¶è¿Ÿï¼ˆç¬¬189è¡Œï¼‰
time.sleep(1)
# ä½œç”¨ï¼šé¿å…APIè°ƒç”¨é¢‘ç‡è¿‡é«˜

# å¼‚å¸¸å¤„ç†
try:
    response = self.client.chat.completions.create(...)
except Exception as e:
    # æ•è·æ‰€æœ‰å¼‚å¸¸
    return f"APIè°ƒç”¨å¤±è´¥: {str(e)}"

# å¯èƒ½çš„å¼‚å¸¸ç±»å‹ï¼š
# - APIConnectionError: è¿æ¥å¤±è´¥
# - APITimeoutError: è¶…æ—¶
# - RateLimitError: é¢‘ç‡é™åˆ¶
# - AuthenticationError: è®¤è¯å¤±è´¥
```

---

## ğŸ“– å†…å®¹è§£ææ–¹æ³•

### _parse_contentæ–¹æ³•ï¼ˆç¬¬195-223è¡Œï¼‰

```python
def _parse_content(self, content):           # ç¬¬195è¡Œ
    """è§£æAPIè¿”å›çš„å†…å®¹"""                   # ç¬¬196è¡Œ
    try:                                     # ç¬¬197è¡Œ
        # å°è¯•ç›´æ¥è§£æJSON                    # ç¬¬198è¡Œï¼ˆæ³¨é‡Šï¼‰
        json_content = json.loads(content)   # ç¬¬199è¡Œ
        return json_content                  # ç¬¬200è¡Œ
    
    except json.JSONDecodeError:             # ç¬¬202è¡Œ
        # å°è¯•ä»markdownæ ¼å¼æå–JSON          # ç¬¬203è¡Œï¼ˆæ³¨é‡Šï¼‰
        json_match = re.search(r'```json\n(.*?)\n```', content, re.DOTALL)  # ç¬¬204è¡Œ
        if json_match:                       # ç¬¬205è¡Œ
            json_content = json.loads(json_match.group(1))  # ç¬¬207è¡Œ
            return json_content              # ç¬¬208è¡Œ
```

**JSONè§£æè¯¦è§£**ï¼š

```python
# json.loads()è¯¦è§£
# åŠŸèƒ½ï¼šå°†JSONå­—ç¬¦ä¸²è½¬æ¢ä¸ºPythonå¯¹è±¡

# ç¤ºä¾‹
import json

json_str = '{"name": "è®ºæ–‡", "year": 2024}'
obj = json.loads(json_str)
# ç»“æœï¼š{'name': 'è®ºæ–‡', 'year': 2024}

# JSONDecodeErrorå¼‚å¸¸
# å½“JSONæ ¼å¼ä¸æ­£ç¡®æ—¶æŠ›å‡º

try:
    json.loads('invalid json')
except json.JSONDecodeError as e:
    print(f"JSONè§£æå¤±è´¥: {e}")

# å¤šå±‚è§£æç­–ç•¥
# ç­–ç•¥1ï¼šç›´æ¥è§£æ
json_content = json.loads(content)

# ç­–ç•¥2ï¼šä»markdownä»£ç å—æå–
# AIå¯èƒ½è¿”å›ï¼š
"""
è¿™æ˜¯ä¸€äº›è¯´æ˜æ–‡å­—

```json
{
  "background": "..."
}
```

æ›´å¤šè¯´æ˜
"""

# ä½¿ç”¨æ­£åˆ™æå–JSONéƒ¨åˆ†
json_match = re.search(r'```json\n(.*?)\n```', content, re.DOTALL)

# æ­£åˆ™è¡¨è¾¾å¼è¯¦è§£
# r'```json\n(.*?)\n```'
# ```json      - å­—é¢åŒ¹é…"```json"
# \n           - æ¢è¡Œç¬¦
# (.*?)        - æ•è·ç»„ï¼Œéè´ªå©ªåŒ¹é…ä»»æ„å­—ç¬¦
# \n```        - æ¢è¡Œ+å­—é¢åŒ¹é…"```"

# re.DOTALLæ ‡å¿—
# è®©.åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„æ‰€æœ‰å­—ç¬¦

# ç¤ºä¾‹
text = """
```json
{
  "key": "value"
}
```
"""

match = re.search(r'```json\n(.*?)\n```', text, re.DOTALL)
if match:
    json_str = match.group(1)
    # '{\n  "key": "value"\n}'

# ç­–ç•¥3ï¼šæå–JSONå¯¹è±¡
# æœ€åçš„å°è¯•ï¼šæŸ¥æ‰¾ç¬¬ä¸€ä¸ª{}
json_match = re.search(r'\{.*\}', content, re.DOTALL)

# ä¸ºä»€ä¹ˆéœ€è¦å¤šå±‚è§£æï¼Ÿ
# AIè¿”å›æ ¼å¼å¯èƒ½ä¸ä¸€è‡´ï¼š
# 1. çº¯JSON
# 2. Markdownä»£ç å—ä¸­çš„JSON
# 3. æ–‡æœ¬ä¸­åŒ…å«JSON

# è§£æå¤±è´¥å¤„ç†
if not parsed_content:
    print("JSONè§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹ï¼š")
    print(content)
    return None
```

---

## ğŸ“ æ–‡æ¡£è¾“å‡ºæ–¹æ³•

### _generate_word_docæ–¹æ³•ï¼ˆç¬¬225-245è¡Œï¼‰

```python
def _generate_word_doc(self, content):       # ç¬¬225è¡Œ
    """ç”ŸæˆWordæ–‡æ¡£"""                        # ç¬¬226è¡Œ
    doc = Document()                         # ç¬¬227è¡Œ
    
    # æ·»åŠ æ ‡é¢˜                               # ç¬¬229è¡Œï¼ˆæ³¨é‡Šï¼‰
    doc.add_heading('ç›¸å…³å·¥ä½œ', level=1)      # ç¬¬230è¡Œ
    
    # å¤„ç†å†…å®¹                               # ç¬¬232è¡Œï¼ˆæ³¨é‡Šï¼‰
    if isinstance(content, str):             # ç¬¬233è¡Œ
        # æŒ‰æ®µè½åˆ†å‰²                          # ç¬¬234è¡Œï¼ˆæ³¨é‡Šï¼‰
        paragraphs = content.split('\n\n')   # ç¬¬235è¡Œ
        for paragraph in paragraphs:         # ç¬¬236è¡Œ
            if paragraph.strip():            # ç¬¬237è¡Œ
                doc.add_paragraph(paragraph.strip())  # ç¬¬238è¡Œ
    
    output_path = "output_chinese.docx"      # ç¬¬242è¡Œ
    doc.save(output_path)                    # ç¬¬243è¡Œ
    return os.path.abspath(output_path)      # ç¬¬245è¡Œ
```

**Wordæ–‡æ¡£ç”Ÿæˆè¯¦è§£**ï¼š

```python
# Document()åˆ›å»ºæ–°æ–‡æ¡£
from docx import Document
doc = Document()

# add_heading()æ·»åŠ æ ‡é¢˜
doc.add_heading('ç›¸å…³å·¥ä½œ', level=1)
# level=1ï¼šä¸€çº§æ ‡é¢˜
# level=2ï¼šäºŒçº§æ ‡é¢˜
# level=3ï¼šä¸‰çº§æ ‡é¢˜

# isinstance()ç±»å‹æ£€æŸ¥
isinstance(content, str)
# æ£€æŸ¥contentæ˜¯å¦æ˜¯å­—ç¬¦ä¸²ç±»å‹

# ç¤ºä¾‹
isinstance("hello", str)     # True
isinstance(123, str)         # False
isinstance({"a": 1}, dict)   # True

# split()æŒ‰åˆ†éš”ç¬¦åˆ†å‰²
content = "æ®µè½1\n\næ®µè½2\n\næ®µè½3"
paragraphs = content.split('\n\n')
# ['æ®µè½1', 'æ®µè½2', 'æ®µè½3']

# '\n\n'è¡¨ç¤ºç©ºè¡Œï¼ˆä¸¤ä¸ªæ¢è¡Œç¬¦ï¼‰
# ç”¨äºåˆ†éš”æ®µè½

# add_paragraph()æ·»åŠ æ®µè½
doc.add_paragraph("è¿™æ˜¯ä¸€ä¸ªæ®µè½")

# save()ä¿å­˜æ–‡æ¡£
doc.save("output.docx")

# os.path.abspath()è·å–ç»å¯¹è·¯å¾„
# ç›¸å¯¹è·¯å¾„
output_path = "output.docx"

# ç»å¯¹è·¯å¾„
abs_path = os.path.abspath(output_path)
# 'D:/project/output.docx'

# ä¸ºä»€ä¹ˆè¿”å›ç»å¯¹è·¯å¾„ï¼Ÿ
# 1. æ˜ç¡®æ–‡ä»¶ä½ç½®
# 2. ä¾¿äºåœ¨å…¶ä»–ç›®å½•è®¿é—®
# 3. ç”¨æˆ·ä½“éªŒæ›´å¥½
```

---

## ğŸ¯ æŠ€æœ¯æ€»ç»“

### æ ¸å¿ƒæŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç”¨é€” | å…³é”®ç‰¹æ€§ |
|------|------|---------|
| **OpenAI API** | AIå†…å®¹ç”Ÿæˆ | GPT-4ã€DeepSeekå…¼å®¹ |
| **python-docx** | Wordæ–‡æ¡£ | åˆ›å»º.docxæ–‡ä»¶ |
| **æ­£åˆ™è¡¨è¾¾å¼** | æ–‡æœ¬å¤„ç† | æ–‡çŒ®åˆ†å‰²ã€JSONæå– |
| **JSON** | æ•°æ®äº¤æ¢ | AIè¾“å‡ºã€é…ç½®ç®¡ç† |
| **å¼‚å¸¸å¤„ç†** | é”™è¯¯ç®¡ç† | try-exceptã€å¤šå±‚è§£æ |

### è®¾è®¡æ¨¡å¼

1. **é¢å‘å¯¹è±¡è®¾è®¡**: ä½¿ç”¨ç±»å°è£…åŠŸèƒ½
2. **é…ç½®é©±åŠ¨**: å¤šæ¨¡å‹æ”¯æŒï¼Œæ˜“äºæ‰©å±•
3. **é”™è¯¯å®¹é”™**: å¤šå±‚è§£æã€å¼‚å¸¸å¤„ç†
4. **æ¨¡æ¿æ–¹æ³•**: åŸºäºpromptæ¨¡æ¿ç”Ÿæˆ
5. **å•ä¸€èŒè´£**: æ¯ä¸ªæ–¹æ³•åŠŸèƒ½æ˜ç¡®

### æœ€ä½³å®è·µ

1. âœ… **ç±»å‹æ£€æŸ¥**: ä½¿ç”¨isinstance()
2. âœ… **æ–‡ä»¶ç®¡ç†**: withè¯­å¥è‡ªåŠ¨å…³é—­
3. âœ… **ç¼–ç æŒ‡å®š**: encoding='utf-8'
4. âœ… **å¼‚å¸¸å¤„ç†**: try-exceptæ•è·é”™è¯¯
5. âœ… **ç§æœ‰æ–¹æ³•**: _å¼€å¤´è¡¨ç¤ºå†…éƒ¨ä½¿ç”¨
6. âœ… **é»˜è®¤å‚æ•°**: æä¾›åˆç†é»˜è®¤å€¼
7. âœ… **æ–‡æ¡£å­—ç¬¦ä¸²**: æ¯ä¸ªæ–¹æ³•éƒ½æœ‰è¯´æ˜

### å­¦ä¹ ä»·å€¼

è¿™ä¸ªæ–‡æ¡£ç”Ÿæˆå™¨å±•ç¤ºäº†ï¼š
- ğŸ¤– **AIé›†æˆ**: å¦‚ä½•è°ƒç”¨LLM API
- ğŸ“„ **æ–‡æ¡£å¤„ç†**: Wordã€LaTeXç”Ÿæˆ
- ğŸ” **æ–‡æœ¬è§£æ**: æ­£åˆ™è¡¨è¾¾å¼åº”ç”¨
- ğŸ’¾ **æ•°æ®ç®¡ç†**: å­—å…¸ã€é›†åˆçš„ä½¿ç”¨
- ğŸ—ï¸ **æ¶æ„è®¾è®¡**: é¢å‘å¯¹è±¡ç¼–ç¨‹

**å®Œæ•´æµç¨‹æ€»ç»“**ï¼š

```
åˆå§‹åŒ– â†’ åŠ è½½æ–‡çŒ® â†’ æ„å»ºæç¤ºè¯ â†’ è°ƒç”¨API â†’ è§£æJSON â†’ ç”Ÿæˆæ–‡æ¡£
  â†“         â†“           â†“          â†“        â†“          â†“
é…ç½®API   2.txt     prompt.txt   OpenAI   å¤šå±‚è§£æ   .docx/.tex
```

è¿™æ˜¯ä¸€ä¸ª**å·¥ä¸šçº§çš„AIæ–‡æ¡£ç”Ÿæˆç³»ç»Ÿ**ï¼ğŸš€


